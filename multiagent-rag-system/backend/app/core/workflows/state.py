"""
LangGraph State Definition for RAG Workflow

This module defines the state schema that flows through the LangGraph workflow.
It's designed to be compatible with the existing StreamingAgentState while
leveraging LangGraph's state management features.
"""

from typing import TypedDict, Annotated, Sequence, List, Dict, Any, Optional, Literal
from operator import add
from datetime import datetime

from langchain_core.messages import BaseMessage


# ============================================================================
# State Reducers
# ============================================================================

def add_messages_reducer(existing: Sequence[BaseMessage], new: Sequence[BaseMessage]) -> Sequence[BaseMessage]:
    """
    Reducer for messages field.
    Accumulates messages while avoiding duplicates.
    """
    existing_list = list(existing) if existing else []
    new_list = list(new) if new else []

    # Simple accumulation (LangGraph handles deduplication)
    return existing_list + new_list


def add_list_reducer(existing: List, new: List) -> List:
    """
    Reducer for list fields.
    Accumulates items from both lists.
    """
    existing_list = existing if existing else []
    new_list = new if new else []
    return existing_list + new_list


def merge_dict_reducer(existing: Dict, new: Dict) -> Dict:
    """
    Reducer for dict fields.
    Merges dictionaries, with new values overwriting existing ones.
    """
    existing_dict = existing if existing else {}
    new_dict = new if new else {}
    return {**existing_dict, **new_dict}


# ============================================================================
# Main State Schema
# ============================================================================

class RAGState(TypedDict):
    """
    LangGraph State for the RAG workflow.

    This TypedDict defines all state that flows through the graph.
    Fields with Annotated[..., reducer] will automatically accumulate
    values across node executions.

    State Flow:
        Initial → Triage → [Chat Flow | Task Flow] → Final

    Compatibility:
        - Maps from existing StreamingAgentState
        - Adds LangGraph-specific features (reducers, messages)
        - Maintains all existing functionality
    """

    # ===== Core Query Information =====
    original_query: str
    """Original user query"""

    conversation_id: str
    """Unique conversation/session identifier"""

    user_id: str
    """User identifier (default: 'default_user')"""

    session_id: str
    """Session ID (same as conversation_id for compatibility)"""

    message_id: Optional[str]
    """Individual message ID within conversation"""

    start_time: str
    """Workflow start timestamp (ISO format)"""

    # ===== Flow Control =====
    flow_type: Optional[Literal['chat', 'task']]
    """
    Workflow type determined by triage:
    - 'chat': Simple Q&A with SimpleAnswerer
    - 'task': Complex report generation with Orchestrator
    """

    current_step_index: int
    """Current step in multi-step task execution (0-indexed)"""

    needs_replan: bool
    """Flag indicating if replanning is needed"""

    replan_feedback: Optional[str]
    """Feedback for replanning (if needed)"""

    # ===== LangChain Messages (LangGraph Standard) =====
    messages: Annotated[Sequence[BaseMessage], add_messages_reducer]
    """
    LangChain message history.
    Automatically accumulated across nodes.
    """

    # ===== Planning & Execution (Task Flow) =====
    plan: Optional[Dict[str, Any]]
    """
    Execution plan generated by OrchestratorAgent.
    Structure: {
        "title": str,
        "reasoning": str,
        "execution_steps": [
            {
                "step_number": int,
                "step_title": str,
                "data_collection_tasks": [
                    {"tool": str, "query": str}
                ]
            }
        ]
    }
    """

    execution_steps: List[Dict[str, Any]]
    """Flattened list of execution steps from plan"""

    step_results_context: Dict[int, str]
    """
    Accumulated context per step.
    Key: step_index, Value: context summary
    """

    # ===== Data Collection (Accumulated across nodes) =====
    collected_data: Annotated[List[Dict[str, Any]], add_list_reducer]
    """
    All collected SearchResults (as dicts).
    Accumulated from multiple data gathering nodes.
    """

    selected_indexes: Annotated[List[int], add_list_reducer]
    """
    Indexes of selected data items for current processing.
    Used for filtering relevant data per step.
    """

    # ===== Report Generation (Task Flow) =====
    design: Optional[Dict[str, Any]]
    """
    Report structure design from ProcessorAgent.
    Structure: {
        "title": str,
        "structure": [
            {
                "section_title": str,
                "content_type": str,
                "description": str
            }
        ]
    }
    """

    accumulated_context: Dict[str, Any]
    """
    Accumulated context for report generation.
    Contains: generated_sections, charts, insights, persona
    """

    chart_counter: int
    """Counter for chart numbering"""

    # ===== Chat Flow Specific =====
    search_flags: Optional[Dict[str, bool]]
    """
    Search requirements determined by SimpleAnswerer.
    Structure: {
        "needs_web_search": bool,
        "needs_vector_search": bool,
        "needs_scraping": bool
    }
    """

    web_results: Annotated[List[Dict[str, Any]], add_list_reducer]
    """Web search results (accumulated)"""

    vector_results: Annotated[List[Dict[str, Any]], add_list_reducer]
    """Vector DB search results (accumulated)"""

    scraped_content: Annotated[List[Dict[str, Any]], add_list_reducer]
    """Scraped content from URLs (accumulated)"""

    memory_context: Optional[str]
    """
    Conversation history context for chat flow.
    Built from conversation_history in metadata.
    """

    final_answer: Optional[str]
    """Final generated answer (chat) or report (task)"""

    # ===== Metadata & Sources =====
    metadata: Annotated[Dict[str, Any], merge_dict_reducer]
    """
    Metadata dictionary (merged across nodes).
    Common keys:
    - run_id: str
    - status: str (running, completed, error, aborted)
    - triage_reasoning: str
    - classified_at: str
    - project_name: str
    - team_id: str
    - conversation_history: List[Dict]
    - graph_probe: Dict (Neo4j pre-check results)
    - sources: List[Dict] (for complete event)
    """

    sources: Annotated[List[Dict[str, Any]], add_list_reducer]
    """
    All source documents referenced in the response.
    Accumulated from all search operations.
    """

    # ===== Execution Tracking =====
    execution_log: Annotated[List[str], add_list_reducer]
    """
    Execution log entries (accumulated).
    Format: "YYYY-MM-DD HH:MM:SS - NodeName - Message"
    """

    # ===== Persona (Team-based responses) =====
    persona: Optional[str]
    """
    Selected persona/team for response generation.
    Examples: "기본", "구매 담당자", "데이터 분석가"
    """


# ============================================================================
# State Utilities
# ============================================================================

def create_initial_state(
    query: str,
    conversation_id: str,
    user_id: str = "default_user",
    session_id: Optional[str] = None,
    message_id: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
    persona: Optional[str] = None
) -> RAGState:
    """
    Create initial RAGState for workflow execution.

    Args:
        query: User query
        conversation_id: Conversation identifier
        user_id: User identifier
        session_id: Session ID (defaults to conversation_id)
        message_id: Message ID
        metadata: Additional metadata
        persona: Selected persona/team

    Returns:
        Initial RAGState with required fields populated
    """
    from langchain_core.messages import HumanMessage

    return RAGState(
        # Core info
        original_query=query,
        conversation_id=conversation_id,
        user_id=user_id,
        session_id=session_id or conversation_id,
        message_id=message_id,
        start_time=datetime.now().isoformat(),

        # Flow control
        flow_type=None,
        current_step_index=0,
        needs_replan=False,
        replan_feedback=None,

        # Messages
        messages=[HumanMessage(content=query)],

        # Planning
        plan=None,
        execution_steps=[],
        step_results_context={},

        # Data collection
        collected_data=[],
        selected_indexes=[],

        # Report generation
        design=None,
        accumulated_context={},
        chart_counter=0,

        # Chat specific
        search_flags=None,
        web_results=[],
        vector_results=[],
        scraped_content=[],
        memory_context=None,
        final_answer=None,

        # Metadata
        metadata=metadata or {},
        sources=[],

        # Execution tracking
        execution_log=[],

        # Persona
        persona=persona
    )


def log_state_transition(
    state: RAGState,
    node_name: str,
    message: str
) -> RAGState:
    """
    Add execution log entry to state.

    Args:
        state: Current state
        node_name: Name of the node
        message: Log message

    Returns:
        Updated state with new log entry
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"{timestamp} - {node_name} - {message}"

    # Create new state with updated log
    new_state = dict(state)
    new_state["execution_log"] = state.get("execution_log", []) + [log_entry]

    return new_state


def validate_state(state: RAGState) -> bool:
    """
    Validate RAGState has required fields.

    Args:
        state: State to validate

    Returns:
        True if valid, False otherwise
    """
    required_fields = [
        "original_query",
        "conversation_id",
        "user_id",
        "session_id"
    ]

    for field in required_fields:
        if field not in state or state[field] is None:
            print(f"❌ State validation failed: missing '{field}'")
            return False

    return True
