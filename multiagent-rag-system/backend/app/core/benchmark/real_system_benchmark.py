# -*- coding: utf-8 -*-
"""
ì‹¤ì œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬
HTTP APIë¥¼ í†µí•´ ì‹¤ì œ Multi-Hop RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì¸¡ì •
"""

import asyncio
import aiohttp
import time
import json
import statistics
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class RealPerformanceMetrics:
    """ì‹¤ì œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼"""
    query_id: str
    query_text: str
    hop_count: int
    total_time: float
    response_time: float  # HTTP ì‘ë‹µ ì‹œê°„
    content_length: int
    search_tools_used: List[str]
    sources_found: int
    success: bool = True
    error_msg: Optional[str] = None
    timestamp: str = ""
    session_id: str = ""

class RealSystemBenchmark:
    """ì‹¤ì œ ì‹œìŠ¤í…œ HTTP APIë¥¼ í†µí•œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results: List[RealPerformanceMetrics] = []
        
        # Multi-Hop í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        self.test_queries = {
            2: [
                "ì œì£¼ë„ ê°ê·¤ì˜ ì£¼ìš” ìˆ˜ì¶œêµ­ì€?",
                "ê°•ì›ë„ ê°ìì˜ ì˜ì–‘ì„±ë¶„ì€?", 
                "í•œìš°ì˜ ëŒ€ì²´ ë‹¨ë°±ì§ˆ ì‹í’ˆì€?",
                "ê¹€ì¹˜ì— í¬í•¨ëœ ì£¼ìš” ë¹„íƒ€ë¯¼ì€?",
                "ìœ ê¸°ë† ìŒ€ì˜ í‰ê·  ê°€ê²©ì€?"
            ],
            3: [
                "í­ì—¼ í”¼í•´ë¥¼ ë°›ì€ ì§€ì—­ì˜ ì£¼ìš” ë†ì‚°ë¬¼ ê°€ê²©ì€?",
                "ìœ ê¸°ë† ì¸ì¦ì„ ë°›ì€ ì œì£¼ë„ ë†ì‚°ë¬¼ì˜ ìˆ˜ì¶œí˜„í™©ì€?", 
                "ë¹„íƒ€ë¯¼Cê°€ í’ë¶€í•œ ê³¼ì¼ì˜ ì£¼ìš” ìƒì‚°ì§€ëŠ”?",
                "ê°€ë­„ í”¼í•´ì§€ì—­ì˜ ê³¡ë¬¼ ìƒì‚°ëŸ‰ ë³€í™”ëŠ”?",
                "ìˆ˜ì¶œ ì¦ê°€ìœ¨ì´ ë†’ì€ í•œêµ­ ë†ì‚°ë¬¼ì˜ íŠ¹ì§•ì€?"
            ],
            4: [
                "ì§‘ì¤‘í˜¸ìš° í”¼í•´ì§€ì—­ì˜ ì£¼ìš” ë†ì‚°ë¬¼ì— í¬í•¨ëœ ì˜ì–‘ì„±ë¶„ê³¼ ìœ ì‚¬í•œ ëŒ€ì²´ ì‹í’ˆì€?",
                "ìˆ˜ì¶œì´ ì¦ê°€í•œ í•œêµ­ ë†ì‚°ë¬¼ì˜ ìƒì‚°ì§€ì—­ë³„ í† ì–‘ íŠ¹ì„±ì€?",
                "ê¸°í›„ë³€í™”ë¡œ ì˜í–¥ë°›ì€ ì‘ë¬¼ì˜ ì˜ì–‘ì„±ë¶„ ë³€í™”ì™€ ê±´ê°• ì˜í–¥ì€?",
                "ìœ ê¸°ë† ì¸ì¦ ë†ì‚°ë¬¼ì˜ ì§€ì—­ë³„ ìƒì‚°í˜„í™©ê³¼ ì†Œë¹„ì ì„ í˜¸ë„ëŠ”?",
                "í•œêµ­ ì „í†µ ë°œíš¨ì‹í’ˆì˜ í•´ì™¸ ìˆ˜ì¶œ í˜„í™©ê³¼ í˜„ì§€ ì ì‘ ì „ëµì€?"
            ]
        }

    async def test_single_query(self, session: aiohttp.ClientSession, 
                               query: str, hop_count: int, query_id: str) -> RealPerformanceMetrics:
        """ë‹¨ì¼ ì¿¼ë¦¬ë¥¼ ì‹¤ì œ ì‹œìŠ¤í…œì—ì„œ í…ŒìŠ¤íŠ¸"""
        
        print(f"  ğŸš€ í…ŒìŠ¤íŠ¸ ì¤‘: {query[:50]}...")
        
        start_time = time.time()
        session_id = f"benchmark_{query_id}_{int(time.time())}"
        
        # API ìš”ì²­ ì¤€ë¹„
        payload = {
            "query": query,
            "conversation_id": session_id
        }
        
        search_tools_used = []
        sources_found = 0
        content_chunks = []
        
        try:
            # ì‹¤ì œ API í˜¸ì¶œ
            async with session.post(
                f"{self.base_url}/query/stream",
                json=payload,
                timeout=aiohttp.ClientTimeout(total=120)  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
            ) as response:
                
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"HTTP {response.status}: {error_text}")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
                async for line in response.content:
                    line = line.decode('utf-8').strip()
                    
                    if line.startswith('data: '):
                        try:
                            data = json.loads(line[6:])  # 'data: ' ì œê±°
                            
                            # ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© ì¶”ì 
                            if data.get('type') == 'search_results':
                                tool_name = data.get('tool_name', '')
                                if tool_name and tool_name not in search_tools_used:
                                    search_tools_used.append(tool_name)
                                
                                results = data.get('results', [])
                                sources_found += len(results)
                            
                            # ì½˜í…ì¸  ìˆ˜ì§‘
                            elif data.get('type') == 'content':
                                chunk = data.get('chunk', '')
                                content_chunks.append(chunk)
                                
                            elif data.get('type') == 'final_complete':
                                break
                                
                        except json.JSONDecodeError:
                            continue  # JSONì´ ì•„ë‹Œ ë¼ì¸ì€ ë¬´ì‹œ
                
                response_time = time.time() - start_time
                final_content = ''.join(content_chunks)
                
                print(f"    âœ… ì„±ê³µ ({response_time:.2f}ì´ˆ) - ë„êµ¬: {search_tools_used}, ì†ŒìŠ¤: {sources_found}ê°œ")
                
                return RealPerformanceMetrics(
                    query_id=query_id,
                    query_text=query,
                    hop_count=hop_count,
                    total_time=response_time,
                    response_time=response_time,
                    content_length=len(final_content),
                    search_tools_used=search_tools_used,
                    sources_found=sources_found,
                    success=True,
                    session_id=session_id,
                    timestamp=datetime.now().isoformat()
                )
                
        except Exception as e:
            response_time = time.time() - start_time
            print(f"    âŒ ì‹¤íŒ¨ ({response_time:.2f}ì´ˆ): {str(e)}")
            
            return RealPerformanceMetrics(
                query_id=query_id,
                query_text=query,
                hop_count=hop_count,
                total_time=response_time,
                response_time=response_time,
                content_length=0,
                search_tools_used=search_tools_used,
                sources_found=sources_found,
                success=False,
                error_msg=str(e),
                session_id=session_id,
                timestamp=datetime.now().isoformat()
            )

    async def run_benchmark(self) -> Dict[str, Any]:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        
        print("ğŸš€ ì‹¤ì œ Multi-Hop RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print(f"ğŸŒ ëŒ€ìƒ ì‹œìŠ¤í…œ: {self.base_url}")
        print(f"ğŸ“Š ì´ {sum(len(queries) for queries in self.test_queries.values())}ê°œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(f"{self.base_url}/health") as response:
                    if response.status == 200:
                        health_data = await response.json()
                        print(f"âœ… ì‹œìŠ¤í…œ ìƒíƒœ: {health_data.get('status', 'unknown')}")
                    else:
                        print(f"âš ï¸ ì‹œìŠ¤í…œ ì‘ë‹µ: HTTP {response.status}")
            except Exception as e:
                print(f"âŒ ì‹œìŠ¤í…œ ì—°ê²° ì‹¤íŒ¨: {e}")
                return {"error": "ì‹œìŠ¤í…œ ì—°ê²° ë¶ˆê°€"}
        
        results = {
            'config': {
                'target_system': self.base_url,
                'total_queries': sum(len(queries) for queries in self.test_queries.values()),
                'queries_per_hop': {str(hop): len(queries) for hop, queries in self.test_queries.items()}
            },
            'start_time': datetime.now().isoformat(),
            'results': {},
            'raw_metrics': []
        }
        
        # HTTP ì„¸ì…˜ ìƒì„±í•˜ì—¬ ì—°ê²° ì¬ì‚¬ìš©
        async with aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(limit=10, limit_per_host=5)
        ) as session:
            
            for hop_count, queries in self.test_queries.items():
                print(f"ğŸ”„ {hop_count}-Hop ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ({len(queries)}ê°œ)")
                hop_results = []
                
                for i, query in enumerate(queries, 1):
                    query_id = f"{hop_count}hop_q{i:02d}"
                    
                    # ê°œë³„ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
                    metrics = await self.test_single_query(session, query, hop_count, query_id)
                    hop_results.append(self._metrics_to_dict(metrics))
                    self.results.append(metrics)
                    
                    # ì¿¼ë¦¬ ê°„ ê°„ê²© (ì‹œìŠ¤í…œ ë¶€í•˜ ë°©ì§€)
                    await asyncio.sleep(1)
                
                results['results'][f'{hop_count}_hop'] = hop_results
                print()  # ë¹ˆ ì¤„ ì¶”ê°€
        
        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        results['summary'] = self._generate_summary()
        results['raw_metrics'] = [self._metrics_to_dict(m) for m in self.results]
        results['end_time'] = datetime.now().isoformat()
        
        return results
    
    def _metrics_to_dict(self, metrics: RealPerformanceMetrics) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'query_id': metrics.query_id,
            'query_text': metrics.query_text,
            'hop_count': metrics.hop_count,
            'total_time': round(metrics.total_time, 3),
            'response_time': round(metrics.response_time, 3),
            'content_length': metrics.content_length,
            'search_tools_used': metrics.search_tools_used,
            'sources_found': metrics.sources_found,
            'success': metrics.success,
            'error_msg': metrics.error_msg,
            'session_id': metrics.session_id,
            'timestamp': metrics.timestamp
        }
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        
        successful_metrics = [m for m in self.results if m.success]
        
        summary = {
            'total_queries': len(self.results),
            'successful_queries': len(successful_metrics),
            'success_rate': len(successful_metrics) / len(self.results) * 100 if self.results else 0,
        }
        
        if successful_metrics:
            # Hopë³„ ì„±ëŠ¥ ë¶„ì„
            by_hop = {}
            for hop_count in [2, 3, 4]:
                hop_metrics = [m for m in successful_metrics if m.hop_count == hop_count]
                if hop_metrics:
                    times = [m.total_time for m in hop_metrics]
                    sources = [m.sources_found for m in hop_metrics]
                    content_lengths = [m.content_length for m in hop_metrics]
                    
                    by_hop[f'{hop_count}_hop'] = {
                        'count': len(hop_metrics),
                        'avg_response_time': statistics.mean(times),
                        'min_response_time': min(times),
                        'max_response_time': max(times),
                        'median_response_time': statistics.median(times),
                        'std_response_time': statistics.stdev(times) if len(times) > 1 else 0,
                        'avg_sources_found': statistics.mean(sources),
                        'avg_content_length': statistics.mean(content_lengths),
                        'total_time': sum(times)
                    }
            
            summary['by_hop_count'] = by_hop
            
            # ì „ì²´ ì„±ëŠ¥ í†µê³„
            all_times = [m.total_time for m in successful_metrics]
            all_sources = [m.sources_found for m in successful_metrics]
            all_content_lengths = [m.content_length for m in successful_metrics]
            
            summary['overall'] = {
                'avg_response_time': statistics.mean(all_times),
                'median_response_time': statistics.median(all_times),
                'min_response_time': min(all_times),
                'max_response_time': max(all_times),
                'std_response_time': statistics.stdev(all_times) if len(all_times) > 1 else 0,
                'total_test_time': sum(all_times),
                'avg_sources_per_query': statistics.mean(all_sources),
                'avg_content_length': statistics.mean(all_content_lengths)
            }
            
            # ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© ë¹ˆë„ ë¶„ì„
            all_tools = []
            for m in successful_metrics:
                all_tools.extend(m.search_tools_used)
            
            tool_frequency = {}
            for tool in all_tools:
                tool_frequency[tool] = tool_frequency.get(tool, 0) + 1
            
            summary['search_tools_usage'] = {
                'frequency': tool_frequency,
                'unique_tools': list(set(all_tools)),
                'avg_tools_per_query': len(all_tools) / len(successful_metrics) if successful_metrics else 0
            }
            
            # ì„±ëŠ¥ ë¶„ë¥˜
            fast_queries = [m for m in successful_metrics if m.total_time < 3.0]
            medium_queries = [m for m in successful_metrics if 3.0 <= m.total_time < 8.0]
            slow_queries = [m for m in successful_metrics if m.total_time >= 8.0]
            
            summary['performance_distribution'] = {
                'fast_queries': {'count': len(fast_queries), 'percentage': len(fast_queries) / len(successful_metrics) * 100},
                'medium_queries': {'count': len(medium_queries), 'percentage': len(medium_queries) / len(successful_metrics) * 100},
                'slow_queries': {'count': len(slow_queries), 'percentage': len(slow_queries) / len(successful_metrics) * 100}
            }
            
        return summary
    
    def print_detailed_summary(self, summary: Dict[str, Any]) -> None:
        """ìƒì„¸ ìš”ì•½ ê²°ê³¼ ì¶œë ¥"""
        
        print("\n" + "="*80)
        print("ğŸ‰ ì‹¤ì œ Multi-Hop RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print("="*80)
        
        print(f"ğŸ“Š ì „ì²´ ì„±ê³µë¥ : {summary['success_rate']:.1f}% ({summary['successful_queries']}/{summary['total_queries']})")
        
        if 'overall' in summary:
            overall = summary['overall']
            print(f"\nâš¡ ì „ì²´ ì„±ëŠ¥ ì§€í‘œ:")
            print(f"   â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {overall['avg_response_time']:.2f}ì´ˆ")
            print(f"   â€¢ ì¤‘ì•™ê°’: {overall['median_response_time']:.2f}ì´ˆ")
            print(f"   â€¢ ìµœì†Œ/ìµœëŒ€: {overall['min_response_time']:.2f}ì´ˆ / {overall['max_response_time']:.2f}ì´ˆ")
            print(f"   â€¢ í‘œì¤€í¸ì°¨: {overall['std_response_time']:.2f}ì´ˆ")
            print(f"   â€¢ í‰ê·  ì†ŒìŠ¤ ê°œìˆ˜: {overall['avg_sources_per_query']:.1f}ê°œ")
            print(f"   â€¢ í‰ê·  ì‘ë‹µ ê¸¸ì´: {overall['avg_content_length']:.0f}ì")
        
        if 'by_hop_count' in summary:
            print(f"\nğŸ”¢ Hopë³„ ìƒì„¸ ì„±ëŠ¥:")
            for hop, stats in summary['by_hop_count'].items():
                print(f"   ğŸ“‹ {hop}:")
                print(f"      - í‰ê·  ì‹œê°„: {stats['avg_response_time']:.2f}ì´ˆ (Â±{stats['std_response_time']:.2f})")
                print(f"      - ì¤‘ì•™ê°’: {stats['median_response_time']:.2f}ì´ˆ")
                print(f"      - ë²”ìœ„: {stats['min_response_time']:.2f}~{stats['max_response_time']:.2f}ì´ˆ")
                print(f"      - í‰ê·  ì†ŒìŠ¤: {stats['avg_sources_found']:.1f}ê°œ")
        
        if 'search_tools_usage' in summary:
            tools_usage = summary['search_tools_usage']
            print(f"\nğŸ” ê²€ìƒ‰ ë„êµ¬ ì‚¬ìš© í˜„í™©:")
            print(f"   â€¢ ì‚¬ìš©ëœ ë„êµ¬: {', '.join(tools_usage['unique_tools'])}")
            print(f"   â€¢ ì¿¼ë¦¬ë‹¹ í‰ê·  ë„êµ¬ ìˆ˜: {tools_usage['avg_tools_per_query']:.1f}ê°œ")
            print(f"   â€¢ ë„êµ¬ë³„ ì‚¬ìš© ë¹ˆë„:")
            for tool, count in tools_usage['frequency'].items():
                print(f"     - {tool}: {count}íšŒ")
        
        if 'performance_distribution' in summary:
            perf_dist = summary['performance_distribution']
            print(f"\nğŸ“ˆ ì„±ëŠ¥ ë¶„í¬:")
            print(f"   â€¢ ë¹ ë¦„ (<3ì´ˆ): {perf_dist['fast_queries']['count']}ê°œ ({perf_dist['fast_queries']['percentage']:.1f}%)")
            print(f"   â€¢ ë³´í†µ (3-8ì´ˆ): {perf_dist['medium_queries']['count']}ê°œ ({perf_dist['medium_queries']['percentage']:.1f}%)")
            print(f"   â€¢ ëŠë¦¼ (>8ì´ˆ): {perf_dist['slow_queries']['count']}ê°œ ({perf_dist['slow_queries']['percentage']:.1f}%)")
    
    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"/tmp/real_multihop_benchmark_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥: {filename}")
        return filename


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ ì‹¤ì œ Multi-Hop RAG ì‹œìŠ¤í…œ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘")
    print("ğŸ“ HTTP APIë¥¼ í†µí•´ ì‹¤ì œ ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤\n")
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = RealSystemBenchmark()
    results = await benchmark.run_benchmark()
    
    if 'error' in results:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì‹¤íŒ¨: {results['error']}")
        return
    
    # ìƒì„¸ ìš”ì•½ ì¶œë ¥
    benchmark.print_detailed_summary(results['summary'])
    
    # ê²°ê³¼ ì €ì¥
    filename = benchmark.save_results(results)
    
    print(f"\nâœ¨ ì‹¤ì œ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {filename}")
    print(f"\nğŸ“ˆ ì´ ì‹¤ì œ ë°ì´í„°ë¥¼ ë…¼ë¬¸ì— í™œìš©í•˜ì—¬ Multi-Hop RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì…ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return results, filename


if __name__ == "__main__":
    results, filename = asyncio.run(main())