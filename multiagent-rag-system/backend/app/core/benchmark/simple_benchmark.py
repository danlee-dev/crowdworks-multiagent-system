# -*- coding: utf-8 -*-
"""
ê°„ë‹¨í•œ ì„±ëŠ¥ ì¸¡ì • ë„êµ¬ - ì˜ì¡´ì„± ìµœì†Œí™”
ì‹¤ì œ ì‹œìŠ¤í…œ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ìƒì„±
"""

import asyncio
import json
import time
import random
from datetime import datetime
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class MockPerformanceMetrics:
    """ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ (ì‹œë®¬ë ˆì´ì…˜ìš©)"""
    query_id: str
    query_text: str
    hop_count: int
    total_time: float
    step_times: List[float]
    search_engine_times: Dict[str, float]
    parallel_time: float
    sequential_time: float
    precheck_time: float
    success: bool = True
    error_msg: str = None
    timestamp: str = ""

class MockBenchmarkSimulator:
    """ì‹¤ì œ ì‹œìŠ¤í…œ ì—†ì´ í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ì‹œë®¬ë ˆì´ì…˜"""
    
    def __init__(self):
        # í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ëª¨ë¸ íŒŒë¼ë¯¸í„°
        self.base_times = {
            2: {'min': 1.5, 'max': 4.0, 'avg': 2.8},  # 2-hop
            3: {'min': 3.2, 'max': 8.5, 'avg': 5.2},  # 3-hop  
            4: {'min': 6.1, 'max': 15.0, 'avg': 9.8}  # 4-hop
        }
        
        self.engine_ratios = {
            'graph_rag': 0.35,      # GraphRAGê°€ 35% ì‹œê°„ ì†Œìš”
            'vector_rag': 0.40,     # Vector RAGê°€ 40% ì‹œê°„ ì†Œìš”  
            'web_search': 0.15,     # Web Searchê°€ 15% ì‹œê°„ ì†Œìš”
            'rdb': 0.10            # RDBê°€ 10% ì‹œê°„ ì†Œìš”
        }
        
        # ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ì„± (hopì´ ë³µì¡í• ìˆ˜ë¡ ë³‘ë ¬ íš¨ê³¼ ì¦ëŒ€)
        self.parallel_efficiency = {2: 0.25, 3: 0.45, 4: 0.65}
        
    def simulate_query_performance(self, query_text: str, hop_count: int, query_id: str) -> MockPerformanceMetrics:
        """ë‹¨ì¼ ì¿¼ë¦¬ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜"""
        
        # ê¸°ë³¸ ì‹¤í–‰ ì‹œê°„ (ì •ê·œë¶„í¬ ê¸°ë°˜)
        base_params = self.base_times[hop_count]
        total_time = random.gauss(base_params['avg'], (base_params['max'] - base_params['min']) / 6)
        total_time = max(base_params['min'], min(base_params['max'], total_time))
        
        # ë‹¨ê³„ë³„ ì‹œê°„ ë¶„ë°°
        step_count = hop_count + 1  # planning + hop ë‹¨ê³„ë“¤
        step_times = []
        remaining_time = total_time * 0.9  # 10%ëŠ” ì˜¤ë²„í—¤ë“œ
        
        for i in range(step_count):
            if i == step_count - 1:
                step_times.append(remaining_time)
            else:
                # ë³µì¡í•œ hopì¼ìˆ˜ë¡ ë’¤ìª½ ë‹¨ê³„ê°€ ë” ì˜¤ë˜ ê±¸ë¦¼
                weight = 1.0 + (i * 0.3)
                step_time = remaining_time * weight / sum(1.0 + j * 0.3 for j in range(step_count))
                step_times.append(step_time)
                remaining_time -= step_time
        
        # ê²€ìƒ‰ ì—”ì§„ë³„ ì‹œê°„ ë¶„ë°°
        search_engine_times = {}
        search_total = total_time * 0.75  # 75%ê°€ ì‹¤ì œ ê²€ìƒ‰ ì‹œê°„
        
        for engine, ratio in self.engine_ratios.items():
            base_time = search_total * ratio
            # Â±20% ë³€ë™ì„± ì¶”ê°€
            variation = random.gauss(0, 0.2)
            search_engine_times[engine] = max(0, base_time * (1 + variation))
        
        # ë³‘ë ¬ vs ìˆœì°¨ ì²˜ë¦¬ ì‹œê°„
        sequential_time = total_time
        parallel_efficiency = self.parallel_efficiency[hop_count]
        parallel_time = total_time * (1 - parallel_efficiency * random.uniform(0.8, 1.2))
        
        # í”„ë¦¬ì²´í¬ ì‹œê°„ (GraphRAG ì‚¬ì „ í™•ì¸)
        precheck_time = random.uniform(0.1, 0.4)
        
        # 5% í™•ë¥ ë¡œ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜ (ë³µì¡í•œ ì¿¼ë¦¬ì¼ìˆ˜ë¡ ì‹¤íŒ¨ìœ¨ ì¦ê°€)
        failure_rate = 0.02 + (hop_count - 2) * 0.015
        success = random.random() > failure_rate
        
        return MockPerformanceMetrics(
            query_id=query_id,
            query_text=query_text,
            hop_count=hop_count,
            total_time=total_time,
            step_times=step_times,
            search_engine_times=search_engine_times,
            parallel_time=parallel_time,
            sequential_time=sequential_time,
            precheck_time=precheck_time,
            success=success,
            error_msg=None if success else f"íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨ (ë³µì¡ë„: {hop_count}-hop)",
            timestamp=datetime.now().isoformat()
        )
    
    def run_full_benchmark(self) -> Dict[str, Any]:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜
        test_queries = {
            2: [
                "ì œì£¼ë„ ê°ê·¤ì˜ ì£¼ìš” ìˆ˜ì¶œêµ­ì€?",
                "ê°•ì›ë„ ê°ìì˜ ì˜ì–‘ì„±ë¶„ì€?", 
                "í•œìš°ì˜ ëŒ€ì²´ ë‹¨ë°±ì§ˆ ì‹í’ˆì€?",
                "ìœ ê¸°ë† ìŒ€ì˜ í‰ê·  ê°€ê²©ì€?",
                "ê¹€ì¹˜ì— í¬í•¨ëœ ì£¼ìš” ë¹„íƒ€ë¯¼ì€?",
                "ì „ë¼ë‚¨ë„ ë°°ì¶”ì˜ ìƒì‚°ëŸ‰ì€?",
                "êµ­ì‚° ì‡ ê³ ê¸°ì˜ ë“±ê¸‰ ê¸°ì¤€ì€?",
                "ì‚¬ê³¼ì˜ ë‹¹ë„ ì¸¡ì • ë°©ë²•ì€?",
                "ê³ êµ¬ë§ˆì˜ ë³´ê´€ ë°©ë²•ì€?",
                "ë§ˆëŠ˜ì˜ í•­ì‚°í™” ì„±ë¶„ì€?"
            ],
            3: [
                "í­ì—¼ í”¼í•´ë¥¼ ë°›ì€ ì§€ì—­ì˜ ì£¼ìš” ë†ì‚°ë¬¼ ê°€ê²©ì€?",
                "ìœ ê¸°ë† ì¸ì¦ì„ ë°›ì€ ì œì£¼ë„ ë†ì‚°ë¬¼ì˜ ìˆ˜ì¶œí˜„í™©ì€?", 
                "ë¹„íƒ€ë¯¼Cê°€ í’ë¶€í•œ ê³¼ì¼ì˜ ì£¼ìš” ìƒì‚°ì§€ëŠ”?",
                "ê°€ë­„ í”¼í•´ì§€ì—­ì˜ ê³¡ë¬¼ ìƒì‚°ëŸ‰ ë³€í™”ëŠ”?",
                "ìˆ˜ì¶œ ì¦ê°€ìœ¨ì´ ë†’ì€ í•œêµ­ ë†ì‚°ë¬¼ì˜ íŠ¹ì§•ì€?",
                "ì§‘ì¤‘í˜¸ìš°ë¡œ í”¼í•´ë°›ì€ ì¶©ì²­ë„ ìŒ€ì˜ ëŒ€ì²´ ê³µê¸‰ì›ì€?",
                "ì¹œí™˜ê²½ ì¸ì¦ ë†ì‚°ë¬¼ì˜ ì†Œë¹„ì êµ¬ë§¤ íŒ¨í„´ì€?",
                "ê¸°í›„ë³€í™”ê°€ ê³¼ì¼ ë‹¹ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
                "í•œêµ­ ì „í†µ ì¥ë¥˜ì˜ í•´ì™¸ ì§„ì¶œ í˜„í™©ì€?",
                "GMO ì‘ë¬¼ì— ëŒ€í•œ êµ­ë¯¼ ì¸ì‹ ë³€í™”ëŠ”?"
            ],
            4: [
                "ì§‘ì¤‘í˜¸ìš° í”¼í•´ì§€ì—­ì˜ ì£¼ìš” ë†ì‚°ë¬¼ì— í¬í•¨ëœ ì˜ì–‘ì„±ë¶„ê³¼ ìœ ì‚¬í•œ ëŒ€ì²´ ì‹í’ˆì€?",
                "ìˆ˜ì¶œì´ ì¦ê°€í•œ í•œêµ­ ë†ì‚°ë¬¼ì˜ ìƒì‚°ì§€ì—­ë³„ í† ì–‘ íŠ¹ì„±ì€?",
                "ê¸°í›„ë³€í™”ë¡œ ì˜í–¥ë°›ì€ ì‘ë¬¼ì˜ ì˜ì–‘ì„±ë¶„ ë³€í™”ì™€ ê±´ê°• ì˜í–¥ì€?",
                "ìœ ê¸°ë† ì¸ì¦ ë†ì‚°ë¬¼ì˜ ì§€ì—­ë³„ ìƒì‚°í˜„í™©ê³¼ ì†Œë¹„ì ì„ í˜¸ë„ëŠ”?",
                "í•œêµ­ ì „í†µ ë°œíš¨ì‹í’ˆì˜ í•´ì™¸ ìˆ˜ì¶œ í˜„í™©ê³¼ í˜„ì§€ ì ì‘ ì „ëµì€?",
                "ê°€ë­„ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ì€ ê³¼ìˆ˜ì˜ ë‹¹ë„ ë³€í™”ì™€ ê°€ê³µì‹í’ˆ í™œìš©ë°©ì•ˆì€?",
                "ìˆ˜ì… ëŒ€ì²´ íš¨ê³¼ê°€ ë†’ì€ êµ­ì‚° ë†ì‚°ë¬¼ì˜ ê²½ìŸë ¥ ê°•í™” ë°©ì•ˆì€?",
                "ìŠ¤ë§ˆíŠ¸íŒœ ê¸°ìˆ  ë„ì… ë†ê°€ì˜ ìƒì‚°ì„± í–¥ìƒê³¼ ê²½ì œì  íš¨ê³¼ëŠ”?",
                "ë†ì‚°ë¬¼ ê°€ê³µ ì‚°ì—… ë°œì „ì´ ë†ì´Œ ê²½ì œì— ë¯¸ì¹˜ëŠ” íŒŒê¸‰íš¨ê³¼ëŠ”?",
                "ì¹œí™˜ê²½ ë†ì—… í™•ì‚°ì´ ìƒë¬¼ë‹¤ì–‘ì„± ë³´ì „ì— ë¯¸ì¹˜ëŠ” ê¸ì •ì  ì˜í–¥ì€?"
            ]
        }
        
        print("ğŸš€ Multi-Hop RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
        print(f"ğŸ“Š ì´ {sum(len(queries) for queries in test_queries.values())}ê°œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
        
        results = {
            'config': {
                'simulation': True,
                'total_queries': sum(len(queries) for queries in test_queries.values()),
                'queries_per_hop': {str(hop): len(queries) for hop, queries in test_queries.items()}
            },
            'start_time': datetime.now().isoformat(),
            'results': {},
            'raw_metrics': []
        }
        
        # ê° hopë³„ ì‹¤í–‰
        for hop_count, queries in test_queries.items():
            print(f"\nğŸ”„ {hop_count}-Hop ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ({len(queries)}ê°œ)")
            hop_results = []
            
            for i, query in enumerate(queries, 1):
                query_id = f"{hop_count}hop_q{i:02d}"
                
                # ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
                metrics = self.simulate_query_performance(query, hop_count, query_id)
                
                hop_results.append({
                    'query_id': metrics.query_id,
                    'query_text': metrics.query_text,
                    'hop_count': metrics.hop_count,
                    'total_time': round(metrics.total_time, 3),
                    'parallel_time': round(metrics.parallel_time, 3),
                    'sequential_time': round(metrics.sequential_time, 3),
                    'speedup_ratio': round(metrics.sequential_time / metrics.parallel_time, 2),
                    'step_times': [round(t, 3) for t in metrics.step_times],
                    'search_engine_times': {k: round(v, 3) for k, v in metrics.search_engine_times.items()},
                    'precheck_time': round(metrics.precheck_time, 3),
                    'success': metrics.success,
                    'error_msg': metrics.error_msg,
                    'timestamp': metrics.timestamp
                })
                
                results['raw_metrics'].append(metrics)
                
                status = "âœ…" if metrics.success else "âŒ"
                speedup = metrics.sequential_time / metrics.parallel_time
                print(f"  [{i:2d}/{len(queries)}] {status} {metrics.total_time:.2f}ì´ˆ (ë³‘ë ¬ íš¨ê³¼: {speedup:.1f}x)")
            
            results['results'][f'{hop_count}_hop'] = hop_results
        
        # ê²°ê³¼ ìš”ì•½ ìƒì„±
        results['summary'] = self._generate_summary(results['raw_metrics'])
        results['end_time'] = datetime.now().isoformat()
        
        return results
    
    def _generate_summary(self, metrics: List[MockPerformanceMetrics]) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        
        successful_metrics = [m for m in metrics if m.success]
        
        summary = {
            'total_queries': len(metrics),
            'successful_queries': len(successful_metrics),
            'success_rate': len(successful_metrics) / len(metrics) * 100 if metrics else 0,
        }
        
        if successful_metrics:
            # Hopë³„ ì„±ëŠ¥ ë¶„ì„
            by_hop = {}
            for hop_count in [2, 3, 4]:
                hop_metrics = [m for m in successful_metrics if m.hop_count == hop_count]
                if hop_metrics:
                    times = [m.total_time for m in hop_metrics]
                    parallel_times = [m.parallel_time for m in hop_metrics]
                    sequential_times = [m.sequential_time for m in hop_metrics]
                    speedups = [s/p for s, p in zip(sequential_times, parallel_times)]
                    
                    by_hop[f'{hop_count}_hop'] = {
                        'count': len(hop_metrics),
                        'avg_total_time': sum(times) / len(times),
                        'avg_parallel_time': sum(parallel_times) / len(parallel_times),
                        'avg_sequential_time': sum(sequential_times) / len(sequential_times),
                        'avg_speedup': sum(speedups) / len(speedups),
                        'min_time': min(times),
                        'max_time': max(times),
                        'time_saved': sum(sequential_times) - sum(parallel_times),
                        'efficiency_gain': (sum(sequential_times) - sum(parallel_times)) / sum(sequential_times) * 100
                    }
            
            summary['by_hop_count'] = by_hop
            
            # ì „ì²´ ì„±ëŠ¥ í†µê³„
            all_times = [m.total_time for m in successful_metrics]
            all_parallel = [m.parallel_time for m in successful_metrics]
            all_sequential = [m.sequential_time for m in successful_metrics]
            all_speedups = [s/p for s, p in zip(all_sequential, all_parallel)]
            
            summary['overall'] = {
                'avg_response_time': sum(all_times) / len(all_times),
                'avg_parallel_time': sum(all_parallel) / len(all_parallel),
                'avg_sequential_time': sum(all_sequential) / len(all_sequential),
                'overall_speedup': sum(all_sequential) / sum(all_parallel),
                'total_time_saved': sum(all_sequential) - sum(all_parallel),
                'efficiency_improvement': (sum(all_sequential) - sum(all_parallel)) / sum(all_sequential) * 100,
                'min_response_time': min(all_times),
                'max_response_time': max(all_times)
            }
            
            # ê²€ìƒ‰ ì—”ì§„ë³„ ì„±ëŠ¥ ë¶„ì„
            engine_summary = {}
            for engine in ['graph_rag', 'vector_rag', 'web_search', 'rdb']:
                engine_times = [m.search_engine_times.get(engine, 0.0) for m in successful_metrics]
                non_zero_times = [t for t in engine_times if t > 0]
                if non_zero_times:
                    engine_summary[engine] = {
                        'avg_time': sum(non_zero_times) / len(non_zero_times),
                        'total_time': sum(non_zero_times),
                        'usage_rate': len(non_zero_times) / len(successful_metrics) * 100,
                        'time_percentage': sum(non_zero_times) / sum(all_times) * 100
                    }
            
            summary['by_search_engine'] = engine_summary
            
            # í”„ë¦¬ì²´í¬ íš¨ê³¼ ë¶„ì„
            precheck_times = [m.precheck_time for m in successful_metrics]
            summary['precheck_analysis'] = {
                'avg_precheck_time': sum(precheck_times) / len(precheck_times),
                'total_precheck_time': sum(precheck_times),
                'precheck_overhead': sum(precheck_times) / sum(all_times) * 100,
                'estimated_searches_avoided': len(successful_metrics) * 0.4  # 40% ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ë°©ì§€ ê°€ì •
            }
            
        return summary
    
    def print_detailed_summary(self, summary: Dict[str, Any]) -> None:
        """ìƒì„¸ ìš”ì•½ ê²°ê³¼ ì¶œë ¥"""
        
        print(f"\n" + "="*80)
        print(f"ğŸ‰ Multi-Hop RAG ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
        print(f"="*80)
        
        print(f"ğŸ“Š ì „ì²´ ì„±ê³µë¥ : {summary['success_rate']:.1f}% ({summary['successful_queries']}/{summary['total_queries']})")
        
        if 'overall' in summary:
            overall = summary['overall']
            print(f"\nâš¡ ë³‘ë ¬ ì²˜ë¦¬ íš¨ê³¼:")
            print(f"   â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {overall['avg_response_time']:.2f}ì´ˆ")
            print(f"   â€¢ ìˆœì°¨ ì²˜ë¦¬: {overall['avg_sequential_time']:.2f}ì´ˆ â†’ ë³‘ë ¬ ì²˜ë¦¬: {overall['avg_parallel_time']:.2f}ì´ˆ")
            print(f"   â€¢ ğŸš€ ì†ë„ í–¥ìƒ: {overall['overall_speedup']:.1f}ë°° ë¹ ë¦„")
            print(f"   â€¢ ğŸ’° ì‹œê°„ ì ˆì•½: {overall['total_time_saved']:.1f}ì´ˆ ({overall['efficiency_improvement']:.1f}% íš¨ìœ¨ í–¥ìƒ)")
        
        if 'by_hop_count' in summary:
            print(f"\nğŸ”¢ Hopë³„ ìƒì„¸ ì„±ëŠ¥:")
            for hop, stats in summary['by_hop_count'].items():
                print(f"   ğŸ“‹ {hop}:")
                print(f"      - í‰ê·  ì‹œê°„: {stats['avg_total_time']:.2f}ì´ˆ")
                print(f"      - ë³‘ë ¬ íš¨ê³¼: {stats['avg_speedup']:.1f}ë°° ì†ë„ í–¥ìƒ")
                print(f"      - íš¨ìœ¨ í–¥ìƒ: {stats['efficiency_gain']:.1f}% ({stats['time_saved']:.1f}ì´ˆ ì ˆì•½)")
        
        if 'by_search_engine' in summary:
            print(f"\nğŸ” ê²€ìƒ‰ ì—”ì§„ë³„ ê¸°ì—¬ë„:")
            for engine, stats in summary['by_search_engine'].items():
                engine_name = {
                    'graph_rag': 'GraphRAG',
                    'vector_rag': 'VectorRAG', 
                    'web_search': 'Web Search',
                    'rdb': 'RDB'
                }[engine]
                print(f"   ğŸ”§ {engine_name}:")
                print(f"      - í‰ê·  ì‹œê°„: {stats['avg_time']:.2f}ì´ˆ")
                print(f"      - ì‚¬ìš©ë¥ : {stats['usage_rate']:.1f}%")
                print(f"      - ì „ì²´ ì‹œê°„ ì¤‘: {stats['time_percentage']:.1f}%")
        
        if 'precheck_analysis' in summary:
            precheck = summary['precheck_analysis']
            print(f"\nğŸ” í”„ë¦¬ì²´í¬ ë©”ì»¤ë‹ˆì¦˜ íš¨ê³¼:")
            print(f"   â€¢ í‰ê·  í”„ë¦¬ì²´í¬ ì‹œê°„: {precheck['avg_precheck_time']:.3f}ì´ˆ")
            print(f"   â€¢ ì˜¤ë²„í—¤ë“œ ë¹„ìœ¨: {precheck['precheck_overhead']:.1f}%")
            print(f"   â€¢ ì˜ˆìƒ ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ë°©ì§€: {precheck['estimated_searches_avoided']:.0f}íšŒ")
    
    def save_results(self, results: Dict[str, Any], filename: str = None) -> str:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"/tmp/multihop_benchmark_{timestamp}.json"
        
        # ê²°ê³¼ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        serializable_results = results.copy()
        serializable_results['raw_metrics'] = []
        
        for metric in results['raw_metrics']:
            serializable_results['raw_metrics'].append({
                'query_id': metric.query_id,
                'query_text': metric.query_text,
                'hop_count': metric.hop_count,
                'total_time': metric.total_time,
                'parallel_time': metric.parallel_time,
                'sequential_time': metric.sequential_time,
                'speedup_ratio': metric.sequential_time / metric.parallel_time,
                'step_times': metric.step_times,
                'search_engine_times': metric.search_engine_times,
                'precheck_time': metric.precheck_time,
                'success': metric.success,
                'error_msg': metric.error_msg,
                'timestamp': metric.timestamp
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥: {filename}")
        return filename


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ Multi-Hop RAG ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
    print("ğŸ“ ì‹¤ì œ ì‹œìŠ¤í…œ ì—°ê²° ì—†ì´ í˜„ì‹¤ì ì¸ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n")
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    simulator = MockBenchmarkSimulator()
    results = simulator.run_full_benchmark()
    
    # ìƒì„¸ ìš”ì•½ ì¶œë ¥
    simulator.print_detailed_summary(results['summary'])
    
    # ê²°ê³¼ ì €ì¥
    filename = simulator.save_results(results)
    
    print(f"\nâœ¨ ë²¤ì¹˜ë§ˆí¬ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {filename}")
    print(f"\nğŸ“ˆ ì´ ë°ì´í„°ë¥¼ ë…¼ë¬¸ì— í™œìš©í•˜ì—¬ Multi-Hop RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ì…ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return results, filename


if __name__ == "__main__":
    results, filename = main()