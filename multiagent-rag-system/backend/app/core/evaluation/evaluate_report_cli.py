"""
ë³´ê³ ì„œ í‰ê°€ CLI ë„êµ¬
Report Evaluation CLI Tool

ìƒì„±ëœ ë³´ê³ ì„œë¥¼ í‰ê°€í•˜ëŠ” ëª…ë ¹ì¤„ ë„êµ¬
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Any, Optional

from app.core.evaluation.report_evaluator import ReportEvaluator
from app.core.evaluation.evaluation_models import EvaluationResult


def load_state_from_file(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ì—ì„œ ìƒíƒœ ë¡œë“œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_evaluation_result(result: EvaluationResult, output_path: str):
    """í‰ê°€ ê²°ê³¼ ì €ì¥"""
    result_dict = result.model_dump()

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_dict, f, ensure_ascii=False, indent=2)

    print(f"\ní‰ê°€ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")


def print_evaluation_summary(result: EvaluationResult):
    """í‰ê°€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 80)
    print("ë³´ê³ ì„œ í‰ê°€ ê²°ê³¼")
    print("=" * 80)

    print(f"\ní‰ê°€ ID: {result.evaluation_id}")
    print(f"ë³´ê³ ì„œ ID: {result.report_id}")
    print(f"í‰ê°€ ì‹œê°: {result.evaluation_timestamp}")
    print(f"ì›ë³¸ ì¿¼ë¦¬: {result.query[:100]}...")

    print(f"\n{'â”€' * 80}")
    print("ğŸ“Š ì¢…í•© ì ìˆ˜")
    print(f"{'â”€' * 80}")
    print(f"  ì¢…í•© ì ìˆ˜: {result.overall_score:.2f}/10.0")
    print(f"  ë“±ê¸‰: {result.grade}")

    print(f"\n{'â”€' * 80}")
    print("âœ… ì‘ì—… ì„±ê³µë¥ ")
    print(f"{'â”€' * 80}")
    print(f"  ì„±ê³µ ìˆ˜ì¤€: {result.task_success.success_level.value}")
    print(f"  ì„±ê³µë¥ : {result.task_success.success_rate:.2%}")
    print(f"  ì™„ì„±ë„: {result.task_success.completion_percentage:.1f}%")
    if result.task_success.missing_requirements:
        print(f"  ëˆ„ë½ ìš”êµ¬ì‚¬í•­: {', '.join(result.task_success.missing_requirements[:3])}")

    print(f"\n{'â”€' * 80}")
    print("ğŸ“ ì¶œë ¥ í’ˆì§ˆ")
    print(f"{'â”€' * 80}")
    print(f"  ì‚¬ì‹¤ ì •í™•ë„: {result.output_quality.factual_accuracy_score:.1f}/10")
    print(f"  ë…¼ë¦¬ì  ì¼ê´€ì„±: {result.output_quality.logical_coherence_score:.1f}/10")
    print(f"  ìš”êµ¬ì‚¬í•­ ë¶€í•©ë„: {result.output_quality.relevance_score:.1f}/10")
    print(f"  ì „ì²´ í’ˆì§ˆ: {result.output_quality.overall_quality_score:.1f}/10")
    print(f"  ì–¸ì–´ í’ˆì§ˆ: {result.output_quality.language_quality}")

    print(f"\n{'â”€' * 80}")
    print("ğŸ“‹ ì™„ì„±ë„")
    print(f"{'â”€' * 80}")
    print(f"  ì„¹ì…˜ ì™„ì„±ë¥ : {result.completeness.completeness_rate:.2%} "
          f"({result.completeness.required_sections_completed}/{result.completeness.total_required_sections})")
    if result.completeness.missing_sections:
        print(f"  ëˆ„ë½ ì„¹ì…˜: {', '.join(result.completeness.missing_sections[:3])}")
    if result.completeness.incomplete_sections:
        print(f"  ë¶ˆì™„ì „ ì„¹ì…˜: {', '.join(result.completeness.incomplete_sections[:3])}")

    print(f"\n{'â”€' * 80}")
    print("ğŸ” í™˜ê° í˜„ìƒ")
    print(f"{'â”€' * 80}")
    print(f"  í™˜ê° ê°ì§€: {'ì˜ˆ' if result.hallucination.hallucination_detected else 'ì•„ë‹ˆì˜¤'}")
    print(f"  í™˜ê° ê±´ìˆ˜: {result.hallucination.hallucination_count}ê±´")
    print(f"  í™˜ê° ë¹„ìœ¨: {result.hallucination.hallucination_rate:.2%}")
    print(f"  ì‹ ë¢°ë„ ì ìˆ˜: {result.hallucination.confidence_score:.2f}")
    if result.hallucination.hallucination_examples:
        print(f"  ì£¼ìš” ì‚¬ë¡€:")
        for i, example in enumerate(result.hallucination.hallucination_examples[:3], 1):
            print(f"    {i}. {example.get('statement', '')[:50]}...")

    print(f"\n{'â”€' * 80}")
    print("âš¡ íš¨ìœ¨ì„±")
    print(f"{'â”€' * 80}")
    print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {result.efficiency.total_execution_time:.2f}ì´ˆ")
    print(f"  í‰ê·  ë‹¨ê³„ ì‹œê°„: {result.efficiency.average_step_time:.2f}ì´ˆ")
    print(f"  ì´ ë‹¨ê³„ ìˆ˜: {result.efficiency.total_steps}ê°œ")
    print(f"  ì¤‘ë³µ ë‹¨ê³„: {result.efficiency.redundant_steps}ê°œ")
    print(f"  ì´ í† í° ì‚¬ìš©: {result.efficiency.total_tokens_used:,}ê°œ")
    print(f"  ì¶”ì • ë¹„ìš©: ${result.efficiency.estimated_cost:.4f}")
    print(f"  íš¨ìœ¨ì„± ì ìˆ˜: {result.efficiency.efficiency_score:.1f}/10")

    print(f"\n{'â”€' * 80}")
    print("ğŸ“š ì¶œì²˜ í’ˆì§ˆ")
    print(f"{'â”€' * 80}")
    print(f"  ì´ ì¶œì²˜: {result.source_quality.total_sources}ê°œ")
    print(f"  ì‹ ë¢° ì¶œì²˜: {result.source_quality.reliable_sources}ê°œ")
    print(f"  ì¶œì²˜ ë‹¤ì–‘ì„±: {result.source_quality.source_diversity}ê°œ íƒ€ì…")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {result.source_quality.average_source_reliability:.2f}")
    print(f"  ì¸ìš© ì •í™•ë„: {result.source_quality.citation_accuracy:.2%}")
    if result.source_quality.source_types:
        print(f"  ì¶œì²˜ íƒ€ì…: {', '.join(result.source_quality.source_types)}")

    print(f"\n{'â”€' * 80}")
    print("ğŸ“„ ì½˜í…ì¸  ë©”íŠ¸ë¦­")
    print(f"{'â”€' * 80}")
    print(f"  ì´ ë‹¨ì–´ ìˆ˜: {result.content_metrics.total_word_count:,}ë‹¨ì–´")
    print(f"  ì´ ë¬¸ì ìˆ˜: {result.content_metrics.total_char_count:,}ì")
    print(f"  ì„¹ì…˜ ìˆ˜: {result.content_metrics.section_count}ê°œ")
    print(f"  ì°¨íŠ¸ ìˆ˜: {result.content_metrics.chart_count}ê°œ")
    print(f"  í…Œì´ë¸” ìˆ˜: {result.content_metrics.table_count}ê°œ")
    print(f"  ì¸ìš© ìˆ˜: {result.content_metrics.citation_count}ê°œ")
    print(f"  ìš”ì•½ í¬í•¨: {'ì˜ˆ' if result.content_metrics.has_executive_summary else 'ì•„ë‹ˆì˜¤'}")
    print(f"  ë°©ë²•ë¡  í¬í•¨: {'ì˜ˆ' if result.content_metrics.has_methodology else 'ì•„ë‹ˆì˜¤'}")
    print(f"  ê²°ë¡  í¬í•¨: {'ì˜ˆ' if result.content_metrics.has_conclusion else 'ì•„ë‹ˆì˜¤'}")

    print(f"\n{'â”€' * 80}")
    print("ğŸ’ª ê°•ì ")
    print(f"{'â”€' * 80}")
    if result.strengths:
        for i, strength in enumerate(result.strengths, 1):
            print(f"  {i}. {strength}")
    else:
        print("  (ì—†ìŒ)")

    print(f"\n{'â”€' * 80}")
    print("âš ï¸  ì•½ì ")
    print(f"{'â”€' * 80}")
    if result.weaknesses:
        for i, weakness in enumerate(result.weaknesses, 1):
            print(f"  {i}. {weakness}")
    else:
        print("  (ì—†ìŒ)")

    print(f"\n{'â”€' * 80}")
    print("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­")
    print(f"{'â”€' * 80}")
    if result.recommendations:
        for i, rec in enumerate(result.recommendations, 1):
            print(f"  {i}. {rec}")
    else:
        print("  (ì—†ìŒ)")

    print("\n" + "=" * 80)


def main():
    """CLI ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ìƒì„±ëœ ë³´ê³ ì„œë¥¼ í‰ê°€í•©ë‹ˆë‹¤.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ìƒíƒœ íŒŒì¼ë¡œë¶€í„° í‰ê°€
  python -m app.core.evaluation.evaluate_report_cli --state state.json

  # ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ì§ì ‘ ì œê³µ
  python -m app.core.evaluation.evaluate_report_cli --query "ì§ˆë¬¸" --report report.md

  # AI ì‹¬íŒ ì—†ì´ í‰ê°€ (ë¹ ë¦„)
  python -m app.core.evaluation.evaluate_report_cli --state state.json --no-ai-judge

  # í‰ê°€ ê²°ê³¼ ì €ì¥
  python -m app.core.evaluation.evaluate_report_cli --state state.json --output evaluation.json
        """
    )

    # ì…ë ¥ ì˜µì…˜
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        '--state',
        type=str,
        help='StreamingAgentState JSON íŒŒì¼ ê²½ë¡œ'
    )
    input_group.add_argument(
        '--report',
        type=str,
        help='ë³´ê³ ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (--queryì™€ í•¨ê»˜ ì‚¬ìš©)'
    )

    parser.add_argument(
        '--query',
        type=str,
        help='ì›ë³¸ ì§ˆë¬¸/ìš”ì²­ (--report ì‚¬ìš© ì‹œ í•„ìˆ˜)'
    )

    # í‰ê°€ ì˜µì…˜
    parser.add_argument(
        '--no-ai-judge',
        action='store_true',
        help='AI ì‹¬íŒ í‰ê°€ ë¹„í™œì„±í™” (ë¹ ë¥¸ í‰ê°€)'
    )

    parser.add_argument(
        '--ai-model',
        type=str,
        default='gpt-4o-mini',
        help='AI ì‹¬íŒì— ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: gpt-4o-mini)'
    )

    # ê¸°ëŒ€ê°’ ì˜µì…˜
    parser.add_argument(
        '--expected-requirements',
        type=str,
        nargs='+',
        help='ê¸°ëŒ€ ìš”êµ¬ì‚¬í•­ ë¦¬ìŠ¤íŠ¸'
    )

    parser.add_argument(
        '--expected-sections',
        type=str,
        nargs='+',
        help='í•„ìˆ˜ ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸'
    )

    parser.add_argument(
        '--expected-word-count',
        type=int,
        help='ê¸°ëŒ€ ë‹¨ì–´ ìˆ˜'
    )

    # ì¶œë ¥ ì˜µì…˜
    parser.add_argument(
        '--output',
        type=str,
        help='í‰ê°€ ê²°ê³¼ ì €ì¥ ê²½ë¡œ (JSON)'
    )

    parser.add_argument(
        '--summary-only',
        action='store_true',
        help='ìš”ì•½ë§Œ ì¶œë ¥'
    )

    args = parser.parse_args()

    # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
    state = None
    query = None
    report_text = None

    if args.state:
        # ìƒíƒœ íŒŒì¼ì—ì„œ ë¡œë“œ
        print(f"ìƒíƒœ íŒŒì¼ ë¡œë”© ì¤‘: {args.state}")
        state = load_state_from_file(args.state)
        query = state.get('original_query', '')
        report_text = state.get('final_answer', '')

    elif args.report:
        # ë³´ê³ ì„œ íŒŒì¼ì—ì„œ ë¡œë“œ
        if not args.query:
            parser.error("--report ì‚¬ìš© ì‹œ --queryê°€ í•„ìš”í•©ë‹ˆë‹¤")

        print(f"ë³´ê³ ì„œ íŒŒì¼ ë¡œë”© ì¤‘: {args.report}")
        with open(args.report, 'r', encoding='utf-8') as f:
            report_text = f.read()

        query = args.query
        # ìµœì†Œ ìƒíƒœ ìƒì„±
        state = {
            'original_query': query,
            'final_answer': report_text,
            'step_results': [],
            'execution_log': [],
            'metadata': {}
        }

    # í‰ê°€ê¸° ì´ˆê¸°í™”
    print(f"\ní‰ê°€ê¸° ì´ˆê¸°í™” ì¤‘...")
    print(f"  AI ì‹¬íŒ: {'ë¹„í™œì„±í™”' if args.no_ai_judge else 'í™œì„±í™”'}")
    if not args.no_ai_judge:
        print(f"  AI ëª¨ë¸: {args.ai_model}")

    evaluator = ReportEvaluator(
        use_ai_judge=not args.no_ai_judge,
        ai_model=args.ai_model
    )

    # í‰ê°€ ì‹¤í–‰
    print(f"\ní‰ê°€ ì‹œì‘...")
    try:
        result = evaluator.evaluate_report(
            query=query,
            state=state,
            report_text=report_text,
            expected_requirements=args.expected_requirements,
            expected_sections=args.expected_sections,
            expected_word_count=args.expected_word_count
        )

        # ê²°ê³¼ ì¶œë ¥
        print_evaluation_summary(result)

        # ê²°ê³¼ ì €ì¥
        if args.output:
            save_evaluation_result(result, args.output)

        print(f"\nâœ… í‰ê°€ ì™„ë£Œ!")
        return 0

    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì‹¤íŒ¨: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
