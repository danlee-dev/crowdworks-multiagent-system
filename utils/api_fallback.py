# api_fallback.py
"""
3ê°œ API í‚¤ ìˆœì°¨ ì‹œë„ ë° fallback ë¡œì§ì„ í†µí•© ê´€ë¦¬í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
ëª¨ë“  í”„ë¡œì íŠ¸ íŒŒì¼ì—ì„œ ì´ í´ë˜ìŠ¤ë¥¼ importí•´ì„œ ì‚¬ìš©
"""
import os
from typing import Optional, Any, List, Union
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
import google.generativeai as genai
from openai import OpenAI


class UnifiedAPIManager:
    """
    í†µí•© API í‚¤ ê´€ë¦¬ ë° fallback ì‹œìŠ¤í…œ
    GEMINI_KEY_1 -> GEMINI_KEY_2 -> GOOGLE_API_KEY -> OPENAI_API_KEY ìˆœìœ¼ë¡œ ì‹œë„
    """
    
    def __init__(self):
        # ëª¨ë“  API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        self.gemini_key_1 = os.getenv("GEMINI_API_KEY_1")
        self.gemini_key_2 = os.getenv("GEMINI_API_KEY_2") 
        self.google_api_key = os.getenv("GOOGLE_API_KEY")
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤ ìˆœì„œ ì •ì˜
        self.api_keys = [
            ("GEMINI_1", self.gemini_key_1),
            ("GEMINI_2", self.gemini_key_2),
            ("GOOGLE", self.google_api_key),
            ("OPENAI", self.openai_api_key)
        ]
        
        # ë¡œê·¸ë¥¼ ìœ„í•œ ì„¤ì •
        self.last_successful_api = None
        self.api_usage_count = {
            "GEMINI_1": 0,
            "GEMINI_2": 0, 
            "GOOGLE": 0,
            "OPENAI": 0
        }
    
    def get_available_apis(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ API í‚¤ ëª©ë¡ ë°˜í™˜"""
        return [name for name, key in self.api_keys if key]
    
    def create_langchain_model(self, model_name: str = "gemini-2.5-flash", **kwargs) -> Any:
        """
        LangChain ëª¨ë¸ì„ 3ê°œ í‚¤ + OpenAI fallbackìœ¼ë¡œ ìƒì„±
        """
        # Gemini/Google API í‚¤ë“¤ ì‹œë„
        for api_name, api_key in self.api_keys[:3]:  # ì²˜ìŒ 3ê°œëŠ” Google ê³„ì—´
            if api_key:
                try:
                    model = ChatGoogleGenerativeAI(
                        model=model_name,
                        google_api_key=api_key,
                        **kwargs
                    )
                    self.last_successful_api = api_name
                    self.api_usage_count[api_name] += 1
                    print(f"âœ… {api_name} APIë¡œ LangChain ëª¨ë¸ ìƒì„± ì„±ê³µ: {model_name}")
                    return model
                except Exception as e:
                    print(f"âŒ {api_name} API ì‹¤íŒ¨: {e}")
                    continue
        
        # OpenAI fallback
        if self.openai_api_key:
            try:
                # Gemini ëª¨ë¸ëª…ì„ OpenAI ëª¨ë¸ëª…ìœ¼ë¡œ ë§¤í•‘
                openai_model_map = {
                    "gemini-2.5-pro": "gpt-4o",
                    "gemini-2.5-flash": "gpt-4o-mini",
                    "gemini-2.5-flash-lite": "gpt-3.5-turbo",
                    "gemini-1.5-pro": "gpt-4o"
                }
                openai_model = openai_model_map.get(model_name, "gpt-4o-mini")
                
                model = ChatOpenAI(
                    model=openai_model,
                    openai_api_key=self.openai_api_key,
                    **kwargs
                )
                self.last_successful_api = "OPENAI"
                self.api_usage_count["OPENAI"] += 1
                print(f"âœ… OpenAI fallback ì„±ê³µ: {openai_model} (ì›ë˜ ìš”ì²­: {model_name})")
                return model
            except Exception as e:
                print(f"âŒ OpenAI fallback ì‹¤íŒ¨: {e}")
        
        raise Exception("ğŸš¨ ëª¨ë“  API í‚¤ ì‹¤íŒ¨: Gemini 3ê°œ + OpenAI ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€")
    
    def invoke_with_fallback(self, prompt: str, model_name: str = "gemini-2.5-flash", **kwargs) -> str:
        """
        í”„ë¡¬í”„íŠ¸ë¥¼ 3ê°œ í‚¤ + OpenAI fallbackìœ¼ë¡œ ì‹¤í–‰
        """
        # Google ê³„ì—´ APIë“¤ ì‹œë„
        for api_name, api_key in self.api_keys[:3]:
            if api_key:
                try:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel(model_name)
                    response = model.generate_content(prompt)
                    
                    self.last_successful_api = api_name
                    self.api_usage_count[api_name] += 1
                    print(f"âœ… {api_name} API ì§ì ‘ í˜¸ì¶œ ì„±ê³µ: {model_name}")
                    return response.text
                except Exception as e:
                    print(f"âŒ {api_name} API ì‹¤íŒ¨: {e}")
                    continue
        
        # OpenAI fallback
        if self.openai_api_key:
            try:
                client = OpenAI(api_key=self.openai_api_key)
                
                # Gemini ëª¨ë¸ëª…ì„ OpenAIë¡œ ë³€í™˜
                openai_model_map = {
                    "gemini-2.5-pro": "gpt-4o",
                    "gemini-2.5-flash": "gpt-4o-mini", 
                    "gemini-2.5-flash-lite": "gpt-3.5-turbo",
                    "gemini-1.5-pro": "gpt-4o"
                }
                openai_model = openai_model_map.get(model_name, "gpt-4o-mini")
                
                response = client.chat.completions.create(
                    model=openai_model,
                    messages=[{"role": "user", "content": prompt}],
                    **kwargs
                )
                
                self.last_successful_api = "OPENAI"
                self.api_usage_count["OPENAI"] += 1
                print(f"âœ… OpenAI fallback ì„±ê³µ: {openai_model}")
                return response.choices[0].message.content
            except Exception as e:
                print(f"âŒ OpenAI fallback ì‹¤íŒ¨: {e}")
        
        raise Exception("ğŸš¨ ëª¨ë“  API í‚¤ ì‹¤íŒ¨: Gemini 3ê°œ + OpenAI ëª¨ë‘ ì‚¬ìš© ë¶ˆê°€")
    
    def get_status_report(self) -> dict:
        """API ì‚¬ìš© í˜„í™© ë¦¬í¬íŠ¸"""
        return {
            "available_apis": self.get_available_apis(),
            "last_successful": self.last_successful_api,
            "usage_count": self.api_usage_count,
            "total_requests": sum(self.api_usage_count.values())
        }
    
    def test_all_apis(self) -> dict:
        """ëª¨ë“  API í‚¤ í…ŒìŠ¤íŠ¸"""
        results = {}
        test_prompt = "Hello, test message"
        
        for api_name, api_key in self.api_keys:
            if not api_key:
                results[api_name] = {"status": "missing", "error": "API key not found"}
                continue
                
            try:
                if api_name == "OPENAI":
                    client = OpenAI(api_key=api_key)
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": test_prompt}],
                        max_tokens=10
                    )
                    results[api_name] = {"status": "success", "response_length": len(response.choices[0].message.content)}
                else:
                    genai.configure(api_key=api_key)
                    model = genai.GenerativeModel("gemini-1.5-flash")
                    response = model.generate_content(test_prompt)
                    results[api_name] = {"status": "success", "response_length": len(response.text)}
                    
            except Exception as e:
                results[api_name] = {"status": "error", "error": str(e)}
        
        return results


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹±ê¸€í†¤ íŒ¨í„´)
api_manager = UnifiedAPIManager()

# í¸ì˜ í•¨ìˆ˜ë“¤
def create_model(model_name: str = "gemini-2.5-flash", **kwargs):
    """ë¹ ë¥¸ ëª¨ë¸ ìƒì„±"""
    return api_manager.create_langchain_model(model_name, **kwargs)

def invoke_prompt(prompt: str, model_name: str = "gemini-2.5-flash", **kwargs) -> str:
    """ë¹ ë¥¸ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰"""
    return api_manager.invoke_with_fallback(prompt, model_name, **kwargs)

def get_api_status() -> dict:
    """API ìƒíƒœ í™•ì¸"""
    return api_manager.get_status_report()

def test_apis() -> dict:
    """ëª¨ë“  API í…ŒìŠ¤íŠ¸"""
    return api_manager.test_all_apis()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("ğŸš€ API Fallback Manager í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    print("\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ API:")
    available = api_manager.get_available_apis()
    print(f"  {available}")
    
    print("\nğŸ§ª API í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    test_results = test_apis()
    for api_name, result in test_results.items():
        status_icon = "âœ…" if result["status"] == "success" else "âŒ"
        print(f"  {status_icon} {api_name}: {result['status']}")
        if result["status"] == "error":
            print(f"    ì˜¤ë¥˜: {result['error']}")
    
    print("\nğŸ’¬ ê°„ë‹¨ í…ŒìŠ¤íŠ¸:")
    try:
        response = invoke_prompt("ì•ˆë…•í•˜ì„¸ìš”", "gemini-2.5-flash")
        print(f"  ì‘ë‹µ: {response[:100]}...")
        print(f"\nğŸ“ˆ ì‚¬ìš© í˜„í™©: {get_api_status()}")
    except Exception as e:
        print(f"  ì‹¤íŒ¨: {e}")