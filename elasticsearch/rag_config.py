"""
RAG ê²€ìƒ‰ ì—”ì§„ ì„¤ì • íŒŒì¼
ë…¼ë¬¸ "Searching for Best Practices in Retrieval-Augmented Generation" ê¸°ë°˜
"""

import os
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class RAGConfig:
    """RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    
    # ========== ê¸°ë³¸ ì„¤ì • ==========
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    COHERE_API_KEY = os.getenv("COHERE_API_KEY")
    ELASTICSEARCH_HOST = "http://localhost:9200"
    ELASTICSEARCH_USER = os.getenv("ELASTICSEARCH_USER")
    ELASTICSEARCH_PASSWORD = os.getenv("ELASTICSEARCH_PASSWORD")
    
    # ========== í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„¤ì • (ë…¼ë¬¸ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤) ==========
    
    # ë…¼ë¬¸ ê¶Œì¥ í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ (Table 8 ê¸°ì¤€)
    HYBRID_ALPHA = 0.5  # BM25 30% + Dense 70%
    
    # ëŒ€ì•ˆ ê°€ì¤‘ì¹˜ë“¤ (ë„ë©”ì¸ë³„ íŠœë‹ ê°€ëŠ¥)
    ALPHA_BALANCED = 0.5      # ê· í˜•í˜•  
    ALPHA_DENSE_HEAVY = 0.1   # Dense ì¤‘ì‹¬ (90%)
    ALPHA_SPARSE_HEAVY = 0.7  # Sparse ì¤‘ì‹¬ (70%)
    
    # ========== ê²€ìƒ‰ ë‹¨ê³„ë³„ ì„¤ì • ==========
    
    # 1. ì´ˆê¸° ê²€ìƒ‰ (Retrieval)
    TOP_K_RETRIEVAL = 100     # ë…¼ë¬¸ ê¶Œì¥: ì¶©ë¶„í•œ í›„ë³´ í™•ë³´
    KNN_NUM_CANDIDATES = 200  # Dense retrieval í›„ë³´
    
    # 2. ì¬ìˆœìœ„í™” (Reranking) 
    TOP_K_RERANK = 100        # 50ê°œ ìµœì¢… ê²°ê³¼ë¥¼ ìœ„í•œ ì¬ìˆœìœ„í™” í›„ë³´
    USE_RERANKING = True
    
    # 3. ìµœì¢… ê²°ê³¼
    TOP_K_FINAL = 50          # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ê²°ê³¼
    
    # ========== ì¿¼ë¦¬ ê°œì„  ì„¤ì • ==========
    
    # HyDE ì„¤ì • (ë…¼ë¬¸ Table 7 ê¸°ì¤€)
    USE_HYDE = False  # HyDE ë¹„í™œì„±í™”
    HYDE_MAX_TOKENS = 500  # ì¶©ë¶„í•œ ê¸¸ì´ì˜ ê°œì„  ì¿¼ë¦¬ ìƒì„±
    HYDE_TEMPERATURE = 0.3
    HYDE_MODEL = "gpt-4o-mini"  # ì‹¤ì œë¡œëŠ” ë” í° ëª¨ë¸ ê¶Œì¥
    
    # Query Rewriting
    USE_QUERY_REWRITING = False  # ë…¼ë¬¸ì—ì„œ íš¨ê³¼ ì œí•œì 
    QUERY_REWRITE_MAX_TOKENS = 100
    
    # ========== ì„ë² ë”© ëª¨ë¸ ì„¤ì • ==========
    
    # ë…¼ë¬¸ ê¶Œì¥: LLM-Embedder (ì„±ëŠ¥ vs í¬ê¸° ê· í˜•)
    EMBEDDING_MODEL = "text-embedding-ada-002"  # OpenAI
    # ì‹¤ì œ ì‚¬ìš©ì‹œ ê¶Œì¥: "LLM-Embedder" ë˜ëŠ” "BAAI/bge-large-en"
    
    EMBEDDING_DIMENSION = 1536  # OpenAI ada-002
    
    # ========== ì¬ìˆœìœ„í™” ëª¨ë¸ ì„¤ì • ==========
    
    # ë…¼ë¬¸ Table 9 ê¸°ì¤€ ê¶Œì¥ ëª¨ë¸ë“¤
    RERANKER_OPTIONS = {
        "balanced": "monoT5",      # ì„±ëŠ¥ vs ì†ë„ ê· í˜• (ë…¼ë¬¸ ê¶Œì¥)
        "performance": "RankLLaMA", # ìµœê³  ì„±ëŠ¥
        "speed": "TILDEv2"         # ìµœê³  ì†ë„ (0.02ì´ˆ/ì¿¼ë¦¬)
    }
    
    DEFAULT_RERANKER = "balanced"
    
    # ========== ë¬¸ì„œ ì²˜ë¦¬ ì„¤ì • ==========
    
    # ì²­í‚¹ ì „ëµ (ë…¼ë¬¸ Table 4 ê¸°ì¤€)
    CHUNKING_STRATEGY = "small2big"  # ë…¼ë¬¸ ê¶Œì¥
    # ëŒ€ì•ˆ: "sliding_window", "fixed_size"
    
    CHUNK_SIZE = 512          # í† í° ë‹¨ìœ„
    CHUNK_OVERLAP = 50        # ê²¹ì¹¨ í¬ê¸°
    
    # ìš”ì•½ ì„¤ì • (ë…¼ë¬¸ Table 10 ê¸°ì¤€)
    USE_SUMMARIZATION = False
    SUMMARIZATION_METHOD = "recomp_abstractive"  # ë…¼ë¬¸ ìµœê³  ì„±ëŠ¥
    SUMMARIZATION_RATIO = 0.4  # ì›ë³¸ì˜ 40%ë¡œ ì••ì¶•
    SUMMARIZATION_MAX_TOKENS = 200
    
    # ========== ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ==========
    
    # ë…¼ë¬¸ Table 5 ê¸°ì¤€ - Milvus ê¶Œì¥
    VECTOR_DB = "elasticsearch"  # í˜„ì¬ ì‚¬ìš©ì¤‘
    # ê¶Œì¥ ì—…ê·¸ë ˆì´ë“œ: "milvus" (ëª¨ë“  ê¸°ì¤€ ì¶©ì¡±)
    
    # ========== í‰ê°€ ì„¤ì • ==========
    
    # ë…¼ë¬¸ ê¶Œì¥ í‰ê°€ ì§€í‘œë“¤
    EVALUATION_METRICS = [
        "faithfulness",      # ì‚¬ì‹¤ ì¼ì¹˜ì„±
        "context_relevancy", # ë¬¸ë§¥ ê´€ë ¨ì„±  
        "answer_relevancy",  # ë‹µë³€ ê´€ë ¨ì„±
        "answer_correctness" # ë‹µë³€ ì •í™•ì„±
    ]
    
    # ========== ì„±ëŠ¥ ìµœì í™” ì„¤ì • ==========
    
    # ë³‘ë ¬ ì²˜ë¦¬
    MAX_WORKERS = 4
    
    # ìºì‹±
    USE_EMBEDDING_CACHE = True
    CACHE_SIZE = 1000
    
    # ë°°ì¹˜ ì²˜ë¦¬
    BATCH_SIZE = 32
    
    # ========== ë„ë©”ì¸ë³„ ì„¤ì • ==========
    
    # ë†ì—… ë„ë©”ì¸ íŠ¹í™” (í˜„ì¬ ì‹œìŠ¤í…œ)
    DOMAIN_KEYWORDS = [
        "ë†ì—…", "ë†ì‚°ë¬¼", "ì‹í’ˆ", "ìˆ˜ì¶œ", "ìƒì‚°", 
        "í†µê³„", "í˜„í™©", "í’ˆëª©", "ì‹œì¥", "ê°€ê²©"
    ]
    
    DOMAIN_BOOST = 0.5  # ë„ë©”ì¸ í‚¤ì›Œë“œ ë¶€ìŠ¤íŠ¸
    
    # ========== ì‘ë‹µ ìƒì„± ì„¤ì • ==========
    
    # LLM ì„¤ì •
    GENERATOR_MODEL = "gpt-3.5-turbo"  # ì‹¤ì œë¡œëŠ” ë” í° ëª¨ë¸ ê¶Œì¥
    GENERATOR_MAX_TOKENS = 500
    GENERATOR_TEMPERATURE = 0.3
    
    # RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    RAG_PROMPT_TEMPLATE = """
ë‹¤ìŒ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ê²€ìƒ‰ëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ê²€ìƒ‰ëœ ë¬¸ì„œë“¤:
{retrieved_documents}

ë‹µë³€:"""

    # ========== ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ==========
    
    LOG_LEVEL = "INFO"
    LOG_FILE = "rag_search.log"
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    TRACK_PERFORMANCE = True
    PERFORMANCE_LOG_FILE = "rag_performance.log"
    
    # ========== ì‹¤í—˜ ì„¤ì • ==========
    
    # A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì •ë“¤
    EXPERIMENT_CONFIGS = {
        "baseline": {
            "hybrid_alpha": 0.0,  # Dense only
            "use_hyde": False,
            "use_reranking": False,
            "use_summarization": False
        },
        "hybrid_only": {
            "hybrid_alpha": 0.3,
            "use_hyde": False, 
            "use_reranking": False,
            "use_summarization": False
        },
        "full_rag": {
            "hybrid_alpha": 0.3,
            "use_hyde": True,
            "use_reranking": True,
            "use_summarization": True
        }
    }


# ========== ë…¼ë¬¸ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ìš”ì•½ ==========

class PaperBestPractices:
    """ë…¼ë¬¸ì—ì„œ ê¶Œì¥í•˜ëŠ” ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ìš”ì•½"""
    
    RECOMMENDATIONS = {
        "chunking": {
            "best": "small2big",
            "reason": "ì‘ì€ ì²­í¬ë¡œ ê²€ìƒ‰, í° ì²­í¬ë¡œ ìƒì„± - ê· í˜•ì  ì„±ëŠ¥"
        },
        "embedding": {
            "best": "LLM-Embedder",
            "reason": "ì„±ëŠ¥ ëŒ€ë¹„ í¬ê¸° ìµœì í™”, BAAI/bge-large-enì˜ 1/3 í¬ê¸°"
        },
        "vector_db": {
            "best": "Milvus", 
            "reason": "ëª¨ë“  í‰ê°€ ê¸°ì¤€ ì¶©ì¡± (ì¸ë±ìŠ¤, ìŠ¤ì¼€ì¼, í•˜ì´ë¸Œë¦¬ë“œ, í´ë¼ìš°ë“œ)"
        },
        "retrieval": {
            "best": "HyDE + Hybrid Search (Î±=0.3)",
            "reason": "ìµœê³  ì„±ëŠ¥, ì ë‹¹í•œ ë ˆì´í„´ì‹œ"
        },
        "reranking": {
            "balanced": "monoT5 (4.5ì´ˆ/ì¿¼ë¦¬)",
            "performance": "RankLLaMA (82.4ì´ˆ/ì¿¼ë¦¬)", 
            "speed": "TILDEv2 (0.02ì´ˆ/ì¿¼ë¦¬)"
        },
        "summarization": {
            "best": "Recomp (Abstractive)",
            "reason": "ìµœê³  F1 ìŠ¤ì½”ì–´ (33.68), ì ì ˆí•œ ì••ì¶•ë¥ "
        },
        "hybrid_weight": {
            "best": "Î± = 0.3",
            "reason": "BM25 30% + Dense 70% = ìµœì  ì„±ëŠ¥"
        }
    }
    
    PERFORMANCE_COMPARISON = {
        "TREC_DL_2019": {
            "BM25_only": {"mAP": 30.13, "nDCG@10": 50.58},
            "LLM_Embedder": {"mAP": 44.66, "nDCG@10": 70.20},
            "Hybrid_Search": {"mAP": 47.14, "nDCG@10": 72.50},
            "HyDE_Hybrid": {"mAP": 52.13, "nDCG@10": 73.34}
        }
    }


def get_config_for_scenario(scenario: str) -> dict:
    """ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ì„¤ì • ë°˜í™˜"""
    
    configs = {
        "production_balanced": {
            "hybrid_alpha": RAGConfig.HYBRID_ALPHA,
            "use_hyde": True,
            "use_reranking": True, 
            "reranker": "monoT5",
            "use_summarization": True,
            "top_k_final": 5
        },
        "production_fast": {
            "hybrid_alpha": RAGConfig.HYBRID_ALPHA,
            "use_hyde": False,  # ì†ë„ ìš°ì„ 
            "use_reranking": True,
            "reranker": "TILDEv2",
            "use_summarization": False,
            "top_k_final": 3
        },
        "research_best": {
            "hybrid_alpha": RAGConfig.HYBRID_ALPHA,
            "use_hyde": True,
            "use_reranking": True,
            "reranker": "RankLLaMA", 
            "use_summarization": True,
            "top_k_final": 10
        },
        "demo": {
            "hybrid_alpha": RAGConfig.HYBRID_ALPHA,
            "use_hyde": True,
            "use_reranking": False,  # ë‹¨ìˆœí™”
            "use_summarization": True,
            "top_k_final": 3
        }
    }
    
    return configs.get(scenario, configs["production_balanced"])


if __name__ == "__main__":
    # ì„¤ì • í™•ì¸ ë° í…ŒìŠ¤íŠ¸
    print("ğŸ“‹ RAG ê²€ìƒ‰ ì—”ì§„ ì„¤ì •")
    print("=" * 40)
    print(f"í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜: Î± = {RAGConfig.HYBRID_ALPHA}")
    print(f"ìµœì¢… ê²°ê³¼ ìˆ˜: {RAGConfig.TOP_K_FINAL}")
    print(f"HyDE ì‚¬ìš©: {RAGConfig.USE_HYDE}")
    print(f"ì¬ìˆœìœ„í™” ì‚¬ìš©: {RAGConfig.USE_RERANKING}")
    print(f"ìš”ì•½ ì‚¬ìš©: {RAGConfig.USE_SUMMARIZATION}")
    
    print("\nğŸ† ë…¼ë¬¸ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:")
    for component, recommendation in PaperBestPractices.RECOMMENDATIONS.items():
        print(f"  {component}: {recommendation['best']}")
        print(f"    ì´ìœ : {recommendation['reason']}") 