from langchain_core.tools import tool
import re
import sys
import asyncio
import json
import concurrent.futures
import os
from typing import Dict, List, Any, Optional, AsyncGenerator, Tuple
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

# arxiv_search í•¨ìˆ˜ì˜ ì‹¤ì œ ë¡œì§ì„ ì§ì ‘ êµ¬í˜„
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET

from langchain.prompts import PromptTemplate
from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

from ..models.models import SearchResult
from ...services.search.search_tools import (
    debug_web_search,
    rdb_search,
    vector_db_search,
    graph_db_search,
    scrape_and_extract_content,
    arxiv_search,
)
from ...utils.session_logger import get_session_logger, set_current_session, session_print

# ì „ì—­ ThreadPoolExecutor ìƒì„± (ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
_global_executor = ThreadPoolExecutor(max_workers=8, thread_name_prefix="search_worker")

# ì¶”ê°€: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
PERSONA_PROMPTS = {}
try:
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_dir, "prompts", "persona_prompts.json")
    with open(file_path, "r", encoding="utf-8") as f:
        PERSONA_PROMPTS = json.load(f)
    print(f"ProcessorAgent: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ ({len(PERSONA_PROMPTS)}ê°œ).")
except Exception as e:
    print(f"ProcessorAgent: í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ - {e}")


class DataGathererAgent:
    """ë°ì´í„° ìˆ˜ì§‘ ë° ì¿¼ë¦¬ ìµœì í™” ì „ë‹´ Agent"""

    def __init__(self, model: str = "gemini-2.5-flash-lite", temperature: float = 0):
        # Gemini ëª¨ë¸ (ê¸°ë³¸)
        self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature)

        # OpenAI fallback ëª¨ë¸ë“¤
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if self.openai_api_key:
            self.llm_openai_mini = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            self.llm_openai_4o = ChatOpenAI(
                model="gpt-4o",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            print("OpenAI fallback ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.llm_openai_mini = None
            self.llm_openai_4o = None
            print("ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ. Gemini ì˜¤ë¥˜ ì‹œ fallback ë¶ˆê°€")

        # ë„êµ¬ ë§¤í•‘ ì„¤ì • - ì´ë¦„ í†µì¼
        self.tool_mapping = {
            "web_search": self._web_search,
            "vector_db_search": self._vector_db_search,
            "graph_db_search": self._graph_db_search,
            "arxiv_search": self._arxiv_search,
            "rdb_search": self._rdb_search,
            "scrape_content": self._scrape_content,
        }

    async def _invoke_with_fallback(self, prompt: str, use_4o: bool = False) -> str:
        """Gemini API ì‹¤íŒ¨ ì‹œ OpenAIë¡œ fallbackí•˜ëŠ” ë©”ì„œë“œ"""
        try:
            # 1ì°¨ ì‹œë„: Gemini
            print("  - Gemini API ì‹œë„ ì¤‘...")
            response = await self.llm.ainvoke(prompt)
            return response.content.strip()
        except Exception as e:
            error_msg = str(e)
            print(f"  - Gemini API ì‹¤íŒ¨: {error_msg}")

            # Rate limit ë˜ëŠ” quota ì˜¤ë¥˜ ì²´í¬
            if any(keyword in error_msg.lower() for keyword in ['429', 'quota', 'rate limit', 'exceeded']):
                print("  - Rate limit ê°ì§€, OpenAIë¡œ fallback ì‹œë„...")

                if self.llm_openai_mini is None:
                    print("  - OpenAI API í‚¤ê°€ ì—†ì–´ fallback ë¶ˆê°€")
                    raise e

                try:
                    # 2ì°¨ ì‹œë„: OpenAI
                    fallback_model = self.llm_openai_4o if use_4o else self.llm_openai_mini
                    model_name = "gpt-4o" if use_4o else "gpt-4o-mini"
                    print(f"  - {model_name} API ì‹œë„ ì¤‘...")
                    response = await fallback_model.ainvoke(prompt)
                    print(f"  - {model_name} API ì„±ê³µ!")
                    return response.content.strip()
                except Exception as openai_error:
                    print(f"  - OpenAI APIë„ ì‹¤íŒ¨: {openai_error}")
                    raise openai_error
            else:
                # Rate limitì´ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ë°œìƒ
                raise e

    async def _optimize_query_for_tool(self, query: str, tool: str) -> str:
        """ê° ë„êµ¬ì˜ íŠ¹ì„±ì— ë§ê²Œ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""

        # RDBì™€ GraphDBëŠ” í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì— ë” íš¨ê³¼ì ì…ë‹ˆë‹¤.
        if tool == "rdb_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘: '{query}'")
            prompt = f"""
        ë„ˆëŠ” PostgreSQL RDBì— ì§ˆì˜í•  'ìš”ì•½ ê²€ìƒ‰ë¬¸'ì„ ë§Œë“œëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë‹¤ìŒ ê·œì¹™ìœ¼ë¡œ 1ì¤„ì§œë¦¬ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•´ë¼. (ì¶”ê°€ ì„¤ëª…/ë”°ì˜´í‘œ/ì½”ë“œë¸”ë¡ ê¸ˆì§€)

        [ê·œì¹™]
        1) í¬í•¨ í•­ëª©: ì§€ì—­, í’ˆëª©(ë“¤), ì˜ë„(ê°€ê²©|ì‹œì„¸|ì˜ì–‘|ì¹¼ë¡œë¦¬|ë¹„íƒ€ë¯¼|ë¬´ì—­|ìˆ˜ì¶œ|ìˆ˜ì…|ì‹œì¥í˜„í™© ë“±), ê¸°ê°„.
        2) ì§€ì—­ ì •ê·œí™”:
        - "êµ­ë‚´", "ìš°ë¦¬ë‚˜ë¼", "í•œêµ­" â†’ "ëŒ€í•œë¯¼êµ­".
        - ì§€ì—­ ë¯¸ì–¸ê¸‰ ì‹œ "ëŒ€í•œë¯¼êµ­"ì„ ê¸°ë³¸ìœ¼ë¡œ ë„£ëŠ”ë‹¤.
        3) ê¸°ê°„ ì •ê·œí™”:
        - ì˜¤ëŠ˜/í˜„ì¬ â†’ today
        - ì´ë²ˆì£¼ â†’ this_week
        - ì´ë²ˆë‹¬/ë‹¹ì›”/ìµœê·¼ 1ë‹¬ â†’ this_month ë˜ëŠ” recent(ëª¨í˜¸í•˜ë©´ recent)
        - íŠ¹ì • ì—°ë„/ë‚ ì§œê°€ ìˆìœ¼ë©´ ìˆ«ìë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨ (ì˜ˆ: 2023ë…„ â†’ 2023)
        4) í’ˆëª©ì€ ì§ˆë¬¸ì— ë‚˜ì˜¨ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì ë˜ ë¶ˆí•„ìš”í•œ ì–´ë¯¸/ì¡°ì‚¬ëŠ” ì œê±°(ì˜ˆ: "êµ­ë‚´ì‚° ì‚¬ê³¼" â†’ "ì‚¬ê³¼").
        5) ì˜ë„ëŠ” ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•œ ê²ƒì„ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´(ì˜ˆ: ê°€ê²©Â·ì‹œì„¸, ì˜ì–‘, ì¹¼ë¡œë¦¬, ë¹„íƒ€ë¯¼C, ìˆ˜ì¶œì•¡, ì„±ì¥ë¥  ë“±).
        6) ì¶œë ¥ í˜•ì‹(ë”± í•œ ì¤„):
        "ì§€ì—­=..., í’ˆëª©=..., ì˜ë„=..., ê¸°ê°„=..."

        [ì˜ˆì‹œ]
        - ì§ˆë¬¸: êµ­ë‚´ ê°ê·¤ì˜ ìµœì‹  ê°€ê²©ê³¼ ì˜ì–‘ì„±ë¶„ ì•Œë ¤ì¤˜
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ê°ê·¤, ì˜ë„=ê°€ê²©Â·ì‹œì„¸Â·ì˜ì–‘, ê¸°ê°„=today

        - ì§ˆë¬¸: ìš°ë¦¬ë‚˜ë¼ íŠ¹ì‚°í’ˆì¸ ì „ë³µì˜ ìœ í†µ êµ¬ì¡°ê°€ ê¶ê¸ˆí•´
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ì „ë³µ, ì˜ë„=ìœ í†µÂ·ì‹œì¥í˜„í™©, ê¸°ê°„=recent

        - ì§ˆë¬¸: ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì•Œë ¤ì¤˜
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ, ì˜ë„=ì‹œì¥í˜„í™©, ê¸°ê°„=recent

        - ì§ˆë¬¸: 2023ë…„ ë§Œë‘ì˜ ì£¼ìš” ìˆ˜ì¶œêµ­ë³„ ìˆ˜ì¶œì•¡ê³¼ ì„±ì¥ë¥ 
        - ì¶œë ¥: ì§€ì—­=ëŒ€í•œë¯¼êµ­, í’ˆëª©=ë§Œë‘, ì˜ë„=ìˆ˜ì¶œì•¡Â·ì„±ì¥ë¥ , ê¸°ê°„=2023

        ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
        ì¶œë ¥:
        """
            try:
                response_content = await self._invoke_with_fallback(prompt)
                optimized_query = response_content.strip()
                print(f"  - ìµœì í™”ëœ í‚¤ì›Œë“œ: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        elif tool == "graph_db_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘: '{query}'")

            # ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ê¸°ì¤€: (í’ˆëª©)-[:isFrom]->(Origin), (í’ˆëª©)-[:hasNutrient]->(Nutrient)
            # ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì •ê·œ ë¬¸êµ¬:
            #   - "<í’ˆëª©>ì˜ ì›ì‚°ì§€"            -> isFrom
            #   - "<í’ˆëª©>ì˜ ì˜ì–‘ì†Œ"            -> hasNutrient
            #   - "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"     -> isFrom + region filter
            #   - "(í™œì–´|ì„ ì–´|ëƒ‰ë™|ê±´ì–´) <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€" -> isFrom + fishState filter
            prompt = f"""
        ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„, Neo4j ê·¸ë˜í”„ ê²€ìƒ‰ì— ë°”ë¡œ ë„£ì„ ìˆ˜ ìˆëŠ” **ì •ê·œ ì§ˆì˜ ë¬¸êµ¬**ë¡œ ë³€í™˜í•˜ì„¸ìš”.
        ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ:
        - í’ˆëª© ë…¸ë“œ ë¼ë²¨: ë†ì‚°ë¬¼ | ìˆ˜ì‚°ë¬¼ | ì¶•ì‚°ë¬¼  (ê³µí†µ ì†ì„±: product)
        - ì›ì‚°ì§€ ë…¸ë“œ ë¼ë²¨: Origin (ì†ì„±: city, region)
        - ê´€ê³„: (í’ˆëª©)-[:isFrom]->(Origin), (í’ˆëª©)-[:hasNutrient]->(Nutrient)
        - ìˆ˜ì‚°ë¬¼ ìƒíƒœ: fishState âˆˆ {{í™œì–´, ì„ ì–´, ëƒ‰ë™, ê±´ì–´}}

        ê·œì¹™(ë°˜ë“œì‹œ ì¤€ìˆ˜):
        1) ê²°ê³¼ëŠ” **í•œ ì¤„ë‹¹ í•˜ë‚˜ì˜ ì§ˆì˜**ë¡œ ì¶œë ¥í•˜ê³ , ì•„ë˜ 4ê°€ì§€ íŒ¨í„´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - "<í’ˆëª©>ì˜ ì›ì‚°ì§€"
        - "<í’ˆëª©>ì˜ ì˜ì–‘ì†Œ"
        - "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"
        - "<ìƒíƒœ> <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€"   (ìƒíƒœ=í™œì–´|ì„ ì–´|ëƒ‰ë™|ê±´ì–´ ì¤‘ í•˜ë‚˜)
        2) ì§ˆë¬¸ì— í•´ë‹¹ë˜ì§€ ì•ŠëŠ” íŒ¨í„´ì€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”. ì¶”ì¸¡ ê¸ˆì§€.
        3) ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬/ì„¤ëª…/ë”°ì˜´í‘œ/ë²ˆí˜¸/Bullet ê¸ˆì§€. í…ìŠ¤íŠ¸ë§Œ.
        4) í’ˆëª©, ì§€ì—­, ìƒíƒœëŠ” ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ **ê·¸ëŒ€ë¡œ ë°œì·Œ**í•˜ì„¸ìš”(ë™ì˜ì–´ ì¹˜í™˜ ê¸ˆì§€).
        5) ê²°ê³¼ê°€ ì—†ìœ¼ë©´ **ë¹ˆ ë¬¸ìì—´**ë§Œ ë°˜í™˜.

        ì˜ˆì‹œ:
        - ì§ˆë¬¸: "ì‚¬ê³¼ ì–´ë””ì„œ ë‚˜ì™€?"  ->  ì‚¬ê³¼ì˜ ì›ì‚°ì§€
        - ì§ˆë¬¸: "ì˜¤ë Œì§€ ì˜ì–‘ ì„±ë¶„ ì•Œë ¤ì¤˜" -> ì˜¤ë Œì§€ì˜ ì˜ì–‘ì†Œ
        - ì§ˆë¬¸: "ê²½ìƒë¶ë„ ì‚¬ê³¼ ì‚°ì§€" -> ê²½ìƒë¶ë„ì˜ ì‚¬ê³¼ ì›ì‚°ì§€
        - ì§ˆë¬¸: "í™œì–´ ë¬¸ì–´ ì‚°ì§€" -> í™œì–´ ë¬¸ì–´ ì›ì‚°ì§€

        ì§ˆë¬¸: "{query}"
        ì¶œë ¥:
        """.strip()

            try:
                response_content = await self._invoke_with_fallback(prompt)
                # íŒŒì‹±: ì¤„ ë‹¨ìœ„ë¡œ ì •ë¦¬, í—ˆìš© íŒ¨í„´ë§Œ í†µê³¼
                allowed_prefixes = ("í™œì–´ ", "ì„ ì–´ ", "ëƒ‰ë™ ", "ê±´ì–´ ")
                def _is_allowed(line: str) -> bool:
                    if not line: return False
                    # íŒ¨í„´ 1/2: "<í’ˆëª©>ì˜ (ì›ì‚°ì§€|ì˜ì–‘ì†Œ)"
                    if "ì˜ ì›ì‚°ì§€" in line or "ì˜ ì˜ì–‘ì†Œ" in line:
                        return True
                    # íŒ¨í„´ 3: "<ì§€ì—­>ì˜ <í’ˆëª©> ì›ì‚°ì§€"
                    if line.endswith(" ì›ì‚°ì§€") and "ì˜ " in line and not any(line.startswith(p) for p in allowed_prefixes):
                        return True
                    # íŒ¨í„´ 4: "<ìƒíƒœ> <ìˆ˜ì‚°ë¬¼> ì›ì‚°ì§€"
                    if line.endswith(" ì›ì‚°ì§€") and any(line.startswith(p) for p in allowed_prefixes):
                        return True
                    return False

                lines = [l.strip().lstrip("-â€¢").strip().strip('"').strip("'") for l in response_content.splitlines()]
                lines = [l for l in lines if _is_allowed(l)]
                optimized_query = "\n".join(dict.fromkeys(lines))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€

                print(f"  - ìµœì í™”ëœ í‚¤ì›Œë“œ(ì •ê·œ ì§ˆì˜):\n{optimized_query or '(empty)'}")
                return optimized_query if optimized_query else query  # ë¹„ë©´ ì›ë³¸ ì§ˆë¬¸ ì „ë‹¬

            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # Vector DBëŠ” êµ¬ì²´ì ì¸ ì •ë³´ ê²€ìƒ‰ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜
        elif tool == "vector_db_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘ (ìˆ˜ì¹˜/í‘œ/í†µê³„ í‚¤ì›Œë“œ íŠ¹í™”): '{query}'")
            prompt = f"""
ë‹¤ìŒ ìš”ì²­ì„ Vector DBì—ì„œ **ìˆ˜ì¹˜ ë°ì´í„°, í‘œ, í†µê³„ ìë£Œ**ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” **í‚¤ì›Œë“œ ì¡°í•©**ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)**:
1. **ì§ˆë¬¸ í˜•ì‹ ê¸ˆì§€** - "~ì¸ê°€ìš”?", "~ì…ë‹ˆê¹Œ?" ë“± ì§ˆë¬¸ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
2. **í‚¤ì›Œë“œ ì¤‘ì‹¬ì˜ ê²€ìƒ‰ì–´ë§Œ ìƒì„±** - ëª…ì‚¬ì™€ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¡°í•©
3. **ë²ˆí˜¸ ë§¤ê¸°ê¸° ì ˆëŒ€ ê¸ˆì§€** (1., 2., 3. ë“± ì‚¬ìš© ê¸ˆì§€)
4. **ë¶€ê°€ ì„¤ëª… ê¸ˆì§€** - "ì›ë³¸ ìš”ì²­:", "ê²€ìƒ‰ì–´:" ë“± ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
5. **í•œ ì¤„ì˜ í‚¤ì›Œë“œ ì¡°í•©ë§Œ ì¶œë ¥**

**ìˆ˜ì¹˜/í‘œ/í†µê³„ ë°ì´í„° íŠ¹í™” í‚¤ì›Œë“œ ê·œì¹™**:
- **ìˆ˜ì¹˜ ë°ì´í„° í‚¤ì›Œë“œ**: ë§¤ì¶œì•¡, ì‹œì¥ê·œëª¨, ì ìœ ìœ¨, ìƒì‚°ëŸ‰, ì†Œë¹„ëŸ‰, ìˆ˜ì¶œì…ëŸ‰, ê°€ê²©, ìˆœìœ„, ë¹„ìœ¨, í†µê³„
- **í‘œ/ì°¨íŠ¸ í‚¤ì›Œë“œ**: í‘œ, í†µê³„í‘œ, í˜„í™©í‘œ, ë°ì´í„°, ì°¨íŠ¸, ê·¸ë˜í”„, ë„í‘œ
- **ë¹„êµ ë¶„ì„ í‚¤ì›Œë“œ**: ì§€ì—­ë³„, ì—…ì²´ë³„, ë¸Œëœë“œë³„, ì—°ë„ë³„, ì›”ë³„, ìƒìœ„, ìˆœìœ„, ë¹„êµ
- **ì‹œê³„ì—´ í‚¤ì›Œë“œ**: 2024ë…„, 2025ë…„, 7ì›”, 8ì›”, ë¶„ê¸°ë³„, ì›”ë³„, ë…„ë„ë³„, ë³€í™”ìœ¨, ì¦ê°
- **ì •ëŸ‰ ì§€í‘œ**: ì–µì›, ì¡°ì›, í¼ì„¼íŠ¸, í†¤, ê°œ, ëª…, ê±´ìˆ˜, ì¦ê°€ìœ¨, ê°ì†Œìœ¨

ë³€í™˜ ì˜ˆì‹œ (í‚¤ì›Œë“œ ì¤‘ì‹¬):
ì…ë ¥: "êµ­ë‚´ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ì˜ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"
ì¶œë ¥: 2024ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ê·œëª¨ ë§¤ì¶œì•¡ ê¸°ì—…ë³„ ì ìœ ìœ¨ ìˆœìœ„ í†µê³„í‘œ

ì…ë ¥: "ìš°ë¦¬ë‚˜ë¼ ì‹ìì¬ ì‹œì¥ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
ì¶œë ¥: 2024ë…„ ëŒ€í•œë¯¼êµ­ ì‹ìì¬ ì‹œì¥ê·œëª¨ í†µê³„ ì§€ì—­ë³„ ìƒì‚°ëŸ‰ ìˆ˜ì¹˜ ë°ì´í„°

ì…ë ¥: "ì§‘ì¤‘í˜¸ìš° í”¼í•´ì§€ì—­ ë†ì‚°ë¬¼ í˜„í™©ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤"
ì¶œë ¥: 2025ë…„ 7ì›” 8ì›” ì§‘ì¤‘í˜¸ìš° í”¼í•´ì§€ì—­ ë†ì‚°ë¬¼ ìƒì‚°ëŸ‰ ê°ì†Œìœ¨ í”¼í•´ì•¡ í†µê³„í‘œ

ì…ë ¥: "ë§Œë‘ ì‹œì¥ ë¶„ì„ì„ í•©ë‹ˆë‹¤"
ì¶œë ¥: 2024ë…„ ëŒ€í•œë¯¼êµ­ ë§Œë‘ ì‹œì¥ê·œëª¨ ë¸Œëœë“œë³„ ì ìœ ìœ¨ ìˆœìœ„ í†µê³„ ë§¤ì¶œì•¡

ì…ë ¥: "ì‹í’ˆ ê°€ê²© ë™í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤"
ì¶œë ¥: 2024ë…„ 2025ë…„ ì‹í’ˆ í’ˆëª©ë³„ ê°€ê²© ë³€ë™ë¥  ì›”ë³„ ë¬¼ê°€ì§€ìˆ˜ í†µê³„í‘œ

**ì›ë³¸ ìš”ì²­**: "{query}"

**ë³€í™˜ëœ í‚¤ì›Œë“œ ì¡°í•©** (í‚¤ì›Œë“œë§Œ ì¶œë ¥):
"""
            try:
                raw_query = await self._invoke_with_fallback(prompt)

                # [ìˆ˜ì •ë¨] í‚¤ì›Œë“œ ì¡°í•© ì¶”ì¶œ
                optimized_query = self._extract_keywords(raw_query)

                print(f"  - ìµœì í™”ëœ í‚¤ì›Œë“œ: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # Web SearchëŠ” ë§¥ë½ ì •ë³´ë¥¼ í¬í•¨í•œ ê²€ìƒ‰ í‚¤ì›Œë“œë¡œ ìµœì í™”
        elif tool == "web_search":
            print(f"  - {tool} ì¿¼ë¦¬ ìµœì í™” ì‹œì‘ (ë§¥ë½ ê°•í™”): '{query}'")
            prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ì›¹ ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ê²€ìƒ‰ íš¨ê³¼ë¥¼ ë†’ì´ê¸° ìœ„í•´ ì¤‘ìš”í•œ ë§¥ë½ ì •ë³´(êµ­ê°€, ì—°ë„, ëŒ€ìƒ ë“±)ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

ìµœì í™” ê·œì¹™:
1. ì§€ì—­ ì •ë³´ ëª…í™•í™” ë° ê¸°ë³¸ê°’ ì„¤ì •:
   - "êµ­ë‚´" â†’ "ëŒ€í•œë¯¼êµ­"
   - "ìš°ë¦¬ë‚˜ë¼" â†’ "ëŒ€í•œë¯¼êµ­"
   - "í•œêµ­" â†’ "ëŒ€í•œë¯¼êµ­"
   - ì§€ì—­ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ â†’ "ëŒ€í•œë¯¼êµ­" ìë™ ì¶”ê°€
2. êµ¬ì²´ì ì¸ ì—°ë„ ëª…ì‹œ:
   - "ìµœê·¼" â†’ "2024ë…„ 2025ë…„"
   - "ìš”ì¦˜" â†’ "2024ë…„ 2025ë…„"
   - "í˜„ì¬" â†’ "2025ë…„"
   - "ì‘ë…„" â†’ "2024ë…„"
3. êµ¬ì²´ì ì¸ ë¶„ì•¼ë‚˜ ëŒ€ìƒ ëª…ì‹œ
4. ê²€ìƒ‰ ì˜ë„ì— ë§ëŠ” í‚¤ì›Œë“œ ì¡°í•©

ì˜ˆì‹œ:
- ì›ë³¸: "êµ­ë‚´ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™© íŠ¸ë Œë“œ"

- ì›ë³¸: "ìš°ë¦¬ë‚˜ë¼ MZì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ MZì„¸ëŒ€ ì†Œë¹„ íŠ¸ë Œë“œ íŒ¨í„´"

- ì›ë³¸: "ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™©ì„ ì¡°ì‚¬í•©ë‹ˆë‹¤" (ì§€ì—­ ì–¸ê¸‰ ì—†ìŒ)
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì‹œì¥ í˜„í™© íŠ¸ë Œë“œ"

- ì›ë³¸: "í•œêµ­ì˜ ìœ ë§í•œ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ë¶„ì•¼ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ìœ ë§ ë¶„ì•¼ ì‹œì¥ ì „ë§"

- ì›ë³¸: "ìµœê·¼ ì‹ìì¬ ì‹œì¥ íŠ¸ë Œë“œë¥¼ ì¡°ì‚¬í•©ë‹ˆë‹¤"
- ìµœì í™”: "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ì‹ìì¬ ì‹œì¥ íŠ¸ë Œë“œ ë™í–¥ ë¶„ì„"

ì›ë³¸ ì§ˆë¬¸: "{query}"
ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ:
"""
            try:
                optimized_query = await self._invoke_with_fallback(prompt)
                print(f"  - ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: '{optimized_query}'")
                return optimized_query
            except Exception as e:
                print(f"  - ì¿¼ë¦¬ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©: {e}")
                return query

        # ê¸°íƒ€ ë„êµ¬ëŠ” ì›ë³¸ ì¿¼ë¦¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return query

    def _extract_keywords(self, raw_response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¡°í•©ë§Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ ë©”ì„œë“œ"""
        lines = raw_response.strip().split('\n')

        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # ë²ˆí˜¸ ë§¤ê¸°ê¸°, ì„¤ëª…, ì§ˆë¬¸ í˜•íƒœ ì œê±°
            if line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '-', '*')):
                continue
            if any(word in line for word in ['ì›ë³¸', 'ë³€í™˜', 'í‚¤ì›Œë“œ:', 'ì¶œë ¥:', 'ê²€ìƒ‰ì–´:']):
                continue
            if '**' in line:  # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                continue
            if line.endswith(('?', 'ì¸ê°€ìš”', 'ì…ë‹ˆê¹Œ', 'ë‚˜ìš”')):  # ì§ˆë¬¸ í˜•íƒœ ì œê±°
                continue
            cleaned_lines.append(line)

        # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ì¡°í•©ë§Œ ë°˜í™˜
        for line in cleaned_lines:
            # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¼ì¸ ì°¾ê¸°
            if any(keyword in line for keyword in ['ì‹œì¥', 'í†µê³„', 'ë°ì´í„°', 'ë§¤ì¶œ', 'ìƒì‚°', 'ê°€ê²©', 'ì ìœ ìœ¨']):
                return line
        
        # fallback: ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë¼ì¸
        if cleaned_lines:
            return cleaned_lines[0]
        
        return raw_response.strip()

    def _extract_single_question(self, raw_response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ ë‹¨ì¼ ì§ˆë¬¸ë§Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ ë©”ì„œë“œ (ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€)"""
        lines = raw_response.strip().split('\n')

        # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # ë²ˆí˜¸ ë§¤ê¸°ê¸°ë‚˜ ë¶€ê°€ ì„¤ëª… ì œê±°
            if line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '-', '*')):
                continue
            if 'ì›ë³¸' in line or 'ë³€í™˜' in line or 'ì§ˆë¬¸:' in line or 'ì¶œë ¥:' in line:
                continue
            if '**' in line:  # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
                continue
            cleaned_lines.append(line)

        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ë¬¸ì¥ë§Œ ë°˜í™˜
        for line in cleaned_lines:
            if line.endswith('?') or line.endswith('ìš”') or line.endswith('ê¹Œ'):
                return line

        # ì ì ˆí•œ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìœ íš¨í•œ ë¼ì¸ ë°˜í™˜
        if cleaned_lines:
            return cleaned_lines[0]

        # ëª¨ë“  ì²˜ë¦¬ê°€ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ì‘ë‹µ ë°˜í™˜
        return raw_response.strip()


    async def execute(self, tool: str, inputs: Dict[str, Any]) -> Tuple[List[SearchResult], str]:
        """ë‹¨ì¼ ë„êµ¬ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ë©°, ì‹¤í–‰ ì „ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤."""
        if tool not in self.tool_mapping:
            print(f"- ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool}")
            return []

        original_query = inputs.get("query", "")
        # [ìˆ˜ì •ë¨] ì‹¤ì œ ë„êµ¬ ì‹¤í–‰ ì „, ì¿¼ë¦¬ ìµœì í™” ë‹¨ê³„ ì¶”ê°€
        optimized_query = await self._optimize_query_for_tool(original_query, tool)

        # ìµœì í™”ëœ ì¿¼ë¦¬ë¡œ ìƒˆë¡œìš´ inputs ë”•ì…”ë„ˆë¦¬ ìƒì„±
        optimized_inputs = inputs.copy()
        optimized_inputs["query"] = optimized_query

        try:
            print(f"\n>> DataGatherer: '{tool}' ë„êµ¬ ì‹¤í–‰ (ì¿¼ë¦¬: '{optimized_query}')")
            result = await self.tool_mapping[tool](**optimized_inputs)
            return result, optimized_query
        except Exception as e:
            print(f"- {tool} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return [], optimized_query


    async def execute_parallel(self, tasks: List[Dict[str, Any]]) -> Dict[str, List[SearchResult]]:
        """ì—¬ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print(f"\n>> DataGatherer: {len(tasks)}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        # ê° ì‘ì—…ì— ëŒ€í•´ execute ì½”ë£¨í‹´ì„ ìƒì„±í•©ë‹ˆë‹¤. execute ë‚´ë¶€ì—ì„œ ì¿¼ë¦¬ ìµœì í™”ê°€ ìë™ìœ¼ë¡œ ì¼ì–´ë‚©ë‹ˆë‹¤.
        coroutines = [self.execute(task.get("tool"), task.get("inputs", {})) for task in tasks]

        # asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        results = await asyncio.gather(*coroutines, return_exceptions=True)



        organized_results = {}
        for i, task in enumerate(tasks):
            tool_name = task.get("tool", f"unknown_tool_{i}")
            result = results[i]

            # ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
            if isinstance(result, Exception):
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ì˜¤ë¥˜: {result}")
                organized_results[f"{tool_name}_{i}"] = []
            else:
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")
                print(f"  - {tool_name} ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼: {result[:3]}...")  # ì²˜ìŒ 3ê°œ ê²°ê³¼ë§Œ ì¶œë ¥
                search_results, optimized_query = result  # íŠœí”Œ ì–¸íŒ¨í‚¹
                organized_results[f"{tool_name}_{i}"] = search_results

        return organized_results

    async def execute_parallel_streaming(self, tasks: List[Dict[str, Any]], state: Dict[str, Any] = None):
        """ì—¬ëŸ¬ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ë˜, ê° ì‘ì—…ì´ ì™„ë£Œë  ë•Œë§ˆë‹¤ ì‹¤ì‹œê°„ìœ¼ë¡œ yieldí•©ë‹ˆë‹¤."""
        print(f"\n>> DataGatherer: {len(tasks)}ê°œ ì‘ì—… ìŠ¤íŠ¸ë¦¬ë° ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        # ë””ë²„ê¹…
        import pprint
        print("\n-- Tasks to be executed --")
        pprint.pprint(tasks, width=100, depth=2)
        print("\n-- Tasks to be executed --")

        # ê° íƒœìŠ¤í¬ì— ì¸ë±ìŠ¤ë¥¼ í• ë‹¹í•˜ì—¬ ìˆœì„œë¥¼ ì¶”ì 
        async def execute_with_callback(task_index: int, task: Dict[str, Any]):
            tool_name = task.get("tool", f"unknown_tool_{task_index}")
            inputs = task.get("inputs", {})
            query = inputs.get("query", "")

            try:
                print(f"  - {tool_name} ì‹œì‘: {query}")
                result, optimized_query = await self.execute(tool_name, inputs)
                print(f"  - {tool_name} ì™„ë£Œ: {len(result)}ê°œ ê²°ê³¼")

                # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                formatted_results = []
                for search_result in result:
                    result_dict = search_result.model_dump()
                    formatted_result = {
                        "title": result_dict.get("title", "ì œëª© ì—†ìŒ"),
                        "content": result_dict.get("content", "content ì—†ìŒ"),
                        "url": result_dict.get("url", "url ì—†ìŒ"),
                        "source": result_dict.get("source", tool_name),
                        "score": result_dict.get("score", 0.0),
                    }
                    formatted_results.append(formatted_result)

                    print(f"  - {tool_name} ê²°ê³¼ í¬ë§· ì™„ë£Œ: {formatted_result}")

                return {
                    "step": task_index + 1,
                    "tool_name": tool_name,
                    "query": optimized_query,
                    "results": formatted_results,
                    "original_results": result  # ì›ë³¸ SearchResult ê°ì²´ë“¤ë„ ë³´ì¡´
                }

            except Exception as e:
                print(f"  - {tool_name} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                return {
                    "step": task_index + 1,
                    "tool_name": tool_name,
                    "query": optimized_query,
                    "results": [],
                    "error": str(e),
                    "original_results": []
                }

        # ëª¨ë“  ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹œì‘í•˜ê³ , ì™„ë£Œë˜ëŠ” ëŒ€ë¡œ yield
        tasks_coroutines = [execute_with_callback(i, task) for i, task in enumerate(tasks)]

        # asyncio.as_completedë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì²˜ë¦¬
        collected_data = []

        for coro in asyncio.as_completed(tasks_coroutines):
            result = await coro
            collected_data.extend(result.get("original_results", []))

            # ê°œë³„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¦‰ì‹œ yield
            yield {
                "type": "search_results",
                "data": {
                    "step": result["step"],
                    "tool_name": result["tool_name"],
                    "query": result["query"],
                    "results": result["results"],
                    "message_id": state.get("message_id") if state else None
                }
            }

        # ëª¨ë“  ê²€ìƒ‰ì´ ì™„ë£Œëœ í›„ ì „ì²´ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë§ˆì§€ë§‰ì— yield
        yield {
            "type": "collection_complete",
            "data": {
                "total_results": len(collected_data),
                "collected_data": collected_data
            }
        }


    async def _web_search(self, query: str) -> List[SearchResult]:
        """ì›¹ ê²€ìƒ‰ ì‹¤í–‰ - ì•ˆì •ì„± ê°•í™”"""
        try:
            # ìµœì í™”ëœ ì¿¼ë¦¬ ì‚¬ìš© (ì´ë¯¸ _optimize_query_for_toolì—ì„œ ì²˜ë¦¬ë¨)
            print(f"  - ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì¿¼ë¦¬: {query}")

            # ì „ì—­ ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
            loop = asyncio.get_event_loop()
            result_text = await loop.run_in_executor(
                _global_executor,  # ì „ì—­ executor ì‚¬ìš©
                debug_web_search,
                query
            )

            # ê²°ê³¼ê°€ ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            search_results = []
            if result_text and isinstance(result_text, str):
                # ê°„ë‹¨í•œ íŒŒì‹±ìœ¼ë¡œ SearchResult ê°ì²´ ìƒì„±
                lines = result_text.split('\n')
                current_result = {}

                for line in lines:
                    line = line.strip()
                    if line.startswith(('1.', '2.', '3.', '4.', '5.')):
                        # ì´ì „ ê²°ê³¼ ì €ì¥
                        if current_result:
                            search_result = SearchResult(
                                source="web_search",
                                content=current_result.get("snippet", ""),
                                search_query=query,
                                title=current_result.get("title", "ì›¹ ê²€ìƒ‰ ê²°ê³¼"),
                                url=current_result.get("link"),
                                score=0.9,  # ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë†’ì€ ì ìˆ˜
                                timestamp=datetime.now().isoformat(),
                                document_type="web",
                                metadata={"optimized_query": query, **current_result},
                                source_url=current_result.get("link", "ì›¹ ê²€ìƒ‰ ê²°ê³¼")
                            )
                            search_results.append(search_result)

                        # ìƒˆ ê²°ê³¼ ì‹œì‘
                        current_result = {"title": line[3:].strip()}  # ë²ˆí˜¸ ì œê±°
                    elif line.startswith("ì¶œì²˜ ë§í¬:"):
                        current_result["link"] = line[7:].strip()  # "ì¶œì²˜ ë§í¬:" ì œê±°
                    elif line.startswith("ìš”ì•½:"):
                        current_result["snippet"] = line[3:].strip()

                # ë§ˆì§€ë§‰ ê²°ê³¼ ì €ì¥
                if current_result:
                    search_result = SearchResult(
                        source="web_search",
                        content=current_result.get("snippet", ""),
                        search_query=query,
                        title=current_result.get("title", "ì›¹ ê²€ìƒ‰ ê²°ê³¼"),
                        url=current_result.get("link"),
                        score=0.9,  # ì›¹ê²€ìƒ‰ ê²°ê³¼ëŠ” ë†’ì€ ì ìˆ˜
                        timestamp=datetime.now().isoformat(),
                        document_type="web",
                        metadata={
                            "optimized_query": query,
                            "link": current_result.get("link"),  # ì¶œì²˜ ë§í¬ í¬í•¨
                            **current_result
                        },
                        source_url=current_result.get("link", "ì›¹ ê²€ìƒ‰ ê²°ê³¼")
                    )
                    search_results.append(search_result)

            print(f"  - ì›¹ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results[:5]  # ìƒìœ„ 5ê°œ ê²°ê³¼ë§Œ

        except concurrent.futures.TimeoutError:
            print(f"ì›¹ ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return []
        except Exception as e:
            print(f"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _vector_db_search(self, query: str) -> List[SearchResult]:
        """Vector DB ê²€ìƒ‰ ì‹¤í–‰ - ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”"""
        try:
            print(f">> Vector DB ê²€ìƒ‰ ì‹œì‘: {query}")

            # ì „ì—­ ThreadPoolExecutor ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬
            loop = asyncio.get_event_loop()
            results = await loop.run_in_executor(
                _global_executor,  # ì „ì—­ executor ì‚¬ìš©
                vector_db_search,
                query
            )

            search_results = []
            for result in results:
                if isinstance(result, dict):
                    # ìƒˆë¡œìš´ doc_linkì™€ page_number í•„ë“œ ì‚¬ìš©
                    doc_link = result.get("source_url", "")
                    page_number = result.get("page_number", [])
                    # ë¬¸ì„œ ì œëª© ì¶”ì¶œ
                    doc_title = result.get("title", "")

                    # ì œëª©ì— í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€
                    full_title = f"{doc_title}, ({', '.join(map(str, page_number))})".strip()
                    score = result.get("score", 5.2)

                    search_results.append(SearchResult(
                        source="vector_db",
                        content=result.get("content", ""),
                        search_query=query,
                        title=full_title,
                        document_type="database",
                        score=score,
                        url=doc_link,  # ìƒˆ í•„ë“œ ì¶”ê°€
                    ))


            print(f"  - Vector DB ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results[:5]

        # except concurrent.futures.TimeoutError:
        #     print(f"Vector DB ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
        #     return []
        except Exception as e:
            print(f"Vector DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

    async def _graph_db_search(self, query: str) -> List[SearchResult]:
        """Graph DB ê²€ìƒ‰ ì‹¤í–‰ - í¬ë§· ë¶ˆì¼ì¹˜ ë°©ì§€ ë° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
        print(f"  - Graph DB ê²€ìƒ‰ ì‹œì‘: {query}")
        import concurrent.futures

        try:
            # graph_db_searchê°€ ë™ê¸° í•¨ìˆ˜ë¼ë©´
            loop = asyncio.get_running_loop()
            raw_results = await loop.run_in_executor(None, graph_db_search, query)
            # ë§Œì•½ langchain Toolì¼ ê²½ìš°:
            # with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            #     raw_results = executor.submit(graph_db_search.invoke, {"query": query}).result(timeout=20)

            search_results: List[SearchResult] = []

            if isinstance(raw_results, list):
                # list of dict or list of str
                for res in raw_results[:5]:
                    if isinstance(res, dict):
                        # Graph DB ê²°ê³¼ì˜ ì˜ë¯¸ìˆëŠ” ì œëª© ìƒì„±
                        title_candidates = [
                            res.get("title"),
                            res.get("entity"),
                            res.get("product"),
                            res.get("name"),
                            res.get("í’ˆëª©ëª…"),
                            res.get("ì›ì‚°ì§€"),
                            res.get("ì˜ì–‘ì†Œëª…")
                        ]
                        title = next((t for t in title_candidates if t), "ê·¸ë˜í”„ ì •ë³´")

                        # ê´€ê³„í˜• ë°ì´í„°ì˜ ì˜ë¯¸ìˆëŠ” ë‚´ìš© ìƒì„±
                        content_parts = []
                        relationship_info = []

                        # ê´€ê³„ ì •ë³´ ì¶”ì¶œ
                        for key, value in res.items():
                            if "ê´€ê³„" in key or "ì—°ê²°" in key or key.endswith("_ê´€ê³„"):
                                relationship_info.append(f"ğŸ”— {key}: {value}")
                            elif key not in ['title', 'content', 'entity', 'product'] and value:
                                content_parts.append(f"â€¢ {key}: {value}")

                        if relationship_info:
                            content_parts = relationship_info + content_parts

                        content = res.get("content") or "\n".join(content_parts[:8]) or json.dumps(res, ensure_ascii=False, indent=2)
                        score = res.get("confidence") or res.get("score") or 0.8
                    else:
                        title = f"ê·¸ë˜í”„ ê´€ê³„ ì •ë³´"
                        content = str(res)
                        score = 0.8

                    search_results.append(
                        SearchResult(
                            source="graph_db",
                            content=content,
                            search_query=query,
                            title=title,
                            score=score,
                            document_type="graph",
                            url=""  # ë¹ˆ ë¬¸ìì—´ë¡œ í†µì¼ (None ì“°ë©´ í›„ë‹¨ì—ì„œ ê¹¨ì§€ëŠ” ê²½ìš° ìˆìŒ)
                        )
                    )
            elif isinstance(raw_results, dict):
                # ë‹¨ì¼ ê·¸ë˜í”„ ê²°ê³¼ì˜ ì˜ë¯¸ìˆëŠ” ì œëª© ìƒì„±
                title_candidates = [
                    raw_results.get("title"),
                    raw_results.get("entity"),
                    raw_results.get("product"),
                    raw_results.get("name"),
                    raw_results.get("í’ˆëª©ëª…")
                ]
                title = next((t for t in title_candidates if t), "ê·¸ë˜í”„ ê´€ê³„ ì •ë³´")

                # êµ¬ì¡°í™”ëœ ë‚´ìš© ìƒì„±
                content_parts = []
                for key, value in raw_results.items():
                    if key not in ['title', 'content', 'entity', 'product'] and value:
                        if "ê´€ê³„" in key or "ì—°ê²°" in key:
                            content_parts.append(f"ğŸ”— {key}: {value}")
                        else:
                            content_parts.append(f"â€¢ {key}: {value}")

                content = raw_results.get("content") or "\n".join(content_parts[:8]) or json.dumps(raw_results, ensure_ascii=False, indent=2)
                score = raw_results.get("confidence") or raw_results.get("score") or 0.8
                search_results.append(
                    SearchResult(
                        source="graph_db",
                        content=content,
                        search_query=query,
                        title=title,
                        score=score,
                        document_type="graph",
                        url=""
                    )
                )
            else:
                # ë¬¸ìì—´ summary ê°™ì€ ê²½ìš°
                content = str(raw_results)
                title = "ê·¸ë˜í”„ ê²€ìƒ‰ ìš”ì•½"
                search_results.append(
                    SearchResult(
                        source="graph_db",
                        content=content,
                        search_query=query,
                        title=title,
                        score=0.6,
                        document_type="graph",
                        url=""
                    )
                )

            print(f"  - Graph DB ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
            return search_results

        except concurrent.futures.TimeoutError:
            print(f"Graph DB ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {query}")
            return []
        except Exception as e:
            print(f"Graph DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _arxiv_search(self, query: str) -> List[SearchResult]:
        """arXiv ë…¼ë¬¸ ê²€ìƒ‰ ì‹¤í–‰ - í•™ìˆ  ë…¼ë¬¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸"""
        try:
            print(f"  - arXiv ë…¼ë¬¸ ê²€ìƒ‰ ì‹œì‘: {query}")

            # arXiv ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ (langchain tool ìš°íšŒ)
            loop = asyncio.get_event_loop()

            def _direct_arxiv_search(query_text, max_results=5):
                try:
                    # ê²€ìƒ‰ ì¿¼ë¦¬ URL ì¸ì½”ë”©
                    base_url = "http://export.arxiv.org/api/query?"
                    search_query = urllib.parse.quote(query_text)

                    # arXiv API íŒŒë¼ë¯¸í„°
                    params = {
                        'search_query': f'all:{search_query}',
                        'start': 0,
                        'max_results': max_results,
                        'sortBy': 'lastUpdatedDate',
                        'sortOrder': 'descending'
                    }

                    # URL ìƒì„±
                    url = base_url + urllib.parse.urlencode(params)

                    # API í˜¸ì¶œ
                    response = urllib.request.urlopen(url, timeout=10)
                    data = response.read().decode('utf-8')

                    # XML íŒŒì‹±
                    root = ET.fromstring(data)

                    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
                    ns = {
                        'atom': 'http://www.w3.org/2005/Atom',
                        'arxiv': 'http://arxiv.org/schemas/atom'
                    }

                    # ê²°ê³¼ íŒŒì‹±
                    entries = root.findall('atom:entry', ns)

                    if not entries:
                        return f"'{query_text}'ì— ëŒ€í•œ arXiv ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                    results = []
                    for i, entry in enumerate(entries[:max_results], 1):
                        # ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ
                        title = entry.find('atom:title', ns).text.strip().replace('\n', ' ')

                        # ì €ì ì •ë³´
                        authors = entry.findall('atom:author', ns)
                        author_names = [author.find('atom:name', ns).text for author in authors]
                        author_str = ', '.join(author_names[:3])
                        if len(author_names) > 3:
                            author_str += f' ì™¸ {len(author_names)-3}ëª…'

                        # ì´ˆë¡
                        summary = entry.find('atom:summary', ns).text.strip()
                        if len(summary) > 300:
                            summary = summary[:297] + "..."

                        # ë°œí–‰ì¼
                        published = entry.find('atom:published', ns).text
                        pub_date = datetime.strptime(published[:10], '%Y-%m-%d').strftime('%Yë…„ %mì›” %dì¼')

                        # ì¹´í…Œê³ ë¦¬
                        categories = entry.findall('atom:category', ns)
                        cat_list = [cat.get('term') for cat in categories]
                        categories_str = ', '.join(cat_list[:3])

                        # ë…¼ë¬¸ ë§í¬
                        pdf_link = None
                        for link in entry.findall('atom:link', ns):
                            if link.get('type') == 'application/pdf':
                                pdf_link = link.get('href')
                                break

                        if not pdf_link:
                            pdf_link = entry.find('atom:id', ns).text.replace('abs', 'pdf')

                        # ê²°ê³¼ í¬ë§·íŒ…
                        result_text = f"{i}. ğŸ“„ {title}\n"
                        result_text += f"   ì €ì: {author_str}\n"
                        result_text += f"   ë°œí–‰ì¼: {pub_date}\n"
                        result_text += f"   ë¶„ì•¼: {categories_str}\n"
                        result_text += f"   PDF: {pdf_link}\n"
                        result_text += f"   ì´ˆë¡: {summary}\n"

                        results.append(result_text)

                    # ìµœì¢… ê²°ê³¼ ë°˜í™˜
                    final_result = f"arXiv ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ (ê²€ìƒ‰ì–´: {query_text}):\n"
                    final_result += f"ì´ {len(results)}ê°œ ë…¼ë¬¸ ë°œê²¬\n\n"
                    final_result += "\n".join(results)

                    return final_result

                except Exception as e:
                    return f"arXiv ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

            result_text = await loop.run_in_executor(
                _global_executor,
                _direct_arxiv_search,
                query,
                5
            )

            # ê²°ê³¼ íŒŒì‹±
            search_results = []
            if result_text and isinstance(result_text, str):
                lines = result_text.split('\n')
                current_paper = {}

                for line in lines:
                    line = line.strip()
                    if line.startswith(('1.', '2.', '3.', '4.', '5.')):
                        # ì´ì „ ë…¼ë¬¸ ì €ì¥
                        if current_paper:
                            search_result = SearchResult(
                                source="arxiv_search",
                                content=current_paper.get("ì´ˆë¡", ""),
                                search_query=query,
                                title=current_paper.get("title", "arXiv ë…¼ë¬¸"),
                                url=current_paper.get("pdf", ""),
                                score=0.95,  # í•™ìˆ  ë…¼ë¬¸ì€ ë†’ì€ ì‹ ë¢°ë„
                                timestamp=datetime.now().isoformat(),
                                document_type="research_paper",
                                metadata={
                                    "authors": current_paper.get("ì €ì", ""),
                                    "date": current_paper.get("ë°œí–‰ì¼", ""),
                                    "categories": current_paper.get("ë¶„ì•¼", ""),
                                    "optimized_query": query
                                },
                                source_url=current_paper.get("pdf", "")
                            )
                            search_results.append(search_result)
                        # ìƒˆ ë…¼ë¬¸ ì‹œì‘
                        current_paper = {}
                        title_part = line.split('ğŸ“„', 1)
                        if len(title_part) > 1:
                            current_paper["title"] = title_part[1].strip()
                    elif 'ì €ì:' in line:
                        current_paper["ì €ì"] = line.split('ì €ì:', 1)[1].strip()
                    elif 'ë°œí–‰ì¼:' in line:
                        current_paper["ë°œí–‰ì¼"] = line.split('ë°œí–‰ì¼:', 1)[1].strip()
                    elif 'ë¶„ì•¼:' in line:
                        current_paper["ë¶„ì•¼"] = line.split('ë¶„ì•¼:', 1)[1].strip()
                    elif 'PDF:' in line:
                        current_paper["pdf"] = line.split('PDF:', 1)[1].strip()
                    elif 'ì´ˆë¡:' in line:
                        current_paper["ì´ˆë¡"] = line.split('ì´ˆë¡:', 1)[1].strip()

                # ë§ˆì§€ë§‰ ë…¼ë¬¸ ì €ì¥
                if current_paper:
                    search_result = SearchResult(
                        source="arxiv_search",
                        content=current_paper.get("ì´ˆë¡", ""),
                        search_query=query,
                        title=current_paper.get("title", "arXiv ë…¼ë¬¸"),
                        url=current_paper.get("pdf", ""),
                        score=0.95,
                        timestamp=datetime.now().isoformat(),
                        document_type="research_paper",
                        metadata={
                            "authors": current_paper.get("ì €ì", ""),
                            "date": current_paper.get("ë°œí–‰ì¼", ""),
                            "categories": current_paper.get("ë¶„ì•¼", ""),
                            "optimized_query": query
                        },
                        source_url=current_paper.get("pdf", "")
                    )
                    search_results.append(search_result)

            print(f"  - arXiv ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ë…¼ë¬¸")
            return search_results[:5]  # ìµœëŒ€ 5ê°œ ë…¼ë¬¸ë§Œ ë°˜í™˜

        except Exception as e:
            print(f"  - arXiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _rdb_search(self, query: str) -> List[SearchResult]:
        """RDB ê²€ìƒ‰ ì‹¤í–‰ - ë°˜í™˜ í‘œì¤€í™”"""
        try:
            loop = asyncio.get_running_loop()
            result_text = await loop.run_in_executor(None, rdb_search, query)

            # rdb_searchëŠ” ë¬¸ìì—´ì„ ë°˜í™˜í•˜ë¯€ë¡œ, ì´ë¥¼ ë‹¨ì¼ SearchResultë¡œ ë³€í™˜
            if isinstance(result_text, str) and result_text.strip():
                # "PostgreSQL ê²€ìƒ‰ ê²°ê³¼: "ë¡œ ì‹œì‘í•˜ëŠ”ì§€ ì²´í¬
                if "PostgreSQL ê²€ìƒ‰ ê²°ê³¼:" in result_text and "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in result_text:
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                    print(f"  - RDBì—ì„œ '{query}' ê´€ë ¨ ë°ì´í„° ì—†ìŒ")
                    return []

                search_result = SearchResult(
                    source="rdb_search",
                    content=result_text,
                    search_query=query,
                    title="PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼",
                    url="",
                    score=0.9,
                    document_type="database",
                    metadata={"raw_result": result_text}
                )
                print(f"  - rdb_search ë˜í¼ ë°˜í™˜: 1ê°œ (í…ìŠ¤íŠ¸ ê²°ê³¼)")
                return [search_result]
            else:
                print(f"  - RDB ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return []


        except Exception as e:
            print(f"RDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    async def _scrape_content(self, url: str, query: str = "") -> List[SearchResult]:
        """ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
        try:
            content = await asyncio.get_event_loop().run_in_executor(
                None, scrape_and_extract_content, url, query
            )

            if content:
                search_result = SearchResult(
                    source="scrape_content",
                    content=content,
                    search_query=query,
                    title=f"ìŠ¤í¬ë˜í•‘ëœ ì½˜í…ì¸ : {url}",
                    url=url,
                    relevance_score=0.9,
                    timestamp=datetime.now().isoformat(),
                    document_type="web",
                    metadata={"scraped_url": url}
                )
                return [search_result]

            return []
        except Exception as e:
            print(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return []



class ProcessorAgent:
    """ë°ì´í„° ê°€ê³µ ë° ìƒì„± ì „ë‹´ Agent (ReAct ì œê±°, ìˆœì°¨ ìƒì„± ì§€ì›)"""

    def __init__(self, model_pro: str = "gemini-2.5-pro", model_flash: str = "gemini-2.5-flash-lite", temperature: float = 0.3):
        # ë³´ê³ ì„œ ìµœì¢… ìƒì„±ì„ ìœ„í•œ ê³ í’ˆì§ˆ ëª¨ë¸ (Gemini)
        self.llm_pro = ChatGoogleGenerativeAI(model=model_pro, temperature=temperature)
        # êµ¬ì¡° ì„¤ê³„, ìš”ì•½ ë“± ë¹ ë¥¸ ì‘ì—…ì— ì‚¬ìš©í•  ê²½ëŸ‰ ëª¨ë¸ (Gemini)
        self.llm_flash = ChatGoogleGenerativeAI(model=model_flash, temperature=0.1)

        # OpenAI fallback ëª¨ë¸ë“¤
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if self.openai_api_key:
            self.llm_openai_mini = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.1,
                api_key=self.openai_api_key
            )
            self.llm_openai_4o = ChatOpenAI(
                model="gpt-4o",
                temperature=temperature,
                api_key=self.openai_api_key
            )
            print("ProcessorAgent: OpenAI fallback ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            self.llm_openai_mini = None
            self.llm_openai_4o = None
            print("ProcessorAgent: ê²½ê³ : OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

        self.personas = PERSONA_PROMPTS

        # Orchestratorê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” ì‘ì—… ëª©ë¡ ì •ì˜
        self.processor_mapping = {
            "design_report_structure": self._design_report_structure,
            "create_chart_data": self._create_charts,
        }

    async def _invoke_with_fallback(self, prompt, primary_model, fallback_model):
        """
        Gemini API rate limit ì‹œ OpenAIë¡œ fallback ì²˜ë¦¬
        """
        try:
            result = await primary_model.ainvoke(prompt)
            return result
        except Exception as e:
            error_str = str(e).lower()
            rate_limit_indicators = ['429', 'quota', 'rate limit', 'exceeded', 'resource_exhausted']

            if any(indicator in error_str for indicator in rate_limit_indicators):
                print(f"ProcessorAgent: Gemini API rate limit ê°ì§€, OpenAIë¡œ fallback ì‹œë„: {e}")
                if fallback_model:
                    try:
                        result = await fallback_model.ainvoke(prompt)
                        print("ProcessorAgent: OpenAI fallback ì„±ê³µ")
                        return result
                    except Exception as fallback_error:
                        print(f"ProcessorAgent: OpenAI fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                        raise fallback_error
                else:
                    print("ProcessorAgent: OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    raise e
            else:
                raise e

    async def _astream_with_fallback(self, prompt, primary_model, fallback_model):
        """
        ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ Gemini API rate limit ì‹œ OpenAIë¡œ fallback ì²˜ë¦¬
        """
        primary_chunks_received = 0
        primary_content_length = 0

        try:
            print(f"- Primary ëª¨ë¸ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œë„ ({type(primary_model).__name__})")
            async for chunk in primary_model.astream(prompt):
                primary_chunks_received += 1
                if hasattr(chunk, 'content') and chunk.content:
                    primary_content_length += len(chunk.content)
                yield chunk

            print(f"- Primary ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ: {primary_chunks_received}ê°œ ì²­í¬, {primary_content_length} ë¬¸ì")

            # ì²­í¬ë¥¼ ë°›ì•˜ì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ë„ ì‹¤íŒ¨ë¡œ ê°„ì£¼
            if primary_chunks_received == 0 or primary_content_length == 0:
                print(f"- Primary ëª¨ë¸ì—ì„œ ìœ íš¨í•œ ë‚´ìš©ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ, fallback ì‹¤í–‰")
                raise Exception("No valid content generated")

        except Exception as e:
            error_str = str(e).lower()
            rate_limit_indicators = ['429', 'quota', 'rate limit', 'exceeded', 'resource_exhausted', 'no valid content', 'no generation chunks']

            if any(indicator in error_str for indicator in rate_limit_indicators) or primary_chunks_received == 0:
                print(f"ProcessorAgent: Gemini API ë¬¸ì œ ê°ì§€ (ì²­í¬:{primary_chunks_received}, ë‚´ìš©:{primary_content_length}), OpenAIë¡œ fallback: {e}")
                if fallback_model:
                    try:
                        print("ProcessorAgent: OpenAI fallbackìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
                        fallback_chunks_received = 0
                        async for chunk in fallback_model.astream(prompt):
                            fallback_chunks_received += 1
                            yield chunk
                        print(f"ProcessorAgent: OpenAI fallback ì™„ë£Œ: {fallback_chunks_received}ê°œ ì²­í¬")
                    except Exception as fallback_error:
                        print(f"ProcessorAgent: OpenAI fallbackë„ ì‹¤íŒ¨: {fallback_error}")
                        raise fallback_error
                else:
                    print("ProcessorAgent: OpenAI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    raise e
            else:
                print(f"ProcessorAgent: ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜: {e}")
                raise e

    async def process(self, processor_type: str, data: Any, param2: Any, param3: str, param4: str = "", yield_callback=None, state: Optional[Dict[str, Any]] = None):
        """Orchestratorë¡œë¶€í„° ë™ê¸°ì‹ ì‘ì—…ì„ ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        session_id = state.get("session_id", "unknown") if state else "unknown"
        logger = get_session_logger(session_id, "ProcessorAgent")
        logger.info(f"Processor ì‹¤í–‰: {processor_type}")
        # stateëŠ” ì´ë¯¸ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ìŒ

        if processor_type == "design_report_structure":
            selected_indexes = param2
            original_query = param3
            async for result in self._design_report_structure(data, selected_indexes, original_query, state):
                yield result
        elif processor_type == "create_chart_data":
            section_title = param2
            generated_content = param3
            # yield_callbackì€ ì´ë¯¸ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ë°›ìŒ
            async for result in self._create_charts(data, section_title, generated_content, yield_callback, state):
                yield result

        else:
            yield {"type": "error", "data": {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì²˜ë¦¬ íƒ€ì…: {processor_type}"}}

    async def _design_report_structure(self, data: List[SearchResult], selected_indexes: List[int], query: str, state: Optional[Dict[str, Any]] = None):
        """ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ + ì„¹ì…˜ë³„ ì‚¬ìš©í•  ë°ì´í„° ì¸ë±ìŠ¤ ì„ íƒ"""

        print(f"\n>> ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‹œì‘:")
        print(f"   ì „ì²´ ë°ì´í„°: {len(data)}ê°œ")
        print(f"   ì„ íƒëœ ì¸ë±ìŠ¤: {selected_indexes} ({len(selected_indexes)}ê°œ)")

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        persona_description = self.personas.get(persona_name, {}).get("description", "ì¼ë°˜ì ì¸ ë¶„ì„ê°€")
        print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ê´€ì  ì ìš©")

        # ì„ íƒëœ ì¸ë±ìŠ¤ì˜ ë°ì´í„°ë¥¼ ì¸ë±ìŠ¤ì™€ í•¨ê»˜ ë§¤í•‘í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        indexed_context = ""
        for idx in selected_indexes:
            if 0 <= idx < len(data):
                res = data[idx]
                source = getattr(res, 'source', 'Unknown')
                title = getattr(res, 'title', 'No Title')
                content = getattr(res, 'content', '')  # ì „ì²´ ë‚´ìš© (ìš”ì•½ ì—†ì´)

                indexed_context += f"""
    --- ë°ì´í„° ì¸ë±ìŠ¤ [{idx}] ---
    ì¶œì²˜: {source}
    ì œëª©: {title}
    ë‚´ìš©: {content}

    """

        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
        limited_indexed_context = indexed_context[:20000]  # ë” ë§ì€ ì •ë³´ í¬í•¨

        print(f"   ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(indexed_context)} ë¬¸ì")
        print(f"   ì œí•œëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(limited_indexed_context)} ë¬¸ì")

        prompt = f"""
    ë‹¹ì‹ ì€ '{persona_name}'({persona_description})ì˜ ê´€ì ì„ ê°€ì§„ ë°ì´í„° ë¶„ì„ê°€ì´ì AI ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì„¤ê³„ìì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ **ì„ ë³„ëœ ë°ì´í„°**ì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬, **'{persona_name}'ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•  ë§Œí•œ ì£¼ì œ**ë“¤ë¡œ **ë‚´ìš©ì´ ì ˆëŒ€ ì¤‘ë³µë˜ì§€ ì•ŠëŠ”** ë…¼ë¦¬ì ì¸ ë³´ê³ ì„œ ëª©ì°¨ë¥¼ ì„¤ê³„í•˜ê³ , **ê° ì„¹ì…˜ì˜ êµ¬ì²´ì ì¸ ëª©í‘œ**ì™€ **ê° ì„¹ì…˜ë³„ë¡œ ì‚¬ìš©í•  ë°ì´í„° ì¸ë±ìŠ¤**ë¥¼ ëª…í™•íˆ ë¶„ë°°í•´ì£¼ì„¸ìš”.

    **ê°€ì¥ ì¤‘ìš”í•œ ëª©í‘œ**: ê° ë³´ê³ ì„œ ì„¹ì…˜ì´ '{persona_name}'ì˜ ê´€ì ì—ì„œ ê³ ìœ í•œ ì£¼ì œë¥¼ ë‹¤ë£¨ê²Œ í•˜ì—¬, ë‚´ìš© ë°˜ë³µì„ ì›ì²œì ìœ¼ë¡œ ë°©ì§€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    **ì‚¬ìš©ì ì§ˆë¬¸**: "{query}"

    **ì„ ë³„ëœ ë°ì´í„° (ì¸ë±ìŠ¤ì™€ ì „ì²´ ë‚´ìš© í¬í•¨)**:
    {limited_indexed_context}

    **ì‘ì—… ì§€ì¹¨**:
    1. **ë³´ê³ ì„œ ëª©ì°¨ ë° ì„¹ì…˜ë³„ ëª©í‘œ ì„¤ê³„**
    - ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ” 3~5ê°œì˜ **ê³ ìœ í•˜ê³  êµ¬ì²´ì ì¸ ì„¹ì…˜**ìœ¼ë¡œ ëª©ì°¨ë¥¼ êµ¬ì„±í•˜ì„¸ìš”.
    - **[ë§¤ìš° ì¤‘ìš”]** ê° ì„¹ì…˜ë§ˆë‹¤ `description` í•„ë“œì— **í•´ë‹¹ ì„¹ì…˜ì´ ë¶„ì„í•´ì•¼ í•  í•µì‹¬ ì§ˆë¬¸ì´ë‚˜ ë‹¬ì„±í•´ì•¼ í•  ëª©í‘œ**ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ê¸°ìˆ í•˜ì„¸ìš”. ì´ ì„¤ëª…ì€ ë‚˜ì¤‘ì— ë‹¤ë¥¸ AIê°€ í•´ë‹¹ ì„¹ì…˜ì„ ì‘ì„±í•  ë•Œ ì§ì ‘ì ì¸ ê°€ì´ë“œë¼ì¸ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    - **í•µì‹¬ ê·œì¹™**: ê° ì„¹ì…˜ì˜ ì œëª©ì€ **ì„œë¡œ ë‹¤ë¥¸ ë¶„ì„ ê´€ì ì´ë‚˜ ì£¼ì œ**ë¥¼ ë‹¤ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤. ëª¨í˜¸í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ì œëª©ì€ ì ˆëŒ€ ê¸ˆì§€ë©ë‹ˆë‹¤.

        - **ì ˆëŒ€ í”¼í•´ì•¼ í•  ë‚˜ìœ ì˜ˆì‹œ (ì£¼ì œê°€ ìœ ì‚¬í•˜ì—¬ ë‚´ìš©ì´ ì¤‘ë³µë¨):**
            - "1. ë§Œë‘ ìˆ˜ì¶œ í˜„í™© ë¶„ì„", "2. ì£¼ìš” ìˆ˜ì¶œêµ­ ë° ì‹œì¥ ë™í–¥"  (X)
            - "1. ì‹œì¥ íŠ¸ë Œë“œ", "2. ìµœì‹  ë™í–¥ ë¶„ì„" (X)

        - **ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•  ì¢‹ì€ ì˜ˆì‹œ (ì£¼ì œê°€ ëª…í™•íˆ ë¶„ë¦¬ë¨):**
            - "1. **êµ­ê°€ë³„ ìˆ˜ì¶œì•¡ ë°ì´í„°**ë¥¼ í†µí•œ í•µì‹¬ ì‹œì¥ ë¶„ì„" (ì •ëŸ‰ì , ìˆœìœ„)
            - "2. **ì†Œë¹„ì ì„ í˜¸ë„ ë° ìµœì‹  ì‹í’ˆ íŠ¸ë Œë“œ** ë¶„ì„" (ì •ì„±ì , íŠ¸ë Œë“œ)
            - "3. **ì£¼ìš” ê²½ìŸì‚¬ ì „ëµ ë° ì„±ê³µ/ì‹¤íŒ¨ ì‚¬ë¡€** ì—°êµ¬" (ê²½ìŸ, ì‚¬ë¡€ ë¶„ì„)

    2. **ê° ì„¹ì…˜ë³„ ì‚¬ìš© ë°ì´í„° ì„ íƒ**
    - **1ë‹¨ê³„ì—ì„œ ì„¤ê³„í•œ ê³ ìœ í•œ ì„¹ì…˜ ì œëª©**ì„ ê¸°ì¤€ìœ¼ë¡œ, ê° ì„¹ì…˜ë§ˆë‹¤ `use_contents` í•„ë“œì— **ì¡°ê¸ˆ ì „ ë‹¹ì‹ ì´ ì§ì ‘ ì •ì˜í•œ `description`ì˜ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ë°** ê°€ì¥ ì í•©í•œ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ ë²ˆí˜¸ë“¤ì„ ë°°ì—´ë¡œ í• ë‹¹í•˜ì„¸ìš”.
    - **ë°ì´í„° ì¤‘ë³µ í• ë‹¹ ì—„ê²© ê¸ˆì§€**: **ì„œë¡œ ë‹¤ë¥¸ ì„¹ì…˜ì€ ë°˜ë“œì‹œ ì„œë¡œ ë‹¤ë¥¸ `use_contents` ëª©ë¡ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.** ë™ì¼í•œ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì„¹ì…˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤.
    - **ìµœì  í• ë‹¹ ì›ì¹™**: ê° ë°ì´í„°ëŠ” ê·¸ê²ƒì´ ê°€ì¥ í•µì‹¬ì ìœ¼ë¡œ ë’·ë°›ì¹¨í•  ìˆ˜ ìˆëŠ” **ë‹¨ í•˜ë‚˜ì˜ ì„¹ì…˜ì—ë§Œ í• ë‹¹**í•˜ëŠ” ê²ƒì„ ì›ì¹™ìœ¼ë¡œ í•©ë‹ˆë‹¤.
    - **ì¸ë±ìŠ¤ ë²”ìœ„ ë° ê°œìˆ˜ ì œí•œ**:
        - ìœ„ì— ì œì‹œëœ ë°ì´í„° ì¸ë±ìŠ¤ ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”: {selected_indexes}
        - í•œ ì„¹ì…˜ì— ë„ˆë¬´ ë§ì€ ë°ì´í„°(5ê°œ ì´ˆê³¼)ë¥¼ í• ë‹¹í•˜ì§€ ë§ˆì„¸ìš”.

    3. **'ê²°ë¡ ' ì„¹ì…˜ ì¶”ê°€ (í•„ìˆ˜)**: ë³´ê³ ì„œì˜ ê°€ì¥ ë§ˆì§€ë§‰ì—ëŠ” í•­ìƒ 'ê²°ë¡ ' ì„¹ì…˜ì„ í¬í•¨í•˜ì„¸ìš”.
    - `content_type`ì€ 'synthesis'ë¡œ ì„¤ì •
    - `use_contents`ì—ëŠ” ì£¼ìš” ì„¹ì…˜ë“¤ì˜ í•µì‹¬ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ í¬í•¨í•˜ì„¸ìš”. **(ì˜ˆì™¸: 'ê²°ë¡ ' ì„¹ì…˜ì€ ë‹¤ë¥¸ ì„¹ì…˜ì—ì„œ ì‚¬ìš©ëœ í•µì‹¬ ë°ì´í„°ë¥¼ ì¤‘ë³µ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)**

    4. **ë°ì´í„° í•„ìš” ìœ í˜• ëª…ì‹œ ë° ì°¨íŠ¸ìš© ë°ì´í„° ì¶”ê°€ ì„ íƒ**:
    - **ìˆ˜ì¹˜, í†µê³„, íŠ¸ë Œë“œ, ë¶„ì„ ê´€ë ¨ ì„¹ì…˜**: 'full_data_for_chart' (ì°¨íŠ¸ ìƒì„±)
    - **ì¼ë°˜ ì„¤ëª…, ê°œìš”, ê²°ë¡ **: 'synthesis' (í…ìŠ¤íŠ¸ë§Œ)
    
    **ì¤‘ìš”: ì°¨íŠ¸ ìƒì„± ì„¹ì…˜ ('full_data_for_chart')ì— ëŒ€í•œ íŠ¹ë³„ ê·œì¹™**:
    - ì°¨íŠ¸ ìƒì„±ì´ í•„ìš”í•œ ì„¹ì…˜ì€ **ê¸°ë³¸ ë°ì´í„° ì™¸ì— ì¶”ê°€ì ìœ¼ë¡œ í†µê³„/í‘œ/ìˆ˜ì¹˜ ë°ì´í„°ê°€ í’ë¶€í•œ ë°ì´í„°ë„ í¬í•¨**í•´ì•¼ í•©ë‹ˆë‹¤
    - ë‹¤ìŒê³¼ ê°™ì€ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ê°€ ì„ íƒí•˜ì„¸ìš”:
      * **ìˆ˜ì¹˜ í‚¤ì›Œë“œ**: "ë§¤ì¶œì•¡", "ì ìœ ìœ¨", "ì¦ê°€ìœ¨", "ê°ì†Œìœ¨", "í¼ì„¼íŠ¸", "%", "ì–µì›", "ì¡°ì›", "í†¤", "ê°œ"
      * **í‘œ/í†µê³„ í‚¤ì›Œë“œ**: "í‘œ", "í†µê³„", "í˜„í™©í‘œ", "ë°ì´í„°", "ìˆœìœ„", "ë¹„êµ", "ë¶„ì„"
      * **ì‹œê³„ì—´ í‚¤ì›Œë“œ**: "2024ë…„", "2025ë…„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ì—°ë„ë³„", "ë³€í™”"
    - ì°¨íŠ¸ ìƒì„± ì„¹ì…˜ì˜ `use_contents`ëŠ” **ê¸°ë³¸ ë°ì´í„° 3-5ê°œ + í†µê³„/ìˆ˜ì¹˜ ë°ì´í„° 2-3ê°œ**ë¡œ êµ¬ì„±í•˜ì„¸ìš”
    - ì˜ˆì‹œ: [0, 2, 5] (ê¸°ë³¸ ë°ì´í„°) + [8, 12] (í†µê³„ ë°ì´í„°) = [0, 2, 5, 8, 12]

    5. **â­ ë§¤ìš° ì¤‘ìš”: ë°ì´í„° ì¶©ë¶„ì„± ê²€ì¦ (ì—„ê²©í•œ ê¸°ì¤€)**:
    - **`full_data_for_chart` ì„¹ì…˜ì˜ ì—„ê²©í•œ ê²€ì¦ ê¸°ì¤€**:
      * **ìˆ˜ì¹˜ ë°ì´í„° í•„ìˆ˜**: ìˆ«ì, í¼ì„¼íŠ¸, ê¸ˆì•¡, ë¹„ìœ¨ì´ **ëª…í™•íˆ ì œì‹œëœ ë°ì´í„°ê°€ 3ê°œ ì´ìƒ** ìˆì–´ì•¼ í•¨
      * **êµ¬ì¡°í™”ëœ ë°ì´í„° í•„ìˆ˜**: í‘œ, í†µê³„í‘œ, ìˆœìœ„, ë¹„êµ ë°ì´í„°ê°€ **êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜** ì œì‹œë˜ì–´ì•¼ í•¨
      * **ì°¨íŠ¸ ìƒì„± ê°€ëŠ¥ì„± í™•ì¸**: 
        - ì§€ì—­ë³„/í’ˆëª©ë³„/ì‹œê¸°ë³„ **êµ¬ì²´ì  ìˆ˜ì¹˜ ë¹„êµ**ê°€ ê°€ëŠ¥í•œê°€?
        - "ì¬ë°°ë©´ì ê°ì†Œ", "ì •ì‹ì§€ì—°" ê°™ì€ **ì •ì„±ì  ì„¤ëª…ë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„**
        - ë°˜ë“œì‹œ "20% ê°ì†Œ", "3000í†¤ ìƒì‚°", "50ë§Œì›/í†¤" ê°™ì€ **êµ¬ì²´ì  ìˆ˜ì¹˜**ê°€ ìˆì–´ì•¼ í•¨
      * **ë¶€ì¡±í•œ ê²½ìš° ë°˜ë“œì‹œ `is_sufficient: false`** ì„¤ì •í•˜ê³  êµ¬ì²´ì ì¸ ì¶”ê°€ ê²€ìƒ‰ ì¿¼ë¦¬ ì œì•ˆ
    
    - **`synthesis` ì„¹ì…˜**: ì„¤ëª…, ë¶„ì„ì— í•„ìš”í•œ ê¸°ë³¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶©ë¶„ (ìˆ˜ì¹˜ ë°ì´í„° ë¶ˆí•„ìš”)
    
    - **`feedback_for_gatherer` ì‘ì„± ì‹œ**:
      * êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ìš”ì²­í•˜ëŠ” ê²€ìƒ‰ì–´ ì‘ì„±
      * ì˜ˆ: "2025ë…„ 7ì›” 8ì›” ê°•ì›ë„ í˜¸ë‚¨ì§€ì—­ ë†ì‚°ë¬¼ ìƒì‚°ëŸ‰ ì¬ë°°ë©´ì  í†µê³„ ìˆ˜ì¹˜ ë°ì´í„°"
      * ì˜ˆ: "ì§‘ì¤‘í˜¸ìš° í”¼í•´ ì§€ì—­ë³„ ë†ì‚°ë¬¼ ìƒì‚°ëŸ‰ ê°ì†Œìœ¨ í¼ì„¼íŠ¸ í†µê³„í‘œ"

    **ì„¹ì…˜ë³„ ë°ì´í„° ì„ íƒ ì˜ˆì‹œ**:
    - **ì°¨íŠ¸ ì„¹ì…˜**: "ì‹œì¥ ê·œëª¨ ë¶„ì„" (full_data_for_chart) 
      â†’ ê¸°ë³¸: [0, 2, 5] (ì‹œì¥, ë§¤ì¶œ ê´€ë ¨) + í†µê³„: [8, 12] (ìˆ˜ì¹˜ í…Œì´ë¸” í¬í•¨) = [0, 2, 5, 8, 12]
    - **ì°¨íŠ¸ ì„¹ì…˜**: "ì§€ì—­ë³„ ìƒì‚° í˜„í™©" (full_data_for_chart)
      â†’ ê¸°ë³¸: [1, 3, 7] (ì§€ì—­, ìƒì‚° ê´€ë ¨) + í†µê³„: [9, 15] (ì§€ì—­ë³„ í†µê³„ í¬í•¨) = [1, 3, 7, 9, 15]
    - **í…ìŠ¤íŠ¸ ì„¹ì…˜**: "ì†Œë¹„ì íŠ¸ë Œë“œ" (synthesis) â†’ [4, 6, 10] (ì†Œë¹„ì, ì„ í˜¸ë„ ê´€ë ¨)
    - **ê²°ë¡  ì„¹ì…˜**: "ê²°ë¡  ë° ì œì–¸" (synthesis) â†’ [0, 1, 3, 5, 8] (ê° ì„¹ì…˜ í•µì‹¬ ë°ì´í„° ì¢…í•©)

    **ì¶œë ¥ í¬ë§· (ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ):**
    {{
        "title": "ë³´ê³ ì„œì˜ ìµœì¢… ì œëª©",
        "structure": [
            {{
                "section_title": "1. ì‹œì¥ í˜„í™© ë° ê·œëª¨ ë¶„ì„",
                "description": "ì „ì²´ ì‹œì¥ì˜ í˜„ì¬ ê·œëª¨ì™€ ì„±ì¥ë¥ ì„ ì •ëŸ‰ì ìœ¼ë¡œ íŒŒì•…í•˜ì—¬ ì œì‹œí•©ë‹ˆë‹¤.",
                "content_type": "full_data_for_chart",
                "use_contents": [0, 3, 7, 10, 13],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }},
            {{
                "section_title": "2. ì§€ì—­ë³„ ìƒì‚° í˜„í™© ë¹„êµ",
                "description": "ì£¼ìš” ì§€ì—­ë³„ ìƒì‚°ëŸ‰ê³¼ í”¼í•´ í˜„í™©ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.",
                "content_type": "full_data_for_chart",
                "use_contents": [1, 5, 9, 12, 16],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }},
            {{
                "section_title": "3. ê²½ìŸ í™˜ê²½ ë¶„ì„",
                "description": "ì£¼ìš” ê²½ìŸì‚¬ë“¤ì˜ ì „ëµê³¼ ì‹œì¥ ë‚´ ìœ„ì¹˜ë¥¼ ë¶„ì„í•˜ì—¬ ê²½ìŸ êµ¬ë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.",
                "content_type": "synthesis",
                "use_contents": [2, 4, 8],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }},
            {{
                "section_title": "3-1. ì‹œì¥ ì ìœ ìœ¨ ì°¨íŠ¸ (ë°ì´í„° ë¶€ì¡± ì˜ˆì‹œ)",
                "description": "ì£¼ìš” ê²½ìŸì‚¬ë“¤ì˜ ì‹œì¥ ì ìœ ìœ¨ì„ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.",
                "content_type": "full_data_for_chart",
                "use_contents": [2, 4],
                "is_sufficient": false,
                "feedback_for_gatherer": {{
                    "tool": "vector_db_search",
                    "query": "2024ë…„ 2025ë…„ ëŒ€í•œë¯¼êµ­ ë§Œë‘ ì‹œì¥ ê¸°ì—…ë³„ ë¸Œëœë“œë³„ ì ìœ ìœ¨ í¼ì„¼íŠ¸ ë§¤ì¶œì•¡ ìˆœìœ„ í†µê³„í‘œ ìˆ˜ì¹˜"
                }}
            }},
            {{
                "section_title": "4. ê²°ë¡  ë° ì œì–¸",
                "description": "ì•ì„œ ë¶„ì„í•œ ì‹œì¥, ì†Œë¹„ì, ê²½ìŸì‚¬ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ê³  ì „ëµì  ë°©í–¥ì„ ì œì•ˆí•©ë‹ˆë‹¤.",
                "content_type": "synthesis",
                "use_contents": [0, 1, 3, 5, 8],
                "is_sufficient": true,
                "feedback_for_gatherer": ""
            }}
        ]
    }}

    **ì¤‘ìš”**: `use_contents` ë°°ì—´ì—ëŠ” ë°˜ë“œì‹œ ìœ„ì— ì œì‹œëœ ì¸ë±ìŠ¤ ë²ˆí˜¸ {selected_indexes} ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”.
    """

        try:
            response = await self._invoke_with_fallback(
                prompt,
                self.llm_flash,
                self.llm_openai_mini
            )

            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‘ë‹µ ê¸¸ì´: {len(response.content)} ë¬¸ì")

            # JSON íŒŒì‹±
            design_result = json.loads(re.search(r'\{.*\}', response.content, re.DOTALL).group())

            # ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ê²°ê³¼ JSON dumpë¡œ ì¶œë ¥
            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ê²°ê³¼ JSON:")
            print(json.dumps(design_result, ensure_ascii=False, indent=2))

            # â­ í•µì‹¬ ì¶”ê°€: ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦ ë° ë°ì´í„° ì¶©ë¶„ì„± ì¬ê²€ì¦
            print(f"  - êµ¬ì¡° ì„¤ê³„ ê²°ê³¼ ê²€ì¦ ë° ë°ì´í„° ì¶©ë¶„ì„± ì¬í™•ì¸:")
            for i, section in enumerate(design_result.get("structure", [])):
                section_title = section.get("section_title", f"ì„¹ì…˜ {i+1}")
                content_type = section.get("content_type", "synthesis")
                use_contents = section.get("use_contents", [])
                is_sufficient = section.get("is_sufficient", True)

                # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í•„í„°ë§
                valid_use_contents = []
                for idx in use_contents:
                    if isinstance(idx, int) and idx in selected_indexes:
                        valid_use_contents.append(idx)
                    else:
                        print(f"    ê²½ê³ : ì˜ëª»ëœ ì¸ë±ìŠ¤ {idx} ì œê±°ë¨ (í—ˆìš©ëœ ì¸ë±ìŠ¤: {selected_indexes})")

                section["use_contents"] = valid_use_contents

                print(f"    '{section_title}' ({content_type}): {len(valid_use_contents)}ê°œ ë°ì´í„°")
                print(f"      ì‚¬ìš© ì¸ë±ìŠ¤: {valid_use_contents}")
                print(f"      LLM íŒë‹¨ is_sufficient: {is_sufficient}")

                # â­ ì°¨íŠ¸ ì„¹ì…˜ì— ëŒ€í•œ ì‹¤ì œ ë°ì´í„° ë‚´ìš© ê¸°ë°˜ ì¬ê²€ì¦
                if content_type == "full_data_for_chart":
                    has_numeric_data = False
                    numeric_count = 0
                    
                    print(f"      ğŸ“Š ì°¨íŠ¸ ì„¹ì…˜ ë°ì´í„° ë‚´ìš© ê²€ì¦:")
                    for idx in valid_use_contents:
                        if 0 <= idx < len(data):
                            data_item = data[idx]
                            content = getattr(data_item, 'content', '')
                            title = getattr(data_item, 'title', 'No Title')
                            
                            # ìˆ˜ì¹˜ ë°ì´í„° íŒ¨í„´ ê²€ì‚¬ (ë” í¬ê´„ì )
                            numeric_patterns = [
                                r'\d+%',                    # í¼ì„¼íŠ¸
                                r'\d+\.\d+%',               # ì†Œìˆ˜ì  í¼ì„¼íŠ¸  
                                r'\d+ì–µì›?',                 # ì–µì›
                                r'\d+ì¡°ì›?',                 # ì¡°ì›
                                r'\d+ë§Œì›?',                 # ë§Œì›
                                r'\d+ì²œí†¤',                  # ì²œí†¤
                                r'\d+í†¤',                   # í†¤
                                r'\d+,\d+',                 # ì²œì˜ ìë¦¬ ì½¤ë§ˆ
                                r'\d+\s*ì›/\s*\d+\s*ê°œ?',     # ë‹¨ê°€ (ì›/ê°œ, ì›/20ê°œ ë“±)
                                r'ë‹¨ìœ„:\s*ì›/\d+ê°œ?',          # "ë‹¨ìœ„: ì›/20ê°œ" í˜•íƒœ
                                r'\d+\s+\d+\s+\d+\s+\d+',     # ì—°ì†ëœ ìˆ«ìë“¤ (í…Œì´ë¸” ë°ì´í„°)
                                r'\d{4}ë…„\s+\d+',           # "2025ë…„ 38660" ê°™ì€ ì—°ë„+ìˆ«ì
                                r'\d+ì›”\s+\d+',             # "7ì›” 14324" ê°™ì€ ì›”+ìˆ«ì
                                r'ì¦ê°€ìœ¨.*?\d+',             # ì¦ê°€ìœ¨ + ìˆ«ì
                                r'ê°ì†Œìœ¨.*?\d+',             # ê°ì†Œìœ¨ + ìˆ«ì
                                r'ì ìœ ìœ¨.*?\d+',             # ì ìœ ìœ¨ + ìˆ«ì
                                r'\d+\s+\d+\s+\d+',         # í‘œ í˜•íƒœì˜ ì—°ì† ìˆ«ì
                                r'í‰ë…„\s+\d+',              # "í‰ë…„ 25686" ê°™ì€ ê¸°ì¤€ê°’
                            ]
                            
                            numeric_matches = 0
                            for pattern in numeric_patterns:
                                matches = re.findall(pattern, content)
                                numeric_matches += len(matches)
                            
                            if numeric_matches > 0:
                                has_numeric_data = True
                                numeric_count += numeric_matches
                                print(f"        [{idx}] âœ… ìˆ˜ì¹˜ ë°ì´í„° {numeric_matches}ê°œ ë°œê²¬: {title[:30]}...")
                            else:
                                print(f"        [{idx}] âŒ ìˆ˜ì¹˜ ë°ì´í„° ì—†ìŒ: {title[:30]}...")
                    
                    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¶©ë¶„ì„± ì¬íŒë‹¨ (ë” ê´€ëŒ€í•œ ê¸°ì¤€)
                    # í…Œì´ë¸”ì´ë‚˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶©ë¶„í•˜ë‹¤ê³  íŒë‹¨
                    has_table_data = any('ë‹¨ìœ„:' in getattr(data[idx], 'content', '') or 
                                       'êµ¬ë¶„' in getattr(data[idx], 'content', '') or
                                       ('ë…„' in getattr(data[idx], 'content', '') and 'ì›”' in getattr(data[idx], 'content', ''))
                                       for idx in valid_use_contents if 0 <= idx < len(data))
                    
                    # ê°€ê²©/ë‹¨ê°€ ì •ë³´ë„ ì°¨íŠ¸ ìƒì„± ê°€ëŠ¥í•˜ë‹¤ê³  íŒë‹¨
                    has_price_data = any(('ì›/' in getattr(data[idx], 'content', '') or
                                        'ê°€ê²©' in getattr(data[idx], 'title', ''))
                                       for idx in valid_use_contents if 0 <= idx < len(data))
                    
                    actually_sufficient = (has_numeric_data and numeric_count >= 2) or has_table_data or has_price_data
                    
                    print(f"        ğŸ’¡ í…Œì´ë¸” í˜•íƒœ ë°ì´í„° ë°œê²¬: {has_table_data}")
                    print(f"        ğŸ’° ê°€ê²©/ë‹¨ê°€ ë°ì´í„° ë°œê²¬: {has_price_data}")
                    print(f"        ğŸ“Š ìµœì¢… ì¶©ë¶„ì„± íŒë‹¨: ìˆ˜ì¹˜({numeric_count}ê°œ) + í…Œì´ë¸”({has_table_data}) + ê°€ê²©({has_price_data}) = {actually_sufficient}")
                    
                    if is_sufficient and not actually_sufficient:
                        print(f"      ğŸ”§ LLM íŒë‹¨ ì˜¤ë¥˜ ê°ì§€: sufficient=trueì˜€ì§€ë§Œ ì‹¤ì œ ìˆ˜ì¹˜ ë°ì´í„° ë¶€ì¡± ({numeric_count}ê°œ)")
                        print(f"      ğŸ”„ is_sufficientë¥¼ falseë¡œ ìˆ˜ì •í•˜ê³  ì¶”ê°€ ê²€ìƒ‰ ìš”ì²­ ìƒì„±")
                        section["is_sufficient"] = False
                        section["feedback_for_gatherer"] = {
                            "tool": "vector_db_search",
                            "query": f"{section_title} ê´€ë ¨ êµ¬ì²´ì  ìˆ˜ì¹˜ í†µê³„ ë°ì´í„° í‘œ ê·¸ë˜í”„ í¼ì„¼íŠ¸ ê¸ˆì•¡ ìƒì‚°ëŸ‰"
                        }
                    elif actually_sufficient:
                        print(f"      âœ… ì°¨íŠ¸ ìƒì„± ê°€ëŠ¥: ìˆ˜ì¹˜ ë°ì´í„° {numeric_count}ê°œ ì¶©ë¶„")
                    else:
                        print(f"      âš ï¸  ì°¨íŠ¸ ìƒì„± ì–´ë ¤ì›€: ìˆ˜ì¹˜ ë°ì´í„° {numeric_count}ê°œ ë¶€ì¡±")

                # ì‚¬ìš©ë  ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                for idx in valid_use_contents[:2]:  # ì²˜ìŒ 2ê°œë§Œ
                    if 0 <= idx < len(data):
                        data_item = data[idx]
                        print(f"      [{idx:2d}] {getattr(data_item, 'source', 'Unknown'):10s} | {getattr(data_item, 'title', 'No Title')[:40]}")

            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì™„ë£Œ: '{design_result.get('title', 'ì œëª©ì—†ìŒ')}'")
            yield {"type": "result", "data": design_result}

        except Exception as e:
            print(f"  - ë³´ê³ ì„œ êµ¬ì¡° ì„¤ê³„ ì‹¤íŒ¨: {e}")
            print(f"  - ì•ˆì „ ëª¨ë“œë¡œ ê¸°ë³¸ êµ¬ì¡° ìƒì„±")

            # ì•ˆì „ ëª¨ë“œ: ëª¨ë“  ì„ íƒëœ ì¸ë±ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ì—ì„œ ì‚¬ìš©
            fallback_design = {
                "title": f"{query} - í†µí•© ë¶„ì„ ë³´ê³ ì„œ",
                "structure": [{
                    "section_title": "ì¢…í•© ë¶„ì„", "description": "ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.",
                    "content_type": "synthesis", "use_contents": selected_indexes[:10],
                    "is_sufficient": True, "feedback_for_gatherer": ""
                }]
            }
            yield {"type": "result", "data": fallback_design}


    # worker_agents.py - ProcessorAgent í´ë˜ìŠ¤ì˜ ìˆ˜ì •ëœ í•¨ìˆ˜ë“¤

    async def _synthesize_data_for_section(self, section_title: str, section_data: List[SearchResult]) -> str:
        """â­ ìˆ˜ì •: ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¶œì²˜ ë²ˆí˜¸ ì •í™•íˆ ë§¤í•‘"""

        # â­ í•µì‹¬ ê°œì„ : ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¶œì²˜ ì •ë³´ ìƒì„±
        context_with_sources = ""
        for i, res in enumerate(section_data):  # section_dataë§Œ ì‚¬ìš© (all_data ëŒ€ì‹ )
            source_info = ""
            source_link = ""

            # Web search ê²°ê³¼ì¸ ê²½ìš°
            if hasattr(res, 'source') and 'web_search' in str(res.source).lower():
                if hasattr(res, 'url') and res.url:
                    source_link = res.url
                    source_info = f"ì›¹ ì¶œì²˜: {res.url}"
                elif hasattr(res, 'metadata') and res.metadata and 'link' in res.metadata:
                    source_link = res.metadata['link']
                    source_info = f"ì›¹ ì¶œì²˜: {res.metadata['link']}"
                else:
                    source_info = "ì›¹ ê²€ìƒ‰ ê²°ê³¼"
                    source_link = "ì›¹ ê²€ìƒ‰"

            # Vector DB ê²°ê³¼ì¸ ê²½ìš°
            elif hasattr(res, 'source_url'):
                source_info = f"ë¬¸ì„œ ì¶œì²˜: {res.source_url}"
                source_link = res.source_url
            elif hasattr(res, 'title'):
                source_info = f"ë¬¸ì„œ: {res.title}"
                source_link = res.title
            else:
                source_name = res.source if hasattr(res, 'source') else 'Vector DB'
                source_info = f"ì¶œì²˜: {source_name}"
                source_link = source_name

            # í•µì‹¬: ì„¹ì…˜ ë°ì´í„° ë‚´ì—ì„œì˜ ì¸ë±ìŠ¤ ì‚¬ìš© (0, 1, 2...)
            context_with_sources += f"--- ë¬¸ì„œ ID {i}: [{source_info}] ---\nì œëª©: {res.title}\në‚´ìš©: {res.content}\nì¶œì²˜_ë§í¬: {source_link}\n\n"

        prompt = f"""
    ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ë¶„ì„ ë³´ê³ ì„œì˜ í•œ ì„¹ì…˜ì„ ì €ìˆ í•˜ëŠ” ì£¼ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    **ì‘ì„±í•  ì„¹ì…˜ì˜ ì£¼ì œ**: "{section_title}"

    **ì‚¬ìš© ë°ì´í„° ì¸ë±ìŠ¤**

    **ì°¸ê³ í•  ì„ íƒëœ ë°ì´í„°** (ì„¹ì…˜ë³„ë¡œ ì—„ì„ ëœ ê´€ë ¨ ë°ì´í„°):
    {context_with_sources[:8000]}

    **ì‘ì„± ì§€ì¹¨**:
    1. **í•µì‹¬ ì •ë³´ ì¶”ì¶œ**: '{section_title}' ì£¼ì œì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í•µì‹¬ ì‚¬ì‹¤, ìˆ˜ì¹˜, í†µê³„ ìœ„ì£¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    2. **ê°„ê²°í•œ ìš”ì•½**: ì •ë³´ë¥¼ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ì§€ ë§ê³ , 1~2 ë¬¸ë‹¨ ì´ë‚´ì˜ ê°„ê²°í•˜ê³  ë…¼ë¦¬ì ì¸ í•µì‹¬ ìš”ì•½ë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.
    3. **ì¤‘ë³µ ì œê±°**: ì—¬ëŸ¬ ë¬¸ì„œì— ê±¸ì³ ë°˜ë³µë˜ëŠ” ë‚´ìš©ì€ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬ ì œê±°í•˜ì„¸ìš”.
    4. **ê°ê´€ì„± ìœ ì§€**: ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ê°ê´€ì ì¸ ì‚¬ì‹¤ë§Œì„ ì „ë‹¬í•´ì£¼ì„¸ìš”.
    5. **â­ ì¶œì²˜ ì •ë³´ ë³´ì¡´**: ì¤‘ìš”í•œ ì •ë³´ë‚˜ ìˆ˜ì¹˜ë¥¼ ì–¸ê¸‰í•  ë•Œ í•´ë‹¹ ì •ë³´ì˜ ì¶œì²˜ë¥¼ [SOURCE:ìˆ«ì] í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”. ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
    - **ë¬¸ì„œ ID ë²ˆí˜¸ë¥¼ ì‚¬ìš©**
    - ì˜ˆì‹œ: "ì‹œì¥ ê·œëª¨ê°€ ì¦ê°€í–ˆìŠµë‹ˆë‹¤ [SOURCE:1]", "ë§¤ì¶œì´ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤ [SOURCE:2]"
    - ì˜ëª»ëœ ì˜ˆì‹œ: [SOURCE:ë°ì´í„° 1], [SOURCE:ë¬¸ì„œ 1] (ì´ëŸ° í˜•ì‹ ì‚¬ìš© ê¸ˆì§€)
    6. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš©**:
    - **ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ìˆ˜ì¹˜**: **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
    - *ì¼ë°˜ì ì¸ ê°•ì¡°ë‚˜ íŠ¸ë Œë“œ*: *ê¸°ìš¸ì„ì²´*ë¡œ í‘œí˜„
    - **í•µì‹¬ í¬ì¸íŠ¸ë‚˜ ê²°ë¡ **: > ì¸ìš©ë¬¸ í˜•íƒœë¡œ ê°•ì¡°
    - **í•­ëª©ì´ ì—¬ëŸ¬ ê°œ**: - ì²« ë²ˆì§¸ í•­ëª©, - ë‘ ë²ˆì§¸ í•­ëª© í˜•íƒœ
    - **í•˜ìœ„ ë¶„ë¥˜**:   - ì„¸ë¶€ í•­ëª© (ë“¤ì—¬ì“°ê¸°)
    - **ë‹¨ë½ êµ¬ë¶„**: ë‚´ìš© ë³€í™” ì‹œ ê³µë°± ë¼ì¸ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„

    **ê²°ê³¼ë¬¼ (í•µì‹¬ ìš”ì•½ë³¸)**:
    """
        response = await self._invoke_with_fallback(
            prompt,
            self.llm_flash,
            self.llm_openai_mini
        )
        return response.content

    async def generate_section_streaming(
        self,
        section: Dict[str, Any],
        full_data_dict: Dict[int, Dict],
        original_query: str,
        use_indexes: List[int],
        awareness_context: str = "",
        state: Optional[Dict[str, Any]] = None
    ) -> AsyncGenerator[str, None]:
        """í˜ë¥´ì†Œë‚˜, ì „ì²´ êµ¬ì¡° ì¸ì§€(awareness_context), ì„¹ì…˜ ëª©í‘œ(description)ë¥¼ ë°˜ì˜í•˜ì—¬ ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì—ì„œ í•´ë‹¹ ì„¹ì…˜ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ìƒì„±"""
        section_title = section.get("section_title", "ì œëª© ì—†ìŒ")
        content_type = section.get("content_type", "synthesis")
        description = section.get("description", "ì´ ì„¹ì…˜ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.")

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        default_report_prompt = "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ AI ë¶„ì„ê°€ì…ë‹ˆë‹¤."
        persona_instruction = self.personas.get(persona_name, {}).get("report_prompt", default_report_prompt)

        print(f"  - ì„¹ì…˜ '{section_title}' ìƒì„±ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ ì ìš© (ì „ì²´ êµ¬ì¡° ì¸ì§€)")

        # ì„¹ì…˜ ì‹œì‘ ì‹œ H2 í—¤ë”ë¡œ ì¶œë ¥
        section_header = f"\n\n## {section_title}\n\n"
        yield section_header

        prompt = "" # ìµœì¢… í”„ë¡¬í”„íŠ¸ë¥¼ ë‹´ì„ ë³€ìˆ˜

        if content_type == "synthesis":
            print(f"\nğŸ” === SECTION STREAMING ë””ë²„ê¹… ({section_title}) ===")
            print(f"use_indexes: {use_indexes}")
            print(f"full_data_dict í‚¤ë“¤: {list(full_data_dict.keys()) if full_data_dict else 'None'}")

            # ì „ì²´ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì—ì„œ í•´ë‹¹ ì¸ë±ìŠ¤ë§Œ ì„ ë³„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…
            section_data_content = ""
            valid_indexes = []
            for actual_index in use_indexes:
                if actual_index in full_data_dict:
                    valid_indexes.append(actual_index)
                    data_info = full_data_dict[actual_index]
                    section_data_content += f"**ë°ì´í„° {actual_index}: {data_info['source']}**\n"
                    section_data_content += f"- **ì œëª©**: {data_info['title']}\n"
                    section_data_content += f"- **ë‚´ìš©**: {data_info['content']}\n\n"
                    print(f"  âœ… [{actual_index}] ë°ì´í„° ë§¤í•‘ ì„±ê³µ: '{data_info['title'][:30]}...'")
                else:
                    print(f"  âŒ [{actual_index}] full_data_dictì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ!")

            print(f"ìœ íš¨í•œ ì¸ë±ìŠ¤ë“¤: {valid_indexes}")
            print(f"í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©í•  SOURCE ë²ˆí˜¸ë“¤: {valid_indexes}")


            prompt_template = """

    {persona_instruction}

    ë‹¹ì‹ ì€ ìœ„ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë”°ë¥´ëŠ” ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì „ì²´ ë³´ê³ ì„œì˜ ì¼ë¶€ì¸ í•œ ì„¹ì…˜ì„ ì‘ì„±í•˜ëŠ” ì„ë¬´ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.

    **ì‚¬ìš©ìì˜ ì „ì²´ ì§ˆë¬¸**: "{original_query}"

    ---
    **[ë§¤ìš° ì¤‘ìš”] ì „ì²´ ë³´ê³ ì„œ êµ¬ì¡° ë° ë‹¹ì‹ ì˜ ì—­í• **:
    ë‹¹ì‹ ì€ ì•„ë˜ êµ¬ì¡°ë¡œ êµ¬ì„±ëœ ì „ì²´ ë³´ê³ ì„œì—ì„œ **ì˜¤ì§ '{section_title}' ì„¹ì…˜ë§Œ**ì„ ì±…ì„ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¤ë¥¸ ì „ë¬¸ê°€ë“¤ì´ ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ì„ ë™ì‹œì— ì‘ì„±í•˜ê³  ìˆìœ¼ë¯€ë¡œ, **ë‹¤ë¥¸ ì„¹ì…˜ì˜ ì£¼ì œë¥¼ ì ˆëŒ€ ì¹¨ë²”í•˜ì§€ ë§ê³  ë‹¹ì‹ ì˜ ì—­í• ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.**

    {awareness_context}
    ---

    **í˜„ì¬ ì‘ì„±í•  ì„¹ì…˜ ì œëª©**: "{section_title}"
    **ì´ ì„¹ì…˜ì˜ í•µì‹¬ ëª©í‘œ**: "{description}"

    **ì°¸ê³  ë°ì´í„° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ í¬í•¨)**:
    {section_data_content}

    **ì‘ì„± ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**:
    1. **ì—­í•  ì¤€ìˆ˜**: ìœ„ 'ì „ì²´ ë³´ê³ ì„œ êµ¬ì¡°'ì™€ 'í•µì‹¬ ëª©í‘œ'ë¥¼ ë°˜ë“œì‹œ ì¸ì§€í•˜ê³ , '{section_title}'ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ë§Œ ê¹Šì´ ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
    2. **í˜ë¥´ì†Œë‚˜ ì—­í•  ìœ ì§€**: ë‹¹ì‹ ì˜ ì—­í• ê³¼ ë§íˆ¬, ë¶„ì„ ê´€ì ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ë©° ì‘ì„±í•˜ì„¸ìš”.
    3. **ê°„ê²°ì„± ìœ ì§€**: ë°˜ë“œì‹œ 1~2 ë¬¸ë‹¨ ì´ë‚´ë¡œ, ê°€ì¥ í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
    4. **ì œëª© ë°˜ë³µ ê¸ˆì§€**: ì£¼ì–´ì§„ ì„¹ì…˜ ì œëª©ì„ ì ˆëŒ€ ë°˜ë³µí•´ì„œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
    5. **ë°ì´í„° ê¸°ë°˜**: ì°¸ê³  ë°ì´í„°ì— ìˆëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ì‹¤, ì¸ìš©êµ¬ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”.
    6. **ì „ë¬¸ê°€ì  ë¬¸ì²´**: ëª…í™•í•˜ê³  ê°„ê²°í•˜ë©° ë…¼ë¦¬ì ì¸ ì „ë¬¸ê°€ì˜ í†¤ìœ¼ë¡œ ê¸€ì„ ì‘ì„±í•˜ì„¸ìš”.
    7. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš© (ë§¤ìš° ì¤‘ìš”) - ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•¨**:
    
    **ê¸°ë³¸ í¬ë§·íŒ… (í•„ìˆ˜)**:
    - **í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì¤‘ìš”í•œ ìˆ˜ì¹˜**: ë°˜ë“œì‹œ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡° (ì˜ˆ: **58,000ì›/10kg**, **ì „ë…„ ëŒ€ë¹„ 81.4% í•˜ë½**)
    - *ë³€í™”ë‚˜ ì¶”ì„¸*: ë°˜ë“œì‹œ *ê¸°ìš¸ì„ì²´*ë¡œ í‘œí˜„ (ì˜ˆ: *ì „ë…„ ëŒ€ë¹„ ê°ì†Œ*, *ì§‘ì¤‘í˜¸ìš°ë¡œ ì¸í•œ í”¼í•´*)
    - ë¬¸ë‹¨ë³„ë¡œ **ë°˜ë“œì‹œ 2-3ê°œ ì´ìƒì˜ ê°•ì¡°** í¬í•¨í•  ê²ƒ
    
    **êµ¬ì¡°í™” (í•„ìˆ˜)**:
    - **ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë‚˜ ê²°ë¡ **: ë°˜ë“œì‹œ `> **í•µì‹¬ ìš”ì•½**: ë‚´ìš©` í˜•íƒœë¡œ ë¸”ë¡ì¿¼íŠ¸ ì‚¬ìš©
    - **ë¹„êµ ì •ë³´ê°€ 3ê°œ ì´ìƒ**: ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ì‚¬ìš©
    - **ëª©ë¡ í˜•íƒœ ì •ë³´**: ë°˜ë“œì‹œ `-` ë¶ˆë¦¿ í¬ì¸íŠ¸ ì‚¬ìš©
    - **ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´**: ë°˜ë“œì‹œ `### ì†Œì œëª©` ì‚¬ìš©
    
    **í•„ìˆ˜ ì˜ˆì‹œ íŒ¨í„´**:
    ```
    **ë°°(Pear)**ì˜ ì „ì²´ ì¬ë°°ë©´ì ì€ **9,361ha**ë¡œ ì „ë…„ ëŒ€ë¹„ **0.6% ê°ì†Œ**í–ˆìœ¼ë©°, *ì§‘ì¤‘í˜¸ìš° í”¼í•´ ì§€ì—­*ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” ê°•ì› ë° í˜¸ë‚¨ ì§€ì—­ì—ì„œì˜ ë³€ë™ì´ ë‘ë“œëŸ¬ì¡ŒìŠµë‹ˆë‹¤. [SOURCE:2, 3]
    
    | ì‹ì¬ë£Œ | ì£¼ìš” ìƒì‚°ì§€ | ì¬ë°°ë©´ì  ë³€í™” | ì£¼ìš” ì›ì¸ |
    | :--- | :--- | :--- | :--- |
    | **ë°°** | ì „êµ­ | **-0.6%** (ì „ë…„ ëŒ€ë¹„) | *ì „êµ­ì  ì¬ë°°ë©´ì  ê°ì†Œ ì¶”ì„¸* [SOURCE:2] |
    | **í¬ë„** | ì „êµ­ | **-2.3% ~ -6.7%** | *ì‘í˜•ë³„ ë©´ì  ê°ì†Œ* [SOURCE:4] |
    
    > **í•µì‹¬ ê²°ë¡ **: ì§‘ì¤‘í˜¸ìš° ì§ì ‘ í”¼í•´ëŠ” *ë¯¸ë¯¸í•œ ìˆ˜ì¤€*ì´ì—ˆìœ¼ë‚˜, ê³ ì˜¨ ë° ê°€ë­„ì´ **ê³¼ë¹„ëŒ€ ì§€ì—°** ë“± í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë” ì»¸ìŠµë‹ˆë‹¤.
    ```
    
    **âš ï¸ ê°•ì œ ìš”êµ¬ì‚¬í•­**: ëª¨ë“  ë¬¸ë‹¨ì—ì„œ **êµµì€ ê¸€ì”¨** 2ê°œ ì´ìƒ, *ê¸°ìš¸ì„ì²´* 1ê°œ ì´ìƒ ë°˜ë“œì‹œ ì‚¬ìš©

    **í‘œ ì‘ì„± ì§€ì¹¨**:
    - 3ê°œ ì´ìƒì˜ í•­ëª©ì„ ë¹„êµí•˜ê±°ë‚˜ ë¶„ë¥˜í•  ë•Œ í…Œì´ë¸” ì‚¬ìš©
    - í…Œì´ë¸” í˜•ì‹: `| í•­ëª© | ë‚´ìš© | ë¹„ê³  |` ë° `| :--- | :--- | :--- |` êµ¬ë¶„ì„ 
    - í…Œì´ë¸” ì…€ ì•ˆì—ì„œë„ **êµµì€ ê¸€ì”¨**, *ê¸°ìš¸ì„ì²´*, [SOURCE:ìˆ«ì] ì¶œì²˜ í‘œê¸° ê°€ëŠ¥
    - ì˜ˆì‹œ:
    ```
    | ì£¼ìš” ì‹ì¬ë£Œ | ì£¼ìš” ìƒì‚°ì§€ | í˜„í™© ìš”ì•½ |
    | :--- | :--- | :--- |
    | **í† ë§ˆí† ** | í˜¸ë‚¨ ì§€ì—­ | ì§‘ì¤‘í˜¸ìš°ë¡œ **ìˆ˜í•´ ë°œìƒ** [SOURCE:2] |
    | **ë°°** | ì¶©ë‚¨, ì „ë‚¨ | í”¼í•´ëŠ” **ë¯¸ë¯¸í•œ ìˆ˜ì¤€** [SOURCE:1] |
    ```
    8. **â­ ì¶œì²˜ í‘œê¸° (ë°ì´í„° ì¸ë±ìŠ¤ ë²ˆí˜¸ ì‚¬ìš©)**: íŠ¹ì • ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œ ë¬¸ì¥ ë°”ë¡œ ë’¤ì— [SOURCE:ìˆ«ì] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ í‘œê¸°í•˜ì„¸ìš”.

    **ğŸ”´ ë§¤ìš° ì¤‘ìš” - SOURCE ë²ˆí˜¸ ì‚¬ìš© ê·œì¹™**:
    - **ë°˜ë“œì‹œ ìœ„ "ì°¸ê³  ë°ì´í„°"ì— ëª…ì‹œëœ "[ë°ì´í„° ì¸ë±ìŠ¤ X]" ì˜ X ë²ˆí˜¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
    - ì˜ˆ: "ë°ì´í„° 0", "ë°ì´í„° 3", "ë°ì´í„° 7"ì´ ì£¼ì–´ì¡Œë‹¤ë©´ â†’ [SOURCE:0], [SOURCE:3], [SOURCE:7]ë§Œ ì‚¬ìš© ê°€ëŠ¥
    - **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë²ˆí˜¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”** (ì˜ˆ: ë°ì´í„° 0~7ë§Œ ìˆëŠ”ë° [SOURCE:15] ì‚¬ìš© ê¸ˆì§€)
    - ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ê³  "ë°ì´í„°", "ë¬¸ì„œ" ë“±ì˜ ë‹¨ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
    - ì—¬ëŸ¬ ì¶œì²˜ëŠ” ì‰¼í‘œì™€ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„: [SOURCE:1, 4, 8]
    - ë‹¨ì¼ ì¶œì²˜: [SOURCE:8]
    - SOURCE íƒœê·¸ëŠ” ì™„ì „í•œ ë¬¸ì¥ì´ ëë‚œ í›„ ë°”ë¡œ ë¶™ì—¬ì„œ ì‘ì„±í•˜ì„¸ìš”
    - SOURCE íƒœê·¸ ì•ë’¤ë¡œ ì¤„ë°”ê¿ˆí•˜ì§€ ë§ˆì„¸ìš” (ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ë¶„í•  ë°©ì§€)

    **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ** (ë°ì´í„° 0, 3, 8ì´ ì£¼ì–´ì§„ ê²½ìš°):
    - "**ë§¤ì¶œì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤** [SOURCE:8]"
    - "ì‹œì¥ ì ìœ ìœ¨ì´ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤ [SOURCE:3]"
    - "**ë§¤ì¶œì´ 5% ê°ì†Œí–ˆìŠµë‹ˆë‹¤** [SOURCE:0, 3, 8]"

    **ğŸš« ì ˆëŒ€ ê¸ˆì§€ë˜ëŠ” ì˜ëª»ëœ ì˜ˆì‹œ**:
    - [SOURCE:ë°ì´í„° 1], [SOURCE:ë¬¸ì„œ 1] (ë‹¨ì–´ í¬í•¨ ê¸ˆì§€)
    - [SOURCE:1,\n4, 8] (ì¤„ë°”ê¿ˆ ê¸ˆì§€)
    - [SOURCE: 1 , 4 , 8] (ë¶ˆí•„ìš”í•œ ê³µë°± ê¸ˆì§€)
    - [SOURCE:15] (ìœ„ ì°¸ê³  ë°ì´í„°ì— ì—†ëŠ” ë²ˆí˜¸ ì‚¬ìš© ê¸ˆì§€)

    **âš ï¸ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë°˜ë“œì‹œ í™•ì¸)**:
    â–¡ **êµµì€ ê¸€ì”¨**ê°€ ë¬¸ë‹¨ë‹¹ 2ê°œ ì´ìƒ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?
    â–¡ *ê¸°ìš¸ì„ì²´*ê°€ ì ì ˆíˆ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€?
    â–¡ 3ê°œ ì´ìƒ ë¹„êµ ì‹œ í…Œì´ë¸”ì„ ì‚¬ìš©í–ˆëŠ”ê°€?
    â–¡ ì¤‘ìš”í•œ ê²°ë¡ ì— `> **í•µì‹¬ ìš”ì•½**:` ë¸”ë¡ì¿¼íŠ¸ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€?
    â–¡ [SOURCE:ìˆ«ì] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ ì •í™•íˆ í‘œê¸°í–ˆëŠ”ê°€?
    â–¡ ë‹¨ë½ ê°„ ê³µë°± ë¼ì¸ì´ ìˆëŠ”ê°€?
    
    **ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­**:
    âŒ "ì¶”ê°€ ì •ë³´ ìš”ì²­", "ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤", "êµ¬ì²´ì ì¸ ë°ì´í„° ë¶€ì¡±" ë“±ì˜ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
    âŒ "...ì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤" ê°™ì€ ë¯¸ì™„ì„± ê²°ë¡  ì œì‹œ ê¸ˆì§€
    âœ… **í˜„ì¬ í™•ë³´ëœ ë°ì´í„°ë¡œ ìµœëŒ€í•œ êµ¬ì²´ì ì´ê³  ì™„ì „í•œ ë¶„ì„ ë° ê²°ë¡  ì œì‹œ í•„ìˆ˜**
    âœ… ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆì–´ë„ í˜„ì¬ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìµœì„ ì˜ ì¸ì‚¬ì´íŠ¸ì™€ í‘œ ì œê³µ
    
    **â­ ì§€ê¸ˆ ë°”ë¡œ ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì„¹ì…˜ì„ ì‘ì„±í•˜ì„¸ìš”:**
    
    **ë³´ê³ ì„œ ì„¹ì…˜ ë‚´ìš©**:
    """

            prompt = prompt_template.format(
                persona_instruction=persona_instruction,
                original_query=original_query,
                section_title=section_title,
                awareness_context=awareness_context,
                description=description,
                section_data_content=section_data_content
            )

        else:  # "full_data_for_chart"
            section_data_content = ""
            for actual_index in use_indexes:
                if actual_index in full_data_dict:
                    data_info = full_data_dict[actual_index]
                    section_data_content += f"**ë°ì´í„° {actual_index}: {data_info['source']}**\n"
                    section_data_content += f"- **ì œëª©**: {data_info['title']}\n"
                    section_data_content += f"- **ë‚´ìš©**: {data_info['content']}\n"
                    section_data_content += f"- **ì¶œì²˜_ë§í¬**: {data_info.get('url') or data_info.get('source_url', '')}\n\n"

            prompt_template = """
            {persona_instruction}

    ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ê°€ì´ì ë³´ê³ ì„œ ì‘ì„±ê°€ì…ë‹ˆë‹¤. ìœ„ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë”°ë¼ì„œ, ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ì„¤ëª…ê³¼ ì‹œê°ì  ì°¨íŠ¸ë¥¼ ê²°í•©í•œ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë³´ê³ ì„œ ì„¹ì…˜ì„ ì‘ì„±í•©ë‹ˆë‹¤.

    **ì‚¬ìš©ìì˜ ì „ì²´ ì§ˆë¬¸**: "{original_query}"

    ---
    **[ë§¤ìš° ì¤‘ìš”] ì „ì²´ ë³´ê³ ì„œ êµ¬ì¡° ë° ë‹¹ì‹ ì˜ ì—­í• **:
    ë‹¹ì‹ ì€ ì•„ë˜ êµ¬ì¡°ë¡œ êµ¬ì„±ëœ ì „ì²´ ë³´ê³ ì„œì—ì„œ **ì˜¤ì§ '{section_title}' ì„¹ì…˜ë§Œ**ì„ ì±…ì„ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¤ë¥¸ ì „ë¬¸ê°€ë“¤ì´ ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ì„ ë™ì‹œì— ì‘ì„±í•˜ê³  ìˆìœ¼ë¯€ë¡œ, **ë‹¤ë¥¸ ì„¹ì…˜ì˜ ì£¼ì œë¥¼ ì ˆëŒ€ ì¹¨ë²”í•˜ì§€ ë§ê³  ë‹¹ì‹ ì˜ ì—­í• ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.**

    {awareness_context}
    ---

    **í˜„ì¬ ì‘ì„±í•  ì„¹ì…˜ ì œëª©**: "{section_title}"
    **ì„¹ì…˜ ëª©í‘œ**: "{description}"

    **ì°¸ê³  ë°ì´í„° (ì‹¤ì œ ì¸ë±ìŠ¤ ë²ˆí˜¸ í¬í•¨)**:
    {section_data_content}

    **ì‘ì„± ì§€ì¹¨ (ë§¤ìš° ì¤‘ìš”)**:
    1. **ì—­í•  ì¤€ìˆ˜**: ìœ„ 'ì „ì²´ ë³´ê³ ì„œ êµ¬ì¡°'ì™€ 'í•µì‹¬ ëª©í‘œ'ë¥¼ ë°˜ë“œì‹œ ì¸ì§€í•˜ê³ , '{section_title}'ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ë§Œ ê¹Šì´ ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
    2. **í˜ë¥´ì†Œë‚˜ ì—­í•  ìœ ì§€**: ë‹¹ì‹ ì˜ ì—­í• ê³¼ ë§íˆ¬, ë¶„ì„ ê´€ì ì„ ë°˜ë“œì‹œ ìœ ì§€í•˜ë©° ì‘ì„±í•˜ì„¸ìš”.
    3. **ê°„ê²°ì„± ìœ ì§€**: ë°˜ë“œì‹œ 1~2 ë¬¸ë‹¨ ì´ë‚´ë¡œ, ë°ì´í„°ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.
    4. **ì œëª© ë°˜ë³µ ê¸ˆì§€**: ì£¼ì–´ì§„ ì„¹ì…˜ ì œëª©ì„ ì ˆëŒ€ ë°˜ë³µí•´ì„œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ë³¸ë¬¸ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
    5. **ë°ì´í„° ê¸°ë°˜**: ì„¤ëª…ì— êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì‚¬ì‹¤, í†µê³„ ìë£Œë¥¼ ì ê·¹ì ìœ¼ë¡œ ì¸ìš©í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ë†’ì´ì„¸ìš”.
    6. **â­ ì°¨íŠ¸ ë§ˆì»¤ ì‚½ì…**: í…ìŠ¤íŠ¸ ì„¤ëª…ì˜ íë¦„ ìƒ, ì‹œê°ì  ë°ì´í„°ê°€ í•„ìš”í•œ ì ì ˆí•œ ìœ„ì¹˜ì— [GENERATE_CHART] ë§ˆì»¤ë¥¼ í•œ ì¤„ì— ë‹¨ë…ìœ¼ë¡œ ì‚½ì…í•˜ì„¸ìš”.
    7. **ì„œìˆ  ê³„ì†**: ë§ˆì»¤ë¥¼ ì‚½ì…í•œ í›„, ì´ì–´ì„œ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ìì—°ìŠ¤ëŸ½ê²Œ ê³„ì† ì‘ì„±í•˜ì„¸ìš”.
    8. **â­ ë…¸ì…˜ ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ì ê·¹ í™œìš©**: êµµì€ ê¸€ì”¨, ê¸°ìš¸ì„ì²´, ì¸ìš©ë¬¸, ëª©ë¡, í…Œì´ë¸” ë“±ì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì„¸ìš”.
    - **â­ í‘œ í˜•íƒœ ë°ì´í„°**: ë¹„êµë‚˜ ë¶„ë¥˜ê°€ í•„ìš”í•œ ì •ë³´ëŠ” ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ êµ¬ì„±
    - 3ê°œ ì´ìƒì˜ í•­ëª©ì„ ë¹„êµí•˜ê±°ë‚˜ ë¶„ë¥˜í•  ë•Œ í…Œì´ë¸” ì‚¬ìš© ê¶Œì¥
    - í…Œì´ë¸” ì…€ ì•ˆì—ì„œë„ **êµµì€ ê¸€ì”¨**, *ê¸°ìš¸ì„ì²´*, [SOURCE:ìˆ«ì] ì¶œì²˜ í‘œê¸° ê°€ëŠ¥
    9. **â­ ì¶œì²˜ í‘œê¸° (ë°ì´í„° ì¸ë±ìŠ¤ ë²ˆí˜¸ ì‚¬ìš©)**: íŠ¹ì • ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œ ë¬¸ì¥ ë°”ë¡œ ë’¤ì— [SOURCE:ìˆ«ì1, ìˆ«ì2, ìˆ«ì3] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ í‘œê¸°í•˜ì„¸ìš”.

    **ğŸ”´ ë§¤ìš° ì¤‘ìš” - SOURCE ë²ˆí˜¸ ì‚¬ìš© ê·œì¹™**:
    - **ë°˜ë“œì‹œ ìœ„ "ì°¸ê³  ë°ì´í„°"ì— ëª…ì‹œëœ "[ë°ì´í„° ì¸ë±ìŠ¤ X]" ì˜ X ë²ˆí˜¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”**
    - ì˜ˆ: "ë°ì´í„° 0", "ë°ì´í„° 3", "ë°ì´í„° 7"ì´ ì£¼ì–´ì¡Œë‹¤ë©´ â†’ [SOURCE:0], [SOURCE:3], [SOURCE:7]ë§Œ ì‚¬ìš© ê°€ëŠ¥
    - **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë²ˆí˜¸ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”** (ì˜ˆ: ë°ì´í„° 0~7ë§Œ ìˆëŠ”ë° [SOURCE:15] ì‚¬ìš© ê¸ˆì§€)
    - ë°˜ë“œì‹œ ìˆ«ìë§Œ ì‚¬ìš©í•˜ê³  "ë°ì´í„°", "ë¬¸ì„œ" ë“±ì˜ ë‹¨ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

    **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ** (ë°ì´í„° 0, 3, 8ì´ ì£¼ì–´ì§„ ê²½ìš°):
    - "**ì‹œì¥ ê·œëª¨ê°€ 10% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. [SOURCE:8]"
    - "**ë§¤ì¶œì´ 5% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤. [SOURCE:0, 3, 8]"

    **ğŸš« ì ˆëŒ€ ê¸ˆì§€ë˜ëŠ” ì˜ëª»ëœ ì˜ˆì‹œ**:
    - [SOURCE:ë°ì´í„° 8], [SOURCE:ë¬¸ì„œ 8] (ë‹¨ì–´ í¬í•¨ ê¸ˆì§€)
    - [SOURCE:15] (ìœ„ ì°¸ê³  ë°ì´í„°ì— ì—†ëŠ” ë²ˆí˜¸ ì‚¬ìš© ê¸ˆì§€)

    **ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­**:
    âŒ "ì¶”ê°€ ì •ë³´ ìš”ì²­", "ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤", "êµ¬ì²´ì ì¸ ë°ì´í„° ë¶€ì¡±" ë“±ì˜ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
    âŒ "...ì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤" ê°™ì€ ë¯¸ì™„ì„± ê²°ë¡  ì œì‹œ ê¸ˆì§€
    âŒ "ë°ì´í„°ê°€ ì œí•œì ì…ë‹ˆë‹¤", "ì •í™•í•œ ëª©ë¡ ì‘ì„±ì„ ìœ„í•´ì„œëŠ”..." ë“±ì˜ í•œê³„ ì–¸ê¸‰ ê¸ˆì§€
    âœ… **í˜„ì¬ í™•ë³´ëœ ë°ì´í„°ë¡œ ìµœëŒ€í•œ êµ¬ì²´ì ì´ê³  ì™„ì „í•œ ë¶„ì„ ë° ê²°ë¡  ì œì‹œ í•„ìˆ˜**
    âœ… ë¶€ì¡±í•œ ì •ë³´ê°€ ìˆì–´ë„ í˜„ì¬ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ìµœì„ ì˜ ì¸ì‚¬ì´íŠ¸ì™€ í‘œ ì œê³µ
    âœ… í‘œ ìš”ì²­ì´ ìˆìœ¼ë©´ í˜„ì¬ ë°ì´í„°ë¡œ ê°€ëŠ¥í•œ í•œ ì™„ì „í•œ í‘œ ì‘ì„±

    **ë³´ê³ ì„œ ì„¹ì…˜ ë³¸ë¬¸**:
    """

            prompt = prompt_template.format(
                persona_instruction=persona_instruction,
                original_query=original_query,
                section_title=section_title,
                awareness_context=awareness_context,
                description=description,
                section_data_content=section_data_content
            )

        try:
            print(f"\n>> ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {section_title} (ì‚¬ìš© ì¸ë±ìŠ¤: {use_indexes})")
            total_content = ""
            chunk_count = 0
            valid_content_count = 0

            async for chunk in self._astream_with_fallback(
                prompt,
                self.llm_pro,
                self.llm_openai_4o
            ):
                chunk_count += 1
                if hasattr(chunk, 'content') and chunk.content:
                    total_content += chunk.content
                    chunk_text = chunk.content
                    valid_content_count += 1

                    print(f"- ì›ë³¸ ì²­í¬ {chunk_count}: {len(chunk_text)} ë¬¸ì")

                    # 5ì ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì „ì†¡
                    for i in range(0, len(chunk_text), 5):
                        mini_chunk = chunk_text[i:i+5]
                        yield mini_chunk

            print(f"\n>> ì„¹ì…˜ ì™„ë£Œ: {section_title}, ì´ {chunk_count}ê°œ ì›ë³¸ ì²­í¬, {valid_content_count}ê°œ ìœ íš¨ ì²­í¬, {len(total_content)} ë¬¸ì")

            if not total_content.strip() or valid_content_count == 0:
                print(f"- ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ({section_title}): No generation chunks were returned")
                raise Exception("No generation chunks were returned")

        except Exception as e:
            print(f"- ì„¹ì…˜ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ({section_title}): {e}")
            if "No generation chunks" in str(e) or "no valid content" in str(e).lower():
                try:
                    print(f"- OpenAIë¡œ ì§ì ‘ ì¬ì‹œë„: {section_title}")
                    total_content = ""
                    chunk_count = 0

                    async for chunk in self.llm_openai_4o.astream(prompt):
                        chunk_count += 1
                        if hasattr(chunk, 'content') and chunk.content:
                            total_content += chunk.content
                            chunk_text = chunk.content
                            print(f"- OpenAI ì¬ì‹œë„ ì²­í¬ {chunk_count}: {len(chunk_text)} ë¬¸ì")

                            for i in range(0, len(chunk_text), 5):
                                mini_chunk = chunk_text[i:i+5]
                                yield mini_chunk

                    print(f"- OpenAI ì¬ì‹œë„ ì™„ë£Œ: {section_title}, {chunk_count}ê°œ ì²­í¬, {len(total_content)} ë¬¸ì")

                    if not total_content.strip():
                        print(f"- OpenAI ì¬ì‹œë„ë„ ì‹¤íŒ¨, fallback ë‚´ìš© ìƒì„±")
                        raise Exception("OpenAI retry also failed")

                except Exception as retry_error:
                    print(f"- OpenAI ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                    fallback_content = f"*'{section_title}' ì„¹ì…˜ì— ëŒ€í•œ ìƒì„¸í•œ ë¶„ì„ì„ ìƒì„±í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.*\n\n"
                    yield fallback_content
            else:
                error_content = f"*'{section_title}' ì„¹ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}*\n\n"
                yield error_content

    async def _create_charts(self, section_data: List[SearchResult], section_title: str, generated_content: str = "", yield_callback=None, state: Dict[str, Any] = None):
        """â­ ìˆ˜ì •: í˜ë¥´ì†Œë‚˜ ê´€ì ì„ ë°˜ì˜í•˜ì—¬ ì„¹ì…˜ë³„ ì„ íƒëœ ë°ì´í„°ì™€ ìƒì„±ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ì°¨íŠ¸ ìƒì„±"""
        print(f"  - ì°¨íŠ¸ ë°ì´í„° ìƒì„±: '{section_title}' (ë°ì´í„° {len(section_data)}ê°œ)")



        # ì£¼ì–´ì§„ ë°ì´í„°ë¡œë§Œ ì°¨íŠ¸ ìƒì„± (ì¶”ê°€ ê²€ìƒ‰ ì—†ìŒ)

        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì¶”ì¶œ
        persona_name = state.get("persona", "ê¸°ë³¸") if state else "ê¸°ë³¸"
        default_chart_prompt = "ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ëª…í™•í•˜ê³  ìœ ìš©í•œ Chart.js ì°¨íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
        persona_chart_instruction = self.personas.get(persona_name, {}).get("chart_prompt", default_chart_prompt)

        print(f"  - ì°¨íŠ¸ ìƒì„±ì— '{persona_name}' í˜ë¥´ì†Œë‚˜ ê´€ì  ì ìš© (ì°¨íŠ¸ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)")


        # ì°¨íŠ¸ ìƒì„± context ì¶”ì¶œ
        chart_context = state.get("chart_context", {}) if state else {}
        previous_charts = chart_context.get("previous_charts", [])
        previous_sections = chart_context.get("previous_sections", [])

        async def _generate_chart_with_data(current_data: List[SearchResult], attempt: int = 1):
            """ì‹¤ì œ ì°¨íŠ¸ ìƒì„± ë¡œì§ (ì¬ì‹œë„ ê°€ëŠ¥)"""
            try:
                # ë°ì´í„° ìš”ì•½ ìƒì„±
                data_summary = ""
                for i, item in enumerate(current_data):
                    source = getattr(item, 'source', 'Unknown')
                    title = getattr(item, 'title', 'No Title')
                    content = getattr(item, 'content', '')[:]
                    data_summary += f"[{i}] [{source}] {title}\në‚´ìš©: {content}...\n\n"

                # ì§ì „ì— ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš© ì¶”ê°€
                context_info = ""
                if generated_content:
                    content_preview = generated_content[:] if generated_content else ""
                    context_info = f"\n**ì§ì „ì— ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš© (ì°¨íŠ¸ì™€ ì¼ë§¥ìƒí†µí•´ì•¼ í•¨)**:\n{content_preview}\n"

                # ì´ì „ ì°¨íŠ¸ ì •ë³´ ì¶”ê°€
                if previous_charts:
                    context_info += "\n**ì´ì „ ì„¹ì…˜ì—ì„œ ìƒì„±ëœ ì°¨íŠ¸ë“¤ (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì°¸ê³ )**:\n"
                    for prev_chart in previous_charts[-2:]:  # ìµœê·¼ 2ê°œë§Œ
                        chart_section = prev_chart.get("section", "")
                        chart_type = prev_chart.get("chart", {}).get("type", "")
                        chart_labels = prev_chart.get("chart", {}).get("data", {}).get("labels", [])[:]
                        context_info += f"- {chart_section}: {chart_type} ì°¨íŠ¸ (í•­ëª©: {', '.join(map(str, chart_labels))}...)\n"
                    context_info += "\n"

                chart_prompt = f"""
        ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Chain of Thought ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„ì„í•œ í›„ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

        **STEP 1: ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì¶”ë¡  ë° ë¶„ì„**
        
        **ì„¹ì…˜ ì •ë³´**:
        - ì œëª©: "{section_title}"
        - í˜ë¥´ì†Œë‚˜: {persona_name}
        - ì‹œë„: {attempt}íšŒì°¨

        **ìˆ˜ì§‘ëœ ì›ë³¸ ë°ì´í„°**:
        {data_summary}
        {context_info}

        **âš ï¸ ì¤‘ìš”**: Vector DBì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ê°€ ìˆ«ì í‘œë§Œ ìˆê³  ë¬´ì—‡ì— ëŒ€í•œ í†µê³„ì¸ì§€ ë¶ˆë¶„ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ë‹¤ìŒ ë‹¨ê³„ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ë¡ í•˜ê³  ë¶„ì„í•˜ì„¸ìš”:

        ```
        ë¶„ì„:
        1. ì»¨í…ìŠ¤íŠ¸ ì¶”ë¡ :
           - ì„¹ì…˜ ì œëª© "{section_title}"ì„ ë³´ê³  ì´ ë°ì´í„°ê°€ ë¬´ì—‡ì— ê´€í•œ í†µê³„ì¸ì§€ ì¶”ë¡ 
           - ë‹¨ìœ„ ì •ë³´ (ì›/20ê°œ, ì›/50ê°œ ë“±)ë¥¼ ë³´ê³  ì–´ë–¤ ìƒí’ˆ/í’ˆëª©ì¸ì§€ ì¶”ë¡ 
           - ì¶œì²˜ URLì´ë‚˜ ë¬¸ì„œëª…ì—ì„œ ì¶”ê°€ íŒíŠ¸ ì°¾ê¸°
           - ì¶”ë¡ ëœ í’ˆëª©/ìƒí’ˆ: [ì˜ˆ: ê³„ë€, ë°°ì¶”, ìŒ€ ë“±]
           
        2. ì„¹ì…˜ ëª©ì : [ì´ ì„¹ì…˜ì´ ë³´ì—¬ì£¼ë ¤ëŠ” í•µì‹¬ ë‚´ìš©]
        
        3. ì¶”ì¶œ ê°€ëŠ¥í•œ ìˆ˜ì¹˜ ë°ì´í„°:
           - í•­ëª©A: [ì •í™•í•œ ìˆ˜ì¹˜] + [ì¶”ë¡ ëœ ì˜ë¯¸] (ì¶œì²˜: ë°ì´í„° ì¸ë±ìŠ¤ X)
           - í•­ëª©B: [ì •í™•í•œ ìˆ˜ì¹˜] + [ì¶”ë¡ ëœ ì˜ë¯¸] (ì¶œì²˜: ë°ì´í„° ì¸ë±ìŠ¤ Y)
           - í•­ëª©C: [ì •í™•í•œ ìˆ˜ì¹˜] + [ì¶”ë¡ ëœ ì˜ë¯¸] (ì¶œì²˜: ë°ì´í„° ì¸ë±ìŠ¤ Z)
           
        4. ì¶”ì¶œëœ ë¼ë²¨/ì¹´í…Œê³ ë¦¬: [ì‹¤ì œ ì—°ë„, ì›”, ì§€ì—­ëª… ë“±]
        
        5. ìµœì  ì°¨íŠ¸ íƒ€ì…: [ì‹œê³„ì—´ì´ë©´ line, ë¹„êµë©´ bar, êµ¬ì„±ë¹„ë©´ pie]
        
        6. ì°¨íŠ¸ êµ¬ì„±:
           - Xì¶•: [ì¶”ë¡ ëœ í’ˆëª©ëª…ì˜ ì‹œê°„/ì§€ì—­/ì¹´í…Œê³ ë¦¬]
           - Yì¶•: [ì¶”ë¡ ëœ í’ˆëª©ëª…ì˜ ê°€ê²©/ìˆ˜ëŸ‰ + ë‹¨ìœ„]
           - ë°ì´í„°ì…‹: [ì˜ë¯¸ìˆëŠ” ë¼ë²¨ë“¤ê³¼ í•´ë‹¹ ìˆ˜ì¹˜ë“¤]
        ```

        **STEP 2: JSON ì°¨íŠ¸ ìƒì„±**
        
        **ì¤‘ìš” ì œì•½ì‚¬í•­**:
        1. **ì ˆëŒ€ í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€** - STEP 1ì—ì„œ ì¶”ì¶œí•œ ì‹¤ì œ ìˆ˜ì¹˜ë§Œ ì‚¬ìš©
        2. **ì •í™•í•œ ì¶œì²˜ ê¸°ë°˜** - ê° ìˆ˜ì¹˜ëŠ” ì›ë³¸ ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ê²ƒë§Œ
        3. **ì‹¤ì œ ë¼ë²¨ ì‚¬ìš©** - ë°ì´í„°ì˜ ì§€ì—­ëª…, í’ˆëª©ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©

        **ì§€ì› ì°¨íŠ¸ íƒ€ì…**: bar, line, pie, doughnut, radar, polararea, scatter, bubble, area, column, horizontalbar, stacked, mixed, multiline, groupedbar, stackedarea

        **ì„ íƒ ê¸°ì¤€**:
        - ì§€ì—­ë³„/í’ˆëª©ë³„ ë¹„êµ â†’ bar, groupedbar
        - ì‹œê°„ ë³€í™” â†’ line, area
        - ë¹„ìœ¨/êµ¬ì„± â†’ pie, doughnut
        - ë‹¤ì°¨ì› ë¹„êµ â†’ radar

        **âš ï¸ ì ê·¹ì ì¸ ì°¨íŠ¸ ìƒì„± ì›ì¹™**:
        1. **ì¹´í…Œê³ ë¦¬/í•­ëª© ì •ë³´ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í™œìš©** - "ì‚°ì²­êµ°ì˜ ë†ì‚°ë¬¼ ì›ì‚°ì§€" ê°™ì€ ì¹´í…Œê³ ë¦¬ê°€ 96ê°œ ìˆë‹¤ë©´ bar ì°¨íŠ¸ë¡œ í•­ëª© ê°œìˆ˜ë¥¼ í‘œì‹œ
        2. **ì§€ì—­ëª…ì´ ìˆìœ¼ë©´ ì§€ì—­ë³„ ë¶„í¬** - ì—¬ëŸ¬ ì§€ì—­ì´ ì–¸ê¸‰ë˜ë©´ ì§€ì—­ë³„ ì°¨íŠ¸ ìƒì„±
        3. **í’ˆëª©ëª…ì´ ìˆìœ¼ë©´ í’ˆëª©ë³„ ë¶„ì„** - êµ¬ì²´ì  ìˆ˜ì¹˜ê°€ ì—†ì–´ë„ "ì–¸ê¸‰ ë¹ˆë„" ë“±ìœ¼ë¡œ ì°¨íŠ¸ ìƒì„±
        4. **ì‹œê³„ì—´ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ì„¸ ë¶„ì„** - ë‚ ì§œë‚˜ ê¸°ê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ timeline ì°¨íŠ¸
        
        **placeholder ì°¨íŠ¸ëŠ” ì˜¤ì§ ë‹¤ìŒ ê²½ìš°ì—ë§Œ**:
        - ì •ë§ë¡œ ì•„ë¬´ëŸ° ë¶„ì„ ê°€ëŠ¥í•œ ì •ë³´ê°€ ì—†ì„ ë•Œ
        - ëª¨ë“  ë°ì´í„°ê°€ nullì´ê±°ë‚˜ ë¹ˆ ê°’ì¼ ë•Œ
        
        **ë°ì´í„° ë¶€ì¡± ì‹œì—ë„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì°¨íŠ¸ ì˜ˆì‹œ**:
        - ë…¸ë“œ/í•­ëª© ê°œìˆ˜ â†’ bar ì°¨íŠ¸ (ì˜ˆ: "ë†ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬: 15ê°œ, ì¶•ì‚°ë¬¼ ì¹´í…Œê³ ë¦¬: 8ê°œ")
        - ì§€ì—­ ë¶„í¬ â†’ pie ì°¨íŠ¸ (ì˜ˆ: "ì–¸ê¸‰ëœ ì§€ì—­ ë¶„í¬")
        - í‚¤ì›Œë“œ ë¹ˆë„ â†’ bar ì°¨íŠ¸ (ì˜ˆ: "í•µì‹¬ í‚¤ì›Œë“œ ì–¸ê¸‰ íšŸìˆ˜")
        
        **âš ï¸ ì¤‘ìš”**: 96ê°œ í•­ëª©ì´ë‚˜ ì—¬ëŸ¬ ì§€ì—­ì´ ì–¸ê¸‰ë˜ë©´ **ë°˜ë“œì‹œ ì˜ë¯¸ìˆëŠ” ì°¨íŠ¸ ìƒì„±**í•˜ì„¸ìš”. placeholderëŠ” ìµœí›„ì˜ ìˆ˜ë‹¨ì…ë‹ˆë‹¤.

        **ì¶©ë¶„í•œ ë°ì´í„°ì‹œ ì¶œë ¥ í˜•ì‹**:
        
        ë¨¼ì € STEP 1 ë¶„ì„ì„ ë³´ì—¬ì£¼ê³ , ì´ì–´ì„œ JSONì„ ì¶œë ¥í•˜ì„¸ìš”:

        ë¶„ì„:
        [ì—¬ê¸°ì— ë°ì´í„° ë¶„ì„ ë‚´ìš©]

        JSON:
        {{
            "type": "STEP1ë¶„ì„_ê¸°ë°˜_ì°¨íŠ¸íƒ€ì…",
            "data": {{
                "labels": ["STEP1ì¶”ì¶œ_ì‹¤ì œë¼ë²¨1", "ì‹¤ì œë¼ë²¨2", "ì‹¤ì œë¼ë²¨3"],
                "datasets": [{{
                    "label": "STEP1ì •ì˜_ë°ì´í„°ì…‹ëª…",
                    "data": [STEP1ì¶”ì¶œ_ì‹¤ì œìˆ˜ì¹˜1, ì‹¤ì œìˆ˜ì¹˜2, ì‹¤ì œìˆ˜ì¹˜3],
                    "backgroundColor": ["#4F46E5", "#7C3AED", "#EC4899"],
                    "borderColor": "#4F46E5",
                    "borderWidth": 2
                }}]
            }},
            "title": "{section_title}",
            "palette": "modern",
            "options": {{
                "responsive": true,
                "plugins": {{
                    "title": {{
                        "display": true,
                        "text": "{section_title}"
                    }}
                }},
                "scales": {{
                    "y": {{
                        "beginAtZero": true
                    }}
                }}
            }}
        }}
        """

                response = await self._invoke_with_fallback(
                    chart_prompt,
                    self.llm_flash,
                    self.llm_openai_mini
                )
                response_text = response.content.strip()

                # JavaScript í•¨ìˆ˜ ì œê±° í—¬í¼ í•¨ìˆ˜ ì •ì˜
                def clean_js_functions(json_str):
                    """JSONì—ì„œ JavaScript í•¨ìˆ˜ ì½”ë“œë¥¼ ë” ê²¬ê³ í•˜ê²Œ ì œê±°"""
                    import re
                    
                    # 1. ê°€ì¥ ì•ˆì „í•œ ë°©ë²•: callbacks ê°ì²´ ì „ì²´ë¥¼ ë¹ˆ ê°ì²´ë¡œ êµì²´
                    # ì¤‘ì²©ëœ ì¤‘ê´„í˜¸ê¹Œì§€ ëª¨ë‘ í¬í•¨í•˜ì—¬ ì œê±°
                    def find_and_replace_callbacks(text):
                        """callbacks ê°ì²´ë¥¼ ì°¾ì•„ì„œ ë¹ˆ ê°ì²´ë¡œ êµì²´"""
                        pattern = r'"callbacks"\s*:\s*\{'
                        match = re.search(pattern, text)
                        if not match:
                            return text
                            
                        start_pos = match.start()
                        brace_pos = text.find('{', match.end() - 1)
                        
                        if brace_pos == -1:
                            return text
                            
                        # ì¤‘ê´„í˜¸ ê· í˜• ë§ì¶”ê¸°
                        brace_count = 1
                        i = brace_pos + 1
                        
                        while i < len(text) and brace_count > 0:
                            if text[i] == '{':
                                brace_count += 1
                            elif text[i] == '}':
                                brace_count -= 1
                            i += 1
                            
                        if brace_count == 0:
                            # callbacks ê°ì²´ ì „ì²´ë¥¼ ë¹ˆ ê°ì²´ë¡œ êµì²´
                            before = text[:start_pos]
                            after = text[i:]
                            return before + '"callbacks": {}' + after
                        
                        return text
                    
                    # 2. callbacks ê°ì²´ êµì²´
                    json_str = find_and_replace_callbacks(json_str)
                    
                    # 3. ë‚¨ì€ function íŒ¨í„´ë“¤ ì œê±°
                    # function(...) { ... } íŒ¨í„´ì„ nullë¡œ êµì²´
                    json_str = re.sub(r'function\s*\([^)]*\)\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', 'null', json_str, flags=re.DOTALL)
                    
                    # 4. í‚¤-ê°’ì—ì„œ functionìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê°’ë“¤ ì œê±°
                    json_str = re.sub(r':\s*function\s*\([^)]*\)\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', ': null', json_str, flags=re.DOTALL)
                    
                    # 5. ì˜ëª»ëœ JSON êµ¬ì¡° ì •ë¦¬
                    # null ë’¤ì— ì˜¤ëŠ” ì˜ëª»ëœ ì½”ë“œ íŒ¨í„´ ì œê±°
                    json_str = re.sub(r'null\s+[^,}\]]*(?:if|let|var|return|context)[^,}\]]*', 'null', json_str, flags=re.DOTALL)
                    
                    # 6. ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ í•¨ìˆ˜ ë³¸ë¬¸ ì •ë¦¬
                    json_str = re.sub(r'null\s*\n\s*if\s*\([^)]*\)\s*\{[^}]*\}\s*return[^;}]*;?\s*\}?', 'null', json_str, flags=re.DOTALL)
                    
                    # 7. ë‚¨ì€ JavaScript ì½”ë“œ ì¡°ê°ë“¤ ì œê±°
                    json_str = re.sub(r'if\s*\([^)]*\)\s*\{[^}]*\}', '', json_str, flags=re.DOTALL)
                    json_str = re.sub(r'return\s+[^;}]*;?', '', json_str, flags=re.DOTALL)
                    json_str = re.sub(r'let\s+\w+\s*=\s*[^;]*;', '', json_str, flags=re.DOTALL)
                    json_str = re.sub(r'var\s+\w+\s*=\s*[^;]*;', '', json_str, flags=re.DOTALL)
                    
                    # 8. ë¹ˆ ë¬¸ìì—´ì´ë‚˜ null ê°’ë“¤ ì •ë¦¬
                    json_str = re.sub(r',\s*null\s*,', ',', json_str)
                    json_str = re.sub(r',\s*null\s*}', '}', json_str)
                    json_str = re.sub(r'{\s*null\s*,', '{', json_str)
                    
                    # 9. ë¶ˆì™„ì „í•œ êµ¬ì¡° ì •ë¦¬
                    json_str = re.sub(r'\s*\n\s*\n\s*', '\n', json_str)  # ë¹ˆ ì¤„ ì •ë¦¬
                    json_str = re.sub(r',\s*}', '}', json_str)  # trailing comma ì œê±°
                    json_str = re.sub(r',\s*]', ']', json_str)  # trailing comma ì œê±°
                    
                    return json_str

                # ê°„ë‹¨í•˜ê³  ì •í™•í•œ JSON ì¶”ì¶œ í•¨ìˆ˜
                def extract_json_simple(text):
                    """ê°„ë‹¨í•˜ê³  ì •í™•í•œ JSON ì¶”ì¶œ"""
                    # 1. ```json ë¸”ë¡ì—ì„œ ì¶”ì¶œ
                    if "```json" in text:
                        start = text.find("```json") + 7
                        end = text.find("```", start)
                        if end != -1:
                            return text[start:end].strip()
                    
                    # 2. JSON: ë‹¤ìŒì—ì„œ ì¶”ì¶œ
                    if "JSON:" in text:
                        start = text.find("JSON:") + 5
                        # ì²« ë²ˆì§¸ { ì°¾ê¸°
                        json_start = text.find("{", start)
                        if json_start == -1:
                            return None
                            
                        # ê· í˜•ì¡íŒ } ì°¾ê¸°
                        brace_count = 0
                        for i in range(json_start, len(text)):
                            if text[i] == '{':
                                brace_count += 1
                            elif text[i] == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    return text[json_start:i+1]
                    
                    # 3. ì²« ë²ˆì§¸ { }ë¸”ë¡ ì¶”ì¶œ
                    json_start = text.find("{")
                    if json_start == -1:
                        return None
                        
                    brace_count = 0
                    for i in range(json_start, len(text)):
                        if text[i] == '{':
                            brace_count += 1
                        elif text[i] == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                return text[json_start:i+1]
                    
                    return None

                # COT ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ 
                try:
                    print(f"  - ì›ë³¸ LLM ì‘ë‹µ (ì²˜ìŒ 500ì): {response_text[:500]}...")
                    print(f"  - ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response_text)}ì")
                    
                    # ê°„ë‹¨í•œ JSON ì¶”ì¶œ ì ìš©
                    json_part = extract_json_simple(response_text)
                    if not json_part:
                        print(f"  - JSON ì¶”ì¶œ ì‹¤íŒ¨: JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        raise ValueError("JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    
                    print(f"  - JSON ì¶”ì¶œ ì„±ê³µ: {len(json_part)}ì")
                    
                    print(f"  - ì¶”ì¶œëœ JSON íŒŒíŠ¸: {json_part[:300]}...")

                    # JavaScript í•¨ìˆ˜ ì œê±° (JSON íŒŒì‹± ì „ì— ì‹¤í–‰)
                    cleaned_json = clean_js_functions(json_part)
                    print(f"  - JavaScript í•¨ìˆ˜ ì œê±° í›„: {cleaned_json[:300]}...")

                    # JSON íŒŒì‹±
                    chart_response = json.loads(cleaned_json)
                    
                    # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSON ì‘ë‹µ ì²˜ë¦¬
                    if isinstance(chart_response, list) and len(chart_response) > 0:
                        print(f"  - JSON íŒŒì‹± ì„±ê³µ: ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ({len(chart_response)}ê°œ í•­ëª©), ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©")
                        chart_response = chart_response[0]  # ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©
                    elif isinstance(chart_response, dict):
                        print(f"  - JSON íŒŒì‹± ì„±ê³µ: ë”•ì…”ë„ˆë¦¬ í˜•íƒœ")
                    else:
                        raise ValueError(f"ì˜¬ë°”ë¥´ì§€ ì•Šì€ JSON í˜•ì‹: {type(chart_response)}")
                    
                    print(f"  - ì°¨íŠ¸ íƒ€ì…: {chart_response.get('type', 'unknown')}")
                    print(f"  - insufficient_data ì—¬ë¶€: {chart_response.get('insufficient_data', False)}")
                    
                    if chart_response.get('insufficient_data', False):
                        print(f"  - ë¶€ì¡±í•œ ë°ì´í„° ì •ë³´: {chart_response.get('missing_info', 'N/A')}")
                        print(f"  - ì œì•ˆëœ ê²€ìƒ‰ì–´: {chart_response.get('suggested_search_query', 'N/A')}")

                    # ì´ì œ ì¶”ê°€ ê²€ìƒ‰ì€ ë³´ê³ ì„œ êµ¬ì¡° ë‹¨ê³„ì—ì„œ ì²˜ë¦¬ë¨

                    # >> ì •ìƒì ì¸ ì°¨íŠ¸ ë°ì´í„°ì¸ ê²½ìš°
                    elif "type" in chart_response and "data" in chart_response:
                        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                        datasets = chart_response.get("data", {}).get("datasets", [])
                        if datasets and len(datasets) > 0:
                            data_points = datasets[0].get("data", [])
                            if len(data_points) < 2:
                                print(f"  - ê²½ê³ : ì°¨íŠ¸ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•¨ ({len(data_points)}ê°œ)")

                        # ì½œë°± í•¨ìˆ˜ ì œê±° (í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜ ë°©ì§€)
                        def remove_callbacks(obj):
                            if isinstance(obj, dict):
                                # ì½œë°± í•¨ìˆ˜ ê´€ë ¨ í‚¤ë“¤ ì œê±°
                                callback_keys = ['callback', 'callbacks', 'generateLabels']
                                for key in list(obj.keys()):
                                    if key in callback_keys:
                                        del obj[key]
                                    elif isinstance(obj[key], str) and 'function' in obj[key]:
                                        del obj[key]
                                    else:
                                        remove_callbacks(obj[key])
                            elif isinstance(obj, list):
                                for item in obj:
                                    remove_callbacks(item)

                        remove_callbacks(chart_response)

                        print(f"  - ì°¨íŠ¸ ìƒì„± ì„±ê³µ: {chart_response['type']} íƒ€ì…, {len(datasets)}ê°œ ë°ì´í„°ì…‹ (ì‹œë„ {attempt})")
                        yield {
                            "type": "chart",
                            "data": chart_response
                        }
                        return
                    else:
                        raise ValueError("ì˜¬ë°”ë¥´ì§€ ì•Šì€ JSON í˜•ì‹")

                except (json.JSONDecodeError, ValueError) as e:
                    print(f"  - ì°¨íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨ (ì‹œë„ {attempt}): {e}")
                    print(f"  - ì¶”ì¶œëœ JSON ê¸¸ì´: {len(json_part)}ì")
                    print(f"  - JSON ì‹œì‘: {json_part[:200]}...")
                    print(f"  - JSON ë: ...{json_part[-200:]}")
                    
                    # ê°„ë‹¨í•œ ì¬ì‹œë„: ì „ì²´ ì‘ë‹µì—ì„œ ë‹¤ì‹œ JSON ì¶”ì¶œ ì‹œë„
                    retry_success = False
                    try:
                        print(f"  - JSON íŒŒì‹± ì¬ì‹œë„ ì¤‘...")
                        # ì „ì²´ ì‘ë‹µì—ì„œ ì™„ì „í•œ JSON ë¸”ë¡ ì°¾ê¸°
                        json_start = response_text.find("{")
                        if json_start != -1:
                            brace_count = 0
                            for i in range(json_start, len(response_text)):
                                if response_text[i] == '{':
                                    brace_count += 1
                                elif response_text[i] == '}':
                                    brace_count -= 1
                                    if brace_count == 0:
                                        retry_json = response_text[json_start:i+1]
                                        cleaned_retry = clean_js_functions(retry_json)
                                        chart_response = json.loads(cleaned_retry)
                                        
                                        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSON ì‘ë‹µ ì²˜ë¦¬
                                        if isinstance(chart_response, list) and len(chart_response) > 0:
                                            print(f"  - ì¬ì‹œë„: ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ({len(chart_response)}ê°œ í•­ëª©), ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš©")
                                            chart_response = chart_response[0]
                                        
                                        print(f"  - ì¬ì‹œë„ JSON íŒŒì‹± ì„±ê³µ! ({len(retry_json)}ì)")
                                        retry_success = True
                                        break
                    except Exception as retry_e:
                        print(f"  - JSON íŒŒì‹± ì¬ì‹œë„ë„ ì‹¤íŒ¨: {retry_e}")
                    
                    # ì¬ì‹œë„ ì„±ê³µí•œ ê²½ìš° ì²˜ë¦¬
                    if retry_success:
                        print(f"  - JSON íŒŒì‹± ì¬ì‹œë„ ì„±ê³µ! ì°¨íŠ¸ ìƒì„± ì§„í–‰")
                        
                        # insufficient_data ì²´í¬
                        if chart_response.get('insufficient_data', False):
                            print(f"  - ë¶€ì¡±í•œ ë°ì´í„° ì •ë³´: {chart_response.get('missing_info', 'N/A')}")
                            print(f"  - ì œì•ˆëœ ê²€ìƒ‰ì–´: {chart_response.get('suggested_search_query', 'N/A')}")
                            # ì´ì œ ì¶”ê°€ ê²€ìƒ‰ì€ ë³´ê³ ì„œ êµ¬ì¡° ë‹¨ê³„ì—ì„œ ì²˜ë¦¬ë¨
                        
                        # ì •ìƒì ì¸ ì°¨íŠ¸ ë°ì´í„°ì¸ ê²½ìš°
                        elif "type" in chart_response and "data" in chart_response:
                            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                            datasets = chart_response.get("data", {}).get("datasets", [])
                            if datasets and len(datasets) > 0:
                                data_points = datasets[0].get("data", [])
                                if len(data_points) < 2:
                                    print(f"  - ê²½ê³ : ì°¨íŠ¸ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•¨ ({len(data_points)}ê°œ)")

                            # ì½œë°± í•¨ìˆ˜ ì œê±° (í”„ë¡ íŠ¸ì—”ë“œ ì˜¤ë¥˜ ë°©ì§€)
                            def remove_callbacks(obj):
                                if isinstance(obj, dict):
                                    # ì½œë°± í•¨ìˆ˜ ê´€ë ¨ í‚¤ë“¤ ì œê±°
                                    callback_keys = ['callback', 'callbacks', 'generateLabels']
                                    for key in list(obj.keys()):
                                        if key in callback_keys:
                                            del obj[key]
                                        elif isinstance(obj[key], str) and 'function' in obj[key]:
                                            del obj[key]
                                        else:
                                            remove_callbacks(obj[key])
                                elif isinstance(obj, list):
                                    for item in obj:
                                        remove_callbacks(item)

                            remove_callbacks(chart_response)

                            print(f"  - ì°¨íŠ¸ ìƒì„± ì„±ê³µ: {chart_response['type']} íƒ€ì…, {len(datasets)}ê°œ ë°ì´í„°ì…‹ (ì¬ì‹œë„ ì„±ê³µ)")
                            yield {
                                "type": "chart",
                                "data": chart_response
                            }
                            return
                        else:
                            print(f"  - ì¬ì‹œë„ ì„±ê³µí–ˆì§€ë§Œ ì˜¬ë°”ë¥´ì§€ ì•Šì€ JSON í˜•ì‹")
                    
                    print(f"  - JSON íŒŒì‹± ì¬ì‹œë„ë„ ì‹¤íŒ¨, fallback ì°¨íŠ¸ë¡œ ì§„í–‰")

                    # ìµœì¢… fallback ì°¨íŠ¸
                    yield {
                        "type": "chart",
                        "data": {
                            "type": "bar",
                            "data": {
                                "labels": [f"{section_title} ê´€ë ¨ ë°ì´í„°"],
                                "datasets": [{
                                    "label": "ì •ë³´ ìˆ˜ì§‘ ìƒíƒœ",
                                    "data": [1],
                                    "backgroundColor": "rgba(255, 193, 7, 0.6)",
                                    "borderColor": "rgba(255, 193, 7, 1)",
                                    "borderWidth": 1
                                }]
                            },
                            "options": {
                                "responsive": True,
                                "plugins": {
                                    "title": {
                                        "display": True,
                                        "text": f"{section_title} - ë°ì´í„° ë¶„ì„ ì¤‘"
                                    }
                                },
                                "scales": {
                                    "y": {
                                        "beginAtZero": True,
                                        "max": 2,
                                        "ticks": {
                                            "stepSize": 1
                                        }
                                    }
                                }
                            }
                        }
                    }

            except Exception as e:
                print(f"  - ì°¨íŠ¸ ìƒì„± ì „ì²´ ì˜¤ë¥˜ (ì‹œë„ {attempt}): {e}")
                yield {
                    "type": "chart",
                    "data": {
                        "type": "bar",
                        "data": {
                            "labels": ["ì‹œìŠ¤í…œ ì˜¤ë¥˜"],
                            "datasets": [{
                                "label": "ì²˜ë¦¬ ìƒíƒœ",
                                "data": [0],
                                "backgroundColor": "rgba(220, 53, 69, 0.6)",
                                "borderColor": "rgba(220, 53, 69, 1)",
                                "borderWidth": 1
                            }]
                        },
                        "options": {
                            "responsive": True,
                            "plugins": {
                                "title": {
                                    "display": True,
                                    "text": "ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
                                }
                            }
                        }
                    }
                }

        # >> ë©”ì¸ ë¡œì§ ì‹¤í–‰
        async for result in _generate_chart_with_data(section_data, attempt=1):
            yield result
